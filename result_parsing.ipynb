{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cdc10e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BAYESIAN NETWORK MODEL PERFORMANCE ANALYSIS\n",
      "================================================================================\n",
      "Total tests: 540\n",
      "Models tested: gpt-oss:latest, llama3.1:70b, qwen3:8b\n",
      "Test types: elementary_test, numerical_test\n",
      "Question categories: dependency, common_cause, common_effect, blocked_evidence, probability, evidence_change_relationship\n",
      "Network size: 5 nodes\n",
      "================================================================================\n",
      "\n",
      "OVERALL PERFORMANCE SUMMARY\n",
      "--------------------------------------------------------------------------------\n",
      "+----+----------------+-------------+-------------+-----------+---------------+---------------+\n",
      "|    |     Model      |  Framework  |   Avg Score |   Std Dev |   Total Tests |   Improvement |\n",
      "+====+================+=============+=============+===========+===============+===============+\n",
      "|  0 | gpt-oss:latest |  Raw Model  |       0.594 |     0.491 |           180 |         0.333 |\n",
      "+----+----------------+-------------+-------------+-----------+---------------+---------------+\n",
      "|  1 | gpt-oss:latest |   BayMin    |       0.928 |     0.259 |           180 |         0.333 |\n",
      "+----+----------------+-------------+-------------+-----------+---------------+---------------+\n",
      "|  2 |  llama3.1:70b  |  Raw Model  |       0.361 |     0.48  |           180 |         0.311 |\n",
      "+----+----------------+-------------+-------------+-----------+---------------+---------------+\n",
      "|  3 |  llama3.1:70b  |   BayMin    |       0.672 |     0.469 |           180 |         0.311 |\n",
      "+----+----------------+-------------+-------------+-----------+---------------+---------------+\n",
      "|  4 |    qwen3:8b    |  Raw Model  |       0.506 |     0.5   |           180 |         0.306 |\n",
      "+----+----------------+-------------+-------------+-----------+---------------+---------------+\n",
      "|  5 |    qwen3:8b    |   BayMin    |       0.811 |     0.391 |           180 |         0.306 |\n",
      "+----+----------------+-------------+-------------+-----------+---------------+---------------+\n",
      "\n",
      "\n",
      "DETAILED BREAKDOWN BY QUESTION TYPE\n",
      "================================================================================\n",
      "\n",
      "DEPENDENCY QUESTIONS\n",
      "--------------------------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.733 |        1     |         0.267 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.467 |        0.633 |         0.167 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.767 |        1     |         0.233 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "COMMON CAUSE QUESTIONS\n",
      "--------------------------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.8   |        0.967 |         0.167 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.467 |        0.933 |         0.467 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.667 |        0.967 |         0.3   |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "COMMON EFFECT QUESTIONS\n",
      "--------------------------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.667 |        0.933 |         0.267 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.4   |        0.7   |         0.3   |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.667 |        1     |         0.333 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "BLOCKED EVIDENCE QUESTIONS\n",
      "--------------------------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.233 |        0.9   |         0.667 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.267 |        0.833 |         0.567 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.267 |        0.433 |         0.167 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "PROBABILITY QUESTIONS\n",
      "--------------------------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.4   |        0.967 |         0.567 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.033 |        0.033 |         0     |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.033 |        0.5   |         0.467 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "EVIDENCE CHANGE RELATIONSHIP QUESTIONS\n",
      "--------------------------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.733 |        0.8   |         0.067 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.533 |        0.9   |         0.367 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.633 |        0.967 |         0.333 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "\n",
      "PERFORMANCE BY TEST TYPE\n",
      "================================================================================\n",
      "\n",
      "ELEMENTARY TEST\n",
      "------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.633 |        0.92  |         0.287 |     150 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.427 |        0.8   |         0.373 |     150 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.6   |        0.873 |         0.273 |     150 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "NUMERICAL TEST\n",
      "------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.4   |        0.967 |         0.567 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.033 |        0.033 |         0     |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.033 |        0.5   |         0.467 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "\n",
      "RUNTIME ANALYSIS\n",
      "================================================================================\n",
      "+----+----------------+-----------------------+--------------------------+--------------------+\n",
      "|    |     Model      |   Raw Avg Runtime (s) |   BayMin Avg Runtime (s) |  Runtime Overhead  |\n",
      "+====+================+=======================+==========================+====================+\n",
      "|  0 | gpt-oss:latest |                 68.25 |                    42.31 |      -25.94s       |\n",
      "+----+----------------+-----------------------+--------------------------+--------------------+\n",
      "|  1 |  llama3.1:70b  |                 37.06 |                    54.63 |      +17.56s       |\n",
      "+----+----------------+-----------------------+--------------------------+--------------------+\n",
      "|  2 |    qwen3:8b    |                 74.75 |                    50.73 |      -24.02s       |\n",
      "+----+----------------+-----------------------+--------------------------+--------------------+\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "def parse_and_print_results(csv_file_path):\n",
    "    \"\"\"\n",
    "    Parse the test log CSV and print a comprehensive performance table.\n",
    "    \n",
    "    Args:\n",
    "        csv_file_path (str): Path to the CSV file containing test results\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"BAYESIAN NETWORK MODEL PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total tests: {len(df)}\")\n",
    "    print(f\"Models tested: {', '.join(df['model'].unique())}\")\n",
    "    print(f\"Test types: {', '.join(df['test_type'].unique())}\")\n",
    "    print(f\"Question categories: {', '.join(df['question_set_name'].unique())}\")\n",
    "    print(f\"Network size: {df['network_size'].iloc[0]} nodes\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Create summary statistics\n",
    "    summary_data = []\n",
    "    \n",
    "    # Group by model and question type\n",
    "    for model in df['model'].unique():\n",
    "        model_data = df[df['model'] == model]\n",
    "        \n",
    "        # Raw model performance\n",
    "        raw_scores = model_data['raw_model_score'].values\n",
    "        raw_avg = np.mean(raw_scores)\n",
    "        raw_std = np.std(raw_scores)\n",
    "        \n",
    "        # BayMin framework performance  \n",
    "        baymin_scores = model_data['baymin_score'].values\n",
    "        baymin_avg = np.mean(baymin_scores)\n",
    "        baymin_std = np.std(baymin_scores)\n",
    "        \n",
    "        # Performance improvement\n",
    "        improvement = baymin_avg - raw_avg\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Model': model,\n",
    "            'Framework': 'Raw Model',\n",
    "            'Avg Score': f\"{raw_avg:.3f}\",\n",
    "            'Std Dev': f\"{raw_std:.3f}\",\n",
    "            'Total Tests': len(raw_scores),\n",
    "            'Improvement': f\"{improvement:+.3f}\"\n",
    "        })\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Model': model,\n",
    "            'Framework': 'BayMin',\n",
    "            'Avg Score': f\"{baymin_avg:.3f}\",\n",
    "            'Std Dev': f\"{baymin_std:.3f}\",\n",
    "            'Total Tests': len(baymin_scores),\n",
    "            'Improvement': f\"{improvement:+.3f}\"\n",
    "        })\n",
    "    \n",
    "    # Print overall summary table\n",
    "    print(\"\\nOVERALL PERFORMANCE SUMMARY\")\n",
    "    print(\"-\" * 80)\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(tabulate(summary_df, headers='keys', tablefmt='grid', stralign='center'))\n",
    "    \n",
    "    # Detailed breakdown by question type\n",
    "    print(\"\\n\\nDETAILED BREAKDOWN BY QUESTION TYPE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for question_type in df['question_set_name'].unique():\n",
    "        print(f\"\\n{question_type.upper().replace('_', ' ')} QUESTIONS\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        type_data = df[df['question_set_name'] == question_type]\n",
    "        type_summary = []\n",
    "        \n",
    "        for model in type_data['model'].unique():\n",
    "            model_type_data = type_data[type_data['model'] == model]\n",
    "            \n",
    "            raw_avg = np.mean(model_type_data['raw_model_score'].values)\n",
    "            baymin_avg = np.mean(model_type_data['baymin_score'].values)\n",
    "            improvement = baymin_avg - raw_avg\n",
    "            \n",
    "            type_summary.append({\n",
    "                'Model': model,\n",
    "                'Raw Avg': f\"{raw_avg:.3f}\",\n",
    "                'BayMin Avg': f\"{baymin_avg:.3f}\",\n",
    "                'Improvement': f\"{improvement:+.3f}\",\n",
    "                'Tests': len(model_type_data)\n",
    "            })\n",
    "        \n",
    "        type_df = pd.DataFrame(type_summary)\n",
    "        print(tabulate(type_df, headers='keys', tablefmt='grid', stralign='center'))\n",
    "    \n",
    "    # Performance by test type (elementary vs numerical)\n",
    "    print(\"\\n\\nPERFORMANCE BY TEST TYPE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for test_type in df['test_type'].unique():\n",
    "        print(f\"\\n{test_type.upper().replace('_', ' ')}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        test_data = df[df['test_type'] == test_type]\n",
    "        test_summary = []\n",
    "        \n",
    "        for model in test_data['model'].unique():\n",
    "            model_test_data = test_data[test_data['model'] == model]\n",
    "            \n",
    "            raw_avg = np.mean(model_test_data['raw_model_score'].values)\n",
    "            baymin_avg = np.mean(model_test_data['baymin_score'].values)\n",
    "            improvement = baymin_avg - raw_avg\n",
    "            \n",
    "            test_summary.append({\n",
    "                'Model': model,\n",
    "                'Raw Avg': f\"{raw_avg:.3f}\",\n",
    "                'BayMin Avg': f\"{baymin_avg:.3f}\",\n",
    "                'Improvement': f\"{improvement:+.3f}\",\n",
    "                'Tests': len(model_test_data)\n",
    "            })\n",
    "        \n",
    "        test_df = pd.DataFrame(test_summary)\n",
    "        print(tabulate(test_df, headers='keys', tablefmt='grid', stralign='center'))\n",
    "    \n",
    "    # Runtime analysis\n",
    "    print(\"\\n\\nRUNTIME ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    runtime_summary = []\n",
    "    for model in df['model'].unique():\n",
    "        model_data = df[df['model'] == model]\n",
    "        \n",
    "        raw_runtime = model_data['raw_model_runtime'].values\n",
    "        baymin_runtime = model_data['baymin_runtime'].values\n",
    "        \n",
    "        runtime_summary.append({\n",
    "            'Model': model,\n",
    "            'Raw Avg Runtime (s)': f\"{np.mean(raw_runtime):.2f}\",\n",
    "            'BayMin Avg Runtime (s)': f\"{np.mean(baymin_runtime):.2f}\",\n",
    "            'Runtime Overhead': f\"{np.mean(baymin_runtime) - np.mean(raw_runtime):+.2f}s\"\n",
    "        })\n",
    "    \n",
    "    runtime_df = pd.DataFrame(runtime_summary)\n",
    "    print(tabulate(runtime_df, headers='keys', tablefmt='grid', stralign='center'))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Test the function\n",
    "csv_path = \"benchmarking/results/latest/test_log.csv\"\n",
    "parse_and_print_results(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab6423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuestionType NetworkSize [Raw] gpt-oss:20b llama3.1:70b qwen3:8b [BayMin] gpt-oss:20b llama3.1:70b qwen3:8b\n",
      "Blocked Evidence 5 23 27 27 90 83 43\n",
      "Common Cause 5 80 47 67 97 93 97\n",
      "Common Effect 5 67 40 67 93 70 100\n",
      "Dependency 5 73 47 77 100 63 100\n",
      "Evidence Change Relationship 5 73 53 63 80 90 97\n",
      "Probability 5 40 3 3 97 3 50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "MODEL_ORDER = ['gpt-oss:latest', 'llama3.1:70b', 'qwen3:8b']\n",
    "MODEL_LABEL = {\n",
    "\t'gpt-oss:latest': 'gpt-oss:20b',\n",
    "\t'llama3.1:70b': 'llama3.1:70b',\n",
    "\t'qwen3:8b': 'qwen3:8b',\n",
    "}\n",
    "\n",
    "\n",
    "def _pct(x):\n",
    "\tif len(x) == 0 or np.isnan(x).all():\n",
    "\t\treturn None\n",
    "\treturn round(float(np.nanmean(x) * 100.0), 1)\n",
    "\n",
    "\n",
    "def print_compact_performance_table(csv_file_path: str) -> pd.DataFrame:\n",
    "\t\"\"\"\n",
    "\tPrint a compact table per requirement:\n",
    "\tQuestionType NetworkSize Raw[gpt-oss:20b llama3.1:70b qwen3:8b] BayMin[gpt-oss:20b llama3.1:70b qwen3:8b]\n",
    "\tExample row: \"Dependency 5 60 30 50 90 70 80\"\n",
    "\tReturns the DataFrame used to print, for reuse/saving if needed.\n",
    "\t\"\"\"\n",
    "\t# Load\n",
    "\tdf = pd.read_csv(csv_file_path)\n",
    "\n",
    "\t# Aggregate means per (question_set_name, network_size, model)\n",
    "\tagg = (\n",
    "\t\tdf.groupby(['question_set_name', 'network_size', 'model'])\n",
    "\t\t.agg(raw_mean=('raw_model_score', 'mean'), baymin_mean=('baymin_score', 'mean'))\n",
    "\t\t.reset_index()\n",
    "\t)\n",
    "\n",
    "\t# Ensure all models appear even if missing for a question type\n",
    "\tqns = sorted(df['question_set_name'].unique().tolist())\n",
    "\tnsizes = sorted(df['network_size'].unique().tolist())\n",
    "\trows = []\n",
    "\tfor q in qns:\n",
    "\t\tfor ns in nsizes:\n",
    "\t\t\trow = {\n",
    "\t\t\t\t'QuestionType': q.replace('_', ' ').title(),\n",
    "\t\t\t\t'NetworkSize': ns,\n",
    "\t\t\t}\n",
    "\t\t\t# Raw block\n",
    "\t\t\tfor m in MODEL_ORDER:\n",
    "\t\t\t\tval = agg[(agg['question_set_name'] == q) & (agg['network_size'] == ns) & (agg['model'] == m)]['raw_mean']\n",
    "\t\t\t\tscore = _pct(val.values) if len(val) else None\n",
    "\t\t\t\trow[f'Raw {MODEL_LABEL[m]}'] = score\n",
    "\t\t\t# BayMin block\n",
    "\t\t\tfor m in MODEL_ORDER:\n",
    "\t\t\t\tval = agg[(agg['question_set_name'] == q) & (agg['network_size'] == ns) & (agg['model'] == m)]['baymin_mean']\n",
    "\t\t\t\tscore = _pct(val.values) if len(val) else None\n",
    "\t\t\t\trow[f'BayMin {MODEL_LABEL[m]}'] = score\n",
    "\t\t\trows.append(row)\n",
    "\n",
    "\twide_df = pd.DataFrame(rows)\n",
    "\n",
    "\t# Desired column ordering\n",
    "\tcols = (\n",
    "\t\t['QuestionType', 'NetworkSize'] +\n",
    "\t\t[*(f'Raw {MODEL_LABEL[m]}' for m in MODEL_ORDER)] +\n",
    "\t\t[*(f'BayMin {MODEL_LABEL[m]}' for m in MODEL_ORDER)]\n",
    "\t)\n",
    "\twide_df = wide_df[cols]\n",
    "\n",
    "\t# Print header with groups\n",
    "\traw_labels = [MODEL_LABEL[m] for m in MODEL_ORDER]\n",
    "\tbay_labels = [MODEL_LABEL[m] for m in MODEL_ORDER]\n",
    "\theader = (\n",
    "\t\t\"QuestionType NetworkSize \"\n",
    "\t\t\"[Raw] \" + \" \".join(raw_labels) + \" \"\n",
    "\t\t\"[BayMin] \" + \" \".join(bay_labels)\n",
    "\t)\n",
    "\tprint(header)\n",
    "\tfor _, r in wide_df.iterrows():\n",
    "\t\tvals = [\n",
    "\t\t\tstr(r['QuestionType']),\n",
    "\t\t\tstr(r['NetworkSize']),\n",
    "\t\t\t*[(\"\" if pd.isna(r[c]) else str(int(r[c]))) for c in [f'Raw {lab}' for lab in raw_labels]],\n",
    "\t\t\t*[(\"\" if pd.isna(r[c]) else str(int(r[c]))) for c in [f'BayMin {lab}' for lab in bay_labels]],\n",
    "\t\t]\n",
    "\t\tprint(\" \".join(vals))\n",
    "\n",
    "\treturn wide_df\n",
    "\n",
    "# Example usage (uncomment to run in the notebook):\n",
    "_ = print_compact_performance_table('benchmarking/results/latest/test_log.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4cc2397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Raw</th>\n",
       "      <th colspan=\"3\" halign=\"left\">BayMin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>gpt-oss:20b</th>\n",
       "      <th>llama3.1:70b</th>\n",
       "      <th>qwen3:8b</th>\n",
       "      <th>gpt-oss:20b</th>\n",
       "      <th>llama3.1:70b</th>\n",
       "      <th>qwen3:8b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuestionType</th>\n",
       "      <th>NetworkSize</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Blocked Evidence</th>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>83.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>87</td>\n",
       "      <td>-</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>87</td>\n",
       "      <td>-</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>93</td>\n",
       "      <td>-</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Common Cause</th>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>47.0</td>\n",
       "      <td>33</td>\n",
       "      <td>93</td>\n",
       "      <td>93.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>-</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>-</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Common Effect</th>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33</td>\n",
       "      <td>93</td>\n",
       "      <td>70.0</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>90</td>\n",
       "      <td>-</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>87</td>\n",
       "      <td>-</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>90</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Dependency</th>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>47.0</td>\n",
       "      <td>38</td>\n",
       "      <td>98</td>\n",
       "      <td>63.0</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>90</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>93</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>90</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Evidence Change Relationship</th>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>53.0</td>\n",
       "      <td>32</td>\n",
       "      <td>83</td>\n",
       "      <td>90.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>80</td>\n",
       "      <td>-</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>80</td>\n",
       "      <td>-</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>83</td>\n",
       "      <td>-</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Probability</th>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>-</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>90</td>\n",
       "      <td>-</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>90</td>\n",
       "      <td>-</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Raw                        \\\n",
       "                                         gpt-oss:20b llama3.1:70b qwen3:8b   \n",
       "QuestionType                 NetworkSize                                     \n",
       "Blocked Evidence             5                    12         27.0       13   \n",
       "                             10                    -            -        -   \n",
       "                             30                    -            -        -   \n",
       "                             60                    -            -        -   \n",
       "Common Cause                 5                    40         47.0       33   \n",
       "                             10                    -            -        -   \n",
       "                             30                    -            -        -   \n",
       "                             60                    -            -        -   \n",
       "Common Effect                5                    33         40.0       33   \n",
       "                             10                    -            -        -   \n",
       "                             30                    -            -        -   \n",
       "                             60                    -            -        -   \n",
       "Dependency                   5                    37         47.0       38   \n",
       "                             10                    -            -        -   \n",
       "                             30                    -            -        -   \n",
       "                             60                    -            -        -   \n",
       "Evidence Change Relationship 5                    37         53.0       32   \n",
       "                             10                    -            -        -   \n",
       "                             30                    -            -        -   \n",
       "                             60                    -            -        -   \n",
       "Probability                  5                    20          3.0        2   \n",
       "                             10                    -            -        -   \n",
       "                             30                    -            -        -   \n",
       "                             60                    -            -        -   \n",
       "\n",
       "                                              BayMin                        \n",
       "                                         gpt-oss:20b llama3.1:70b qwen3:8b  \n",
       "QuestionType                 NetworkSize                                    \n",
       "Blocked Evidence             5                    83         83.0       48  \n",
       "                             10                   87            -       50  \n",
       "                             30                   87            -       57  \n",
       "                             60                   93            -       80  \n",
       "Common Cause                 5                    93         93.0       95  \n",
       "                             10                  100            -      100  \n",
       "                             30                  100            -       93  \n",
       "                             60                  100            -       87  \n",
       "Common Effect                5                    93         70.0       97  \n",
       "                             10                   90            -       90  \n",
       "                             30                   87            -       90  \n",
       "                             60                   90            -       97  \n",
       "Dependency                   5                    98         63.0       97  \n",
       "                             10                   90            -      100  \n",
       "                             30                   93            -      100  \n",
       "                             60                   90            -      100  \n",
       "Evidence Change Relationship 5                    83         90.0       88  \n",
       "                             10                   80            -       83  \n",
       "                             30                   80            -       90  \n",
       "                             60                   83            -       93  \n",
       "Probability                  5                    95          3.0       55  \n",
       "                             10                   97            -       27  \n",
       "                             30                   90            -       43  \n",
       "                             60                   90            -       33  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def build_performance_table(csv_file_path: str, baymin_csv_file_path: str = None) -> pd.DataFrame:\n",
    "\t\"\"\"\n",
    "\tReturn a DataFrame indexed by (QuestionType, NetworkSize) with grouped column\n",
    "\theaders: top-level framework (Raw, BayMin) and second-level model labels\n",
    "\t(gpt-oss:20b, llama3.1:70b, qwen3:8b). Values are mean percentage scores.\n",
    "\tIncludes all network sizes present for each question type.\n",
    "\tConcatenates main CSV with baymin CSV if provided.\n",
    "\t\"\"\"\n",
    "\tfrom __main__ import MODEL_ORDER, MODEL_LABEL, _pct  # use definitions from earlier cell\n",
    "\n",
    "\t# Load main CSV\n",
    "\tdf = pd.read_csv(csv_file_path)\n",
    "\t\n",
    "\t# Load and concatenate baymin CSV if provided\n",
    "\tif baymin_csv_file_path:\n",
    "\t\tdf_baymin = pd.read_csv(baymin_csv_file_path)\n",
    "\t\tdf = pd.concat([df, df_baymin], ignore_index=True)\n",
    "\n",
    "\t# Aggregate means once\n",
    "\tagg = (\n",
    "\t\tdf.groupby(['question_set_name', 'network_size', 'model'])\n",
    "\t\t.agg(raw_mean=('raw_model_score', 'mean'), baymin_mean=('baymin_score', 'mean'))\n",
    "\t\t.reset_index()\n",
    "\t)\n",
    "\n",
    "\t# Build MultiIndex columns: (Framework, ModelLabel)\n",
    "\ttop = []\n",
    "\tbottom = []\n",
    "\tfor fw in ['Raw', 'BayMin']:\n",
    "\t\tfor m in MODEL_ORDER:\n",
    "\t\t\ttop.append(fw)\n",
    "\t\t\tbottom.append(MODEL_LABEL[m])\n",
    "\tcols = pd.MultiIndex.from_arrays([top, bottom])\n",
    "\n",
    "\trows = []\n",
    "\trow_index = []\n",
    "\tfor q in sorted(agg['question_set_name'].unique().tolist()):\n",
    "\t\tsub = agg[agg['question_set_name'] == q]\n",
    "\t\t# Include all network sizes that exist in the data for this question type\n",
    "\t\tavailable_sizes = sorted(sub['network_size'].unique().tolist())\n",
    "\t\tfor ns in available_sizes:\n",
    "\t\t\trow_vals = []\n",
    "\t\t\t# Raw values (in model order)\n",
    "\t\t\tfor m in MODEL_ORDER:\n",
    "\t\t\t\tval = sub[(sub['network_size'] == ns) & (sub['model'] == m)]['raw_mean']\n",
    "\t\t\t\trow_vals.append(_pct(val.values) if len(val) else None)\n",
    "\t\t\t# BayMin values (in model order)\n",
    "\t\t\tfor m in MODEL_ORDER:\n",
    "\t\t\t\tval = sub[(sub['network_size'] == ns) & (sub['model'] == m)]['baymin_mean']\n",
    "\t\t\t\trow_vals.append(_pct(val.values) if len(val) else None)\n",
    "\t\t\trows.append(row_vals)\n",
    "\t\t\trow_index.append((q.replace('_', ' ').title(), ns))\n",
    "\n",
    "\tidx = pd.MultiIndex.from_tuples(row_index, names=['QuestionType', 'NetworkSize'])\n",
    "\ttable = pd.DataFrame(rows, index=idx, columns=cols)\n",
    "\n",
    "\t# Replace NaN values and 0 values with \"-\" for better readability\n",
    "\ttable = table.fillna(\"-\")\n",
    "\ttable = table.replace(0, \"-\")\n",
    "\n",
    "\treturn table\n",
    "\n",
    "\n",
    "def show_performance_table(csv_file_path: str, baymin_csv_file_path: str = None) -> pd.DataFrame:\n",
    "\t\"\"\"Build and display the grouped performance table in the notebook.\"\"\"\n",
    "\ttable = build_performance_table(csv_file_path, baymin_csv_file_path)\n",
    "\tdisplay(table)\n",
    "\treturn table\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "_ = show_performance_table('benchmarking/results/latest/test_log.csv', 'baymin_test_log.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-bn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
