{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cfe2f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QWEN = \"qwen3:1.7b\"\n",
    "GPT_OSS = \"gpt-oss-bn-json\"\n",
    "MODEL = GPT_OSS\n",
    "MODEL_QUIZ = \"qwen2.5:7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ec2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as _random\n",
    "\n",
    "def create_dependency_quiz(net, node1, node2, rng=None):\n",
    "    \"\"\"\n",
    "    Builds two multiple-choice questions about dependency and d-separation, with\n",
    "    randomized answer order. Returns (questions_text, answers_letters).\n",
    "\n",
    "    - answers_letters: list like [\"A\", \"C\"] indicating the correct choice per question\n",
    "    - rng: optional random-like object with .shuffle(list) and .choice(...)\n",
    "    \"\"\"\n",
    "    from bn_helpers.bn_helpers import BnHelper\n",
    "    from bn_helpers.utils import get_path\n",
    "\n",
    "    randomizer = rng or _random\n",
    "\n",
    "    bn_helper = BnHelper(function_name='is_XY_connected')\n",
    "    is_connected = bn_helper.is_XY_connected(net, node1, node2)\n",
    "\n",
    "    # Q1: Is changing evidence of node1 going to change probability of node2?\n",
    "    q1_prompt = f\"1. Is changing the evidence of {node1} going to change the probability of {node2}?\"\n",
    "    q1_options = [\n",
    "        (\"Yes\", is_connected),\n",
    "        (\"No\", not is_connected),\n",
    "        (\"None of the above\", False),\n",
    "    ]\n",
    "    randomizer.shuffle(q1_options)\n",
    "    q1_lines = [q1_prompt]\n",
    "    q1_correct_letter = None\n",
    "    for idx, (text, correct) in enumerate(q1_options):\n",
    "        letter = chr(65 + idx)  # A, B, C\n",
    "        q1_lines.append(f\"{letter}. {text}\")\n",
    "        if correct:\n",
    "            q1_correct_letter = letter\n",
    "\n",
    "    # Q2: d-connected or d-separated explanation\n",
    "    if is_connected:\n",
    "        option_texts = [\n",
    "            (f\"They are d-connected through the path {get_path(net, node1, node2)}\", True),\n",
    "            (\"They are not d-connected\", False),\n",
    "            (\"None of the above\", False),\n",
    "        ]\n",
    "        q2_header = \"2. Why they are d-connected?\"\n",
    "    else:\n",
    "        common_effect = bn_helper.get_common_effect(net, node1, node2)\n",
    "        because_text = (\n",
    "            f\"They are d-separated because they are blocked by {common_effect}\"\n",
    "            if common_effect\n",
    "            else f\"There are no path between {node1} and {node2}\"\n",
    "        )\n",
    "        option_texts = [\n",
    "            (because_text, True),\n",
    "            (\"They are not d-separated\", False),\n",
    "            (\"None of the above\", False),\n",
    "        ]\n",
    "        q2_header = \"2. Why they are d-separated?\"\n",
    "\n",
    "    randomizer.shuffle(option_texts)\n",
    "    q2_lines = [\"\", q2_header]  # blank line between Q1 and Q2\n",
    "    q2_correct_letter = None\n",
    "    for idx, (text, correct) in enumerate(option_texts):\n",
    "        letter = chr(65 + idx)\n",
    "        q2_lines.append(f\"{letter}. {text}\")\n",
    "        if correct:\n",
    "            q2_correct_letter = letter\n",
    "\n",
    "    questions = \"\\n\".join(q1_lines + q2_lines)\n",
    "    answers = [q1_correct_letter, q2_correct_letter]\n",
    "\n",
    "    return questions, answers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d28cd9",
   "metadata": {},
   "source": [
    "# Build Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2384f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Netica\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bni_netica.bni_netica import Net\n",
    "from benchmarking.data_generator import build_random_bn\n",
    "from bn_helpers.get_structures_print_tools import get_nets, printNet, get_BN_structure, printPath\n",
    "from benchmarking.data_utils import save_nets_to_parquet, load_nets_from_parquet\n",
    "from benchmarking.benchmarking_utils import pickTwoRandomNodes\n",
    "from bn_helpers.bn_helpers import AnswerStructure, BnHelper\n",
    "from ollama.prompt import answer_this_prompt, generate_chat\n",
    "from bn_helpers.utils import get_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3aee397",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./nets/outputs/\"\n",
    "\n",
    "# net3 = build_random_bn(\n",
    "#     n_nodes=12,\n",
    "#     name=\"SkewBN\",\n",
    "#     cpt_mode=\"random\",\n",
    "#     dirichlet_alpha=0.3,     # spiky rows\n",
    "#     avg_edges_per_node=1.4,\n",
    "#     max_in_degree=2,\n",
    "#     sprinkle_motifs=5,\n",
    "#     # save_path=output_path\n",
    "# )\n",
    "\n",
    "# printNet(net3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc0372",
   "metadata": {},
   "source": [
    "## Test the boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "445e24d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net2 = build_random_bn(\n",
    "#     n_nodes=60,\n",
    "#     name=\"MaxRandomBN\",\n",
    "#     cpt_mode=\"random\",\n",
    "#     avg_edges_per_node=5,\n",
    "#     max_in_degree=5,\n",
    "#     sprinkle_motifs=5,\n",
    "#     # save_path=output_path\n",
    "# )\n",
    "\n",
    "# printNet(net2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f6ee85",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f03f6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A -> ['B', 'C']\n",
      "B -> ['D']\n",
      "C -> ['D', 'E']\n",
      "D -> []\n",
      "E -> []\n",
      "\n",
      "VisitAsia -> ['Tuberculosis']\n",
      "Tuberculosis -> ['TbOrCa']\n",
      "Smoking -> ['Cancer', 'Bronchitis']\n",
      "Cancer -> ['TbOrCa']\n",
      "TbOrCa -> ['XRay', 'Dyspnea']\n",
      "XRay -> []\n",
      "Bronchitis -> ['Dyspnea']\n",
      "Dyspnea -> []\n",
      "\n",
      "Class -> ['Obsv', 'Result']\n",
      "Obsv -> ['Classifier']\n",
      "Classifier -> ['Result']\n",
      "Result -> []\n",
      "\n",
      "Sex -> ['Smoking_status', 'LVH', 'Coronary_artery_disease']\n",
      "Smoking_status -> ['Coronary_artery_disease']\n",
      "Systolic_Blood_Pressure -> ['LVH', 'Coronary_artery_disease']\n",
      "Age -> ['LVH', 'Coronary_artery_disease']\n",
      "LVH -> ['Coronary_artery_disease']\n",
      "Diabetes_mellitus -> ['Coronary_artery_disease']\n",
      "Total_chol -> ['Coronary_artery_disease']\n",
      "HDL_Status -> ['Coronary_artery_disease']\n",
      "Coronary_artery_disease -> []\n",
      "\n",
      "Tampering -> ['Alarm']\n",
      "Fire -> ['Alarm', 'Smoke']\n",
      "Alarm -> ['Leaving']\n",
      "Leaving -> ['Report']\n",
      "Smoke -> []\n",
      "Report -> []\n",
      "\n",
      "P1 -> ['C', 'Color_P1']\n",
      "P2 -> ['C', 'Color_P2']\n",
      "C -> ['Color_C']\n",
      "Color_P1 -> []\n",
      "Color_C -> []\n",
      "Color_P2 -> []\n",
      "\n",
      "Ecstazine -> ['Neurofill', 'Social_Activity']\n",
      "Neurofill -> ['Social_Activity']\n",
      "Social_Activity -> ['Squeaking']\n",
      "Squeaking -> []\n",
      "\n",
      "Rain -> ['Sprinkler', 'Grass', 'Wall', 'NeighGrass']\n",
      "Sprinkler -> ['Grass', 'Wall']\n",
      "Grass -> []\n",
      "Wall -> []\n",
      "NeighGrass -> []\n",
      "\n",
      "Ecstazine -> ['Neurofill', 'Social_Activity']\n",
      "Neurofill -> ['Social_Activity']\n",
      "Social_Activity -> ['Squeaking']\n",
      "Squeaking -> []\n",
      "\n",
      "Podunk_Beach -> ['Dunkalot_Sunscreen', 'Jumbos_Ice_Cream', 'Dermascare']\n",
      "Dunkalot_Sunscreen -> ['Dermascare']\n",
      "Jumbos_Ice_Cream -> []\n",
      "Dermascare -> ['Peeling', 'Bruising']\n",
      "Mutation -> ['Peeling']\n",
      "Peeling -> []\n",
      "Bruising -> []\n",
      "\n",
      "Z -> ['X', 'Y']\n",
      "X -> ['A']\n",
      "Y -> ['E']\n",
      "A -> ['B']\n",
      "E -> ['D']\n",
      "B -> ['C']\n",
      "D -> ['C']\n",
      "C -> []\n",
      "\n",
      "Rainfall -> ['TreeCond', 'PesticideInRiver', 'RiverFlow']\n",
      "Drought -> ['TreeCond', 'RiverFlow']\n",
      "TreeCond -> []\n",
      "PesticideUse -> ['PesticideInRiver']\n",
      "PesticideInRiver -> ['FishAbundance']\n",
      "RiverFlow -> ['FishAbundance']\n",
      "FishAbundance -> []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import all nets from the collection\n",
    "nets_collection = get_nets()\n",
    "\n",
    "# print all nets\n",
    "for net in nets_collection:\n",
    "    printNet(net)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b7c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output = \"./benchmarking/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "236a85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate 500 random nets\n",
    "# nets = nets_collection + \\\n",
    "# [ \n",
    "#     build_random_bn(n_nodes=i,\n",
    "#         cpt_mode=\"random\",\n",
    "#         avg_edges_per_node=2,\n",
    "#         max_in_degree=2,\n",
    "#         sprinkle_motifs=5\n",
    "#     )\n",
    "#     for i in range(3,800)\n",
    "# ]\n",
    "\n",
    "# # Save them\n",
    "# save_nets_to_parquet(nets, os.path.join(data_output, \"nets_dataset_800.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db66183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_NETS = False\n",
    "# Load them back\n",
    "if LOAD_NETS:\n",
    "    loaded_nets = load_nets_from_parquet(os.path.join(data_output, \"nets_dataset.parquet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54a7a97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for net in loaded_nets[:20]:\n",
    "#   printNet(net)\n",
    "#   print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c7075",
   "metadata": {},
   "source": [
    "# Benchmark simple Query: Is D-connected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97bda069",
   "metadata": {},
   "outputs": [],
   "source": [
    "nets_collection = get_nets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5ed0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explain_XY_dconnected(net, node1, node2):\n",
    "    open_path = get_path(net, node1, node2)\n",
    "    ans = (f\"Yes, {node1} is d-connected to {node2}, \"\n",
    "          f\"which means that entering evidence for {node1} would \"\n",
    "          f\"change the probability of {node2} and vice versa. They d-connected through the following path: {open_path}\")\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1d5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rainfall -> ['TreeCond', 'PesticideInRiver', 'RiverFlow']\n",
      "Drought -> ['TreeCond', 'RiverFlow']\n",
      "TreeCond -> []\n",
      "PesticideUse -> ['PesticideInRiver']\n",
      "PesticideInRiver -> ['FishAbundance']\n",
      "RiverFlow -> ['FishAbundance']\n",
      "FishAbundance -> []\n",
      "True\n",
      "Yes, B is d-connected to C, which means that entering evidence for B would change the probability of C and vice versa. They d-connected through the following path: ['B', 'A', 'C']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "printNet(nets_collection[-1])\n",
    "targetNet = nets_collection[0]\n",
    "targetBN = get_BN_structure(targetNet)\n",
    "\n",
    "node1 = \"B\"\n",
    "node2 = \"C\"\n",
    "\n",
    "bn_helper = BnHelper(function_name='is_XY_connected')\n",
    "\n",
    "ans = bn_helper.is_XY_connected(targetNet, node1, node2)\n",
    "print(ans)\n",
    "\n",
    "dcon_template = get_explain_XY_dconnected(targetNet, node1, node2)\n",
    "print(dcon_template)\n",
    "\n",
    "prompt = f\"In this Bayesian Network:\\n{targetBN}\\n\"\n",
    "prompt += f\"Is changing the evidence of {node1} going to change the probability of {node2}?\"\n",
    "prompt += f\"Answer exactly as this template: {dcon_template}\"\n",
    "\n",
    "# result = answer_this_prompt(prompt, format=AnswerStructure.model_json_schema(), model=MODEL)\n",
    "# print(result)\n",
    "\n",
    "# y = get_ground_truth(targetNet, node1, node2)\n",
    "# print('y:\\n', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63938fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explain_XY_dseperated(net, node1, node2):\n",
    "  import random\n",
    "  # no nodes observed\n",
    "  bn_helper = BnHelper(function_name=\"get_common_effect\")\n",
    "  blocked_nodes = bn_helper.get_common_effect(net, node1, node2)\n",
    "\n",
    "  random_blocked_node = None\n",
    "  # get one randome node in blocked_nodes\n",
    "  if len(blocked_nodes) > 0:\n",
    "    random_blocked_node = random.choice(list(blocked_nodes))\n",
    "\n",
    "  ans = (f\"No, {node1} is not d-connected to {node2}, \"\n",
    "  f\"which means that entering evidence for {node1} would not \"\n",
    "  f\"change the probability of {node2}.\")\n",
    "\n",
    "  if random_blocked_node is not None:\n",
    "    ans += f\" They are blocked by {random_blocked_node} due to common effect.\"\n",
    "  else:\n",
    "    ans += f\" There are no path between {node1} and {node2}.\"\n",
    "\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6d83279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printNet(nets_collection[-1])\n",
    "# targetNet = nets_collection[-1]\n",
    "# targetBN = get_BN_structure(targetNet)\n",
    "\n",
    "# node1 = \"PesticideUse\"\n",
    "# node2 = \"Rainfall\"\n",
    "\n",
    "# dsep_template = get_explain_XY_dseperated(targetNet, node1, node2)\n",
    "\n",
    "# prompt = f\"In this Bayesian Network:\\n{targetBN}\\n\"\n",
    "# prompt += f\"Is changing the evidence of {node1} going to change the probability of {node2}?\"\n",
    "# prompt += f\"Answer exactly as this template: {dsep_template}\"\n",
    "\n",
    "# result = answer_this_prompt(prompt, format=AnswerStructure.model_json_schema(), model=MODEL)\n",
    "# print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6742dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ValidateScore(BaseModel):\n",
    "    score: int\n",
    "\n",
    "# def create_dependency_quiz(net, node1, node2):\n",
    "#     bn_helper = BnHelper(function_name='is_XY_connected')\n",
    "#     is_connected = bn_helper.is_XY_connected(net, node1, node2)\n",
    "\n",
    "#     q1 = f\"1. Is changing the evidence of {node1} going to change the probability of {node2}?\\n\"\n",
    "#     q1 += f\"A. Yes\\n\"\n",
    "#     q1 += f\"B. No\\n\"\n",
    "#     q1 += f\"C. I don't know\\n\"\n",
    "\n",
    "#     q2 = \"\"\n",
    "#     if is_connected:\n",
    "#         q2 = f\"2. Why they are d-connected?\\n\"\n",
    "#         q2 += f\"A. They are d-connected through the path {get_path(net, node1, node2)}\\n\"\n",
    "#         q2 += f\"B. They are not d-connected\\n\"\n",
    "#         q2 += f\"C. Answer is not listed\\n\"\n",
    "#     else:\n",
    "#         q2 = f\"2. Why they are d-separated?\\n\"\n",
    "#         if bn_helper.get_common_effect(net, node1, node2):\n",
    "#             q2 += f\"A. They are d-separated because they are blocked by {bn_helper.get_common_effect(net, node1, node2)}\\n\"\n",
    "#         else:\n",
    "#             q2 += f\"A. There are no path between {node1} and {node2}\\n\"\n",
    "#         q2 += f\"B. They are not d-separated\\n\"\n",
    "#         q2 += f\"C. Answer is not listed\\n\"\n",
    "\n",
    "#     ans_q1 = \"A\" if is_connected else \"B\"\n",
    "#     ans_q2 = \"A\" \n",
    "#     questions = q1 + \"\\n\" + q2\n",
    "#     answers = [ans_q1, ans_q2]\n",
    "\n",
    "#     return questions, answers\n",
    "    \n",
    "\n",
    "def get_ground_truth(net, node1, node2):\n",
    "    bn_helper = BnHelper(function_name='is_XY_connected')\n",
    "\n",
    "    ans = bn_helper.is_XY_connected(net, node1, node2)\n",
    "    if ans:\n",
    "        template = get_explain_XY_dconnected(net, node1, node2)\n",
    "    else:\n",
    "        template = get_explain_XY_dseperated(net, node1, node2)\n",
    "\n",
    "    return template\n",
    "\n",
    "TAKE_QUIZ_PROMPT = \"\"\"Use the provided Explanation to answer the following quiz.\n",
    "\n",
    "Quiz:\n",
    "\n",
    "{quiz}\n",
    "\n",
    "Explanation:\n",
    "\n",
    "{bn_explanation}\n",
    "\n",
    "You must respond with just a list of 2 answers and no additional text, for example:\n",
    "\n",
    "[A, A]\n",
    "\"\"\"\n",
    "\n",
    "def model_do_quiz(quiz, bn_explanation):\n",
    "    prompt = TAKE_QUIZ_PROMPT.format(quiz=quiz, bn_explanation=bn_explanation)\n",
    "    # print('MODEL QUIZ:', MODEL_QUIZ)\n",
    "    # print('prompt:\\n', prompt)\n",
    "    res_str = answer_this_prompt(prompt, format=AnswerStructure.model_json_schema(), model='qwen2.5:7b')\n",
    "    get_res = AnswerStructure.model_validate_json(res_str)\n",
    "    res = get_res.answer\n",
    "    # res = generate_chat(prompt, model=MODEL_QUIZ, model=\"qwen2.5:7b\", num_predict=5)\n",
    "    # print('res:\\n', res)\n",
    "    ans = res.strip(\"[]\").split(\", \")\n",
    "    # print('ans:\\n', ans)\n",
    "    return ans\n",
    "\n",
    "def validate_quiz_answer(y_list, y_hat_list):\n",
    "    score = 0\n",
    "    for y, y_hat in zip(y_list, y_hat_list):\n",
    "        if y == y_hat:\n",
    "            score += 1\n",
    "    return score / len(y_list)\n",
    "\n",
    "def get_validation_score(y, y_hat):\n",
    "    validation_prompt = f\"\"\"\n",
    "    Best explanation: {y}\n",
    "    LLM explanation: {y_hat}\n",
    "    Compare the LLM explanation with the best explanation in terms of correctness and details, rate the LLM explanation in the scale of 0 to 100.\n",
    "    \"\"\"\n",
    "\n",
    "    validate_score = answer_this_prompt(validation_prompt, format=ValidateScore.model_json_schema())\n",
    "    validate_score = ValidateScore.model_validate_json(validate_score)\n",
    "\n",
    "    print('validation_prompt:\\n', validation_prompt)\n",
    "    print('validate_score:\\n', validate_score)\n",
    "    return validate_score.score\n",
    "\n",
    "# def output_score_raw_model(net):\n",
    "#     node1, node2 = pickTwoRandomNodes(net)\n",
    "#     y = get_ground_truth(net, node1, node2)\n",
    "#     # print('Two random nodes:', node1, node2)\n",
    "\n",
    "#     bn = get_BN_structure(net)\n",
    "#     prompt = f\"In this Bayesian Network:\\n{bn}\\n\"\n",
    "#     prompt += f\"Is changing the evidence of {node1} going to change the probability of {node2}? Why?\"\n",
    "\n",
    "#     ans = answer_this_prompt(prompt, format=AnswerStructure.model_json_schema())\n",
    "#     y_hat = AnswerStructure.model_validate_json(ans)\n",
    "#     # print('y_hat:\\n', y_hat)\n",
    "\n",
    "#     return get_validation_score(y, y_hat)\n",
    "def output_score_raw_model(net):\n",
    "    node1, node2 = pickTwoRandomNodes(net)\n",
    "    # y = get_ground_truth(net, node1, node2)\n",
    "    # print('Two random nodes:', node1, node2)\n",
    "\n",
    "    bn = get_BN_structure(net)\n",
    "    prompt = f\"In this Bayesian Network:\\n{bn}\\n\"\n",
    "    prompt += f\"Is changing the evidence of {node1} going to change the probability of {node2}? Why?\"\n",
    "\n",
    "    ans = answer_this_prompt(prompt, format=AnswerStructure.model_json_schema(), model=MODEL)\n",
    "    validated_ans = AnswerStructure.model_validate_json(ans)\n",
    "    quiz, y_list = create_dependency_quiz(net, node1, node2)\n",
    "    y_hat_list = model_do_quiz(quiz, validated_ans.answer)\n",
    "    \n",
    "    print('Raw Model:')\n",
    "    # print('ans:\\n', ans)\n",
    "    print('y_list:\\n', y_list)\n",
    "    print('y_hat_list:\\n', y_hat_list)\n",
    "    score = validate_quiz_answer(y_list, y_hat_list)\n",
    "    return score\n",
    "\n",
    "\n",
    "def output_score_baymin(net):\n",
    "    node1, node2 = pickTwoRandomNodes(net)\n",
    "    \n",
    "    template = \"\"\n",
    "    bn_helper = BnHelper(function_name=\"is_XY_connected\")\n",
    "\n",
    "    connected = bn_helper.is_XY_connected(net, node1, node2)\n",
    "    if connected:\n",
    "        template = get_explain_XY_dconnected(net, node1, node2)\n",
    "    else:\n",
    "        template = get_explain_XY_dseperated(net, node1, node2)\n",
    "        \n",
    "    bn = get_BN_structure(net)\n",
    "    prompt = f\"In this Bayesian Network:\\n{bn}\\n\"\n",
    "    prompt += f\"Is changing the evidence of {node1} going to change the probability of {node2}? Why? \"\n",
    "    prompt += f\"We run the algorithm to get the answer, and the answer is: '{template}' \"\n",
    "    prompt += f\"If the answer is grammatically correct, return exactly as that answer, otherwise fix the grammar and return the fixed answer.\"\n",
    "    prompt += f\"Do not check the answer's correctness. Just check the answer's grammar, fix only the grammar if necessary, and return the answer.\"\n",
    "\n",
    "    ans = answer_this_prompt(prompt, format=AnswerStructure.model_json_schema(), model=MODEL)\n",
    "    validated_ans = AnswerStructure.model_validate_json(ans)\n",
    "    quiz, y_list = create_dependency_quiz(net, node1, node2)\n",
    "    y_hat_list = model_do_quiz(quiz, validated_ans.answer)\n",
    "    \n",
    "    print('Baymin Model:')\n",
    "    print('y_list:\\n', y_list)\n",
    "    print('y_hat_list:\\n', y_hat_list)\n",
    "    score = validate_quiz_answer(y_list, y_hat_list)\n",
    "    return score\n",
    "\n",
    "# print(output_score_raw_model(loaded_nets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a72b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def output_score_baymin(net):\n",
    "#     node1, node2 = pickTwoRandomNodes(net)\n",
    "#     # print(node1, node2)\n",
    "#     # print('Two random nodes:', node1, node2)\n",
    "\n",
    "#     y = get_ground_truth(net, node1, node2)\n",
    "#     # print('y:\\n', y)\n",
    "\n",
    "#     template = \"\"\n",
    "#     bn_helper = BnHelper(function_name=\"is_XY_connected\")\n",
    "\n",
    "#     connected = bn_helper.is_XY_connected(net, node1, node2)\n",
    "#     if connected:\n",
    "#         template = get_explain_XY_dconnected(net, node1, node2)\n",
    "#     else:\n",
    "#         template = get_explain_XY_dseperated(net, node1, node2)\n",
    "\n",
    "#     bn = get_BN_structure(net)\n",
    "#     prompt = f\"In this Bayesian Network:\\n{bn}\\n\"\n",
    "#     prompt += f\"Is changing the evidence of {node1} going to change the probability of {node2}? Why? \"\n",
    "#     prompt += f\"We run the algorithm to get the answer, and the answer is: '{template}' \"\n",
    "#     # prompt += f\"If the answer is grammatically correct, return exactly as that answer, otherwise fix the grammar and return the fixed answer.\"\n",
    "#     prompt += f\"Do not check the answer's correctness. Just check the answer's grammar, fix only the grammar if necessary, and return the answer.\"\n",
    "#     print(prompt)\n",
    "    # y_hat = answer_this_prompt(prompt, format=AnswerStructure.model_json_schema(), model=MODEL)\n",
    "    # print()\n",
    "    # print('y_hat:\\n', y_hat)\n",
    "    # print('---------------------------------------------')\n",
    "    # score = get_validation_score(y, y_hat)\n",
    "    # if score == 0:\n",
    "    #     print('y:\\n', y)\n",
    "    #     print('y_hat:\\n', y_hat)\n",
    "    #     print('---------------------------------------------')\n",
    "    # return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28493a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(answer_this_prompt(prompt, format=AnswerStructure.model_json_schema(), model='qwen3:latest'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92c3d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(output_score_baymin(nets_collection[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a2fc2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 nets from ./benchmarking/data/simple_dataset.parquet\n"
     ]
    }
   ],
   "source": [
    "net_5, net_10, net_30, net_60 = load_nets_from_parquet(os.path.join(data_output, \"simple_dataset.parquet\"))\n",
    "# net_5 = build_random_bn(\n",
    "#     n_nodes=5,\n",
    "#     cpt_mode=\"random\",\n",
    "#     avg_edges_per_node=3,\n",
    "#     max_in_degree=3,\n",
    "#     sprinkle_motifs=5,\n",
    "#     # save_path=output_path\n",
    "# )\n",
    "\n",
    "# print('net_5 done')\n",
    "\n",
    "# net_10 = build_random_bn(\n",
    "#     n_nodes=10,\n",
    "#     cpt_mode=\"random\",\n",
    "#     avg_edges_per_node=6,\n",
    "#     max_in_degree=6,\n",
    "#     sprinkle_motifs=5\n",
    "# )\n",
    "\n",
    "# print('net_10 done')\n",
    "\n",
    "# net_30 = build_random_bn(\n",
    "#     n_nodes=30,\n",
    "#     cpt_mode=\"random\",\n",
    "#     avg_edges_per_node=8,\n",
    "#     max_in_degree=8,\n",
    "#     sprinkle_motifs=5\n",
    "# )\n",
    "\n",
    "# print('net_30 done')\n",
    "\n",
    "# net_60 = build_random_bn(\n",
    "#     n_nodes=60,\n",
    "#     cpt_mode=\"random\",\n",
    "#     avg_edges_per_node=6,\n",
    "#     max_in_degree=6,\n",
    "#     sprinkle_motifs=3\n",
    "# )\n",
    "\n",
    "# print('net_60 done')\n",
    "\n",
    "# simple_nets = [net_5, net_10, net_30, net_60]\n",
    "# save_nets_to_parquet(simple_nets, os.path.join(data_output, \"simple_dataset.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6abfb158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_5, Raw Model\n",
      "Raw Model:\n",
      "y_list:\n",
      " ['B', 'A']\n",
      "y_hat_list:\n",
      " ['B', 'B']\n",
      "score 1: 0.5\n",
      "---------------\n",
      "Raw Model:\n",
      "y_list:\n",
      " ['B', 'B']\n",
      "y_hat_list:\n",
      " ['B', 'B']\n",
      "score 2: 1.5\n",
      "---------------\n",
      "Raw Model:\n",
      "y_list:\n",
      " ['A', 'B']\n",
      "y_hat_list:\n",
      " ['A', 'B']\n",
      "score 3: 2.5\n",
      "---------------\n",
      "Raw Model:\n",
      "y_list:\n",
      " ['C', 'A']\n",
      "y_hat_list:\n",
      " ['C', 'C']\n",
      "score 4: 3.0\n",
      "---------------\n",
      "Raw Model:\n",
      "y_list:\n",
      " ['A', 'C']\n",
      "y_hat_list:\n",
      " ['A', 'C']\n",
      "score 5: 4.0\n",
      "---------------\n",
      "Raw Model:\n",
      "y_list:\n",
      " ['C', 'B']\n",
      "y_hat_list:\n",
      " ['B', 'B']\n",
      "score 6: 4.5\n",
      "---------------\n",
      "Raw Model:\n",
      "y_list:\n",
      " ['C', 'A']\n",
      "y_hat_list:\n",
      " ['C', 'A']\n",
      "score 7: 5.5\n",
      "---------------\n",
      "Raw Model:\n",
      "y_list:\n",
      " ['B', 'C']\n",
      "y_hat_list:\n",
      " ['C', 'C']\n",
      "score 8: 6.0\n",
      "---------------\n",
      "Raw Model:\n",
      "y_list:\n",
      " ['B', 'C']\n",
      "y_hat_list:\n",
      " ['C', 'C']\n",
      "score 9: 6.5\n",
      "---------------\n",
      "Raw Model:\n",
      "y_list:\n",
      " ['C', 'B']\n",
      "y_hat_list:\n",
      " ['B', 'B']\n",
      "score 10: 7.0\n",
      "---------------\n",
      "Raw Model:\n",
      "y_list:\n",
      " ['C', 'C']\n",
      "y_hat_list:\n",
      " ['B', 'C']\n",
      "score 11: 7.5\n",
      "---------------\n",
      "Raw Model:\n",
      "y_list:\n",
      " ['C', 'C']\n",
      "y_hat_list:\n",
      " ['C', 'C']\n",
      "score 12: 8.5\n",
      "---------------\n",
      "Raw Model:\n",
      "y_list:\n",
      " ['B', 'A']\n",
      "y_hat_list:\n",
      " ['B', 'A']\n",
      "score 13: 9.5\n",
      "---------------\n",
      "Raw Model:\n",
      "y_list:\n",
      " ['B', 'A']\n",
      "y_hat_list:\n",
      " ['B', 'A']\n",
      "score 14: 10.5\n",
      "---------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m result = {}\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mNet_5, Raw Model\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m raw_net_5_score = \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_score_raw_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m result[\u001b[33m'\u001b[39m\u001b[33mraw_net_5_score\u001b[39m\u001b[33m'\u001b[39m] = raw_net_5_score\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mNet_10, Raw Model\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtest_model\u001b[39m\u001b[34m(net, get_score_func)\u001b[39m\n\u001b[32m      3\u001b[39m total_score = \u001b[32m0\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(RANGE):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m   score = \u001b[43mget_score_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m   total_score += score\n\u001b[32m      7\u001b[39m   \u001b[38;5;66;03m# if i % 5 == 0:\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 124\u001b[39m, in \u001b[36moutput_score_raw_model\u001b[39m\u001b[34m(net)\u001b[39m\n\u001b[32m    122\u001b[39m validated_ans = AnswerStructure.model_validate_json(ans)\n\u001b[32m    123\u001b[39m quiz, y_list = create_dependency_quiz(net, node1, node2)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m y_hat_list = \u001b[43mmodel_do_quiz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquiz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidated_ans\u001b[49m\u001b[43m.\u001b[49m\u001b[43manswer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mRaw Model:\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# print('ans:\\n', ans)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mmodel_do_quiz\u001b[39m\u001b[34m(quiz, bn_explanation)\u001b[39m\n\u001b[32m     65\u001b[39m prompt = TAKE_QUIZ_PROMPT.format(quiz=quiz, bn_explanation=bn_explanation)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# print('MODEL QUIZ:', MODEL_QUIZ)\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# print('prompt:\\n', prompt)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m res_str = \u001b[43manswer_this_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mAnswerStructure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_json_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mqwen2.5:7b\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m get_res = AnswerStructure.model_validate_json(res_str)\n\u001b[32m     70\u001b[39m res = get_res.answer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/fs04/scratch2/lb64/projects/llm-bn/ollama/prompt.py:21\u001b[39m, in \u001b[36manswer_this_prompt\u001b[39m\u001b[34m(prompt, stream, model, temperature, format)\u001b[39m\n\u001b[32m     18\u001b[39m endpoint = \u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:11434/api/generate\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Send the POST request with streaming enabled\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m     23\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     24\u001b[39m             \u001b[38;5;66;03m# Process the response incrementally\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages/requests/api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "RANGE = 30\n",
    "def test_model(net, get_score_func):\n",
    "  total_score = 0\n",
    "  for i in range(RANGE):\n",
    "    score = get_score_func(net)\n",
    "    total_score += score\n",
    "    # if i % 5 == 0:\n",
    "    print(f\"score {i+1}: {total_score}\")\n",
    "    print('---------------')\n",
    "      \n",
    "  avg_score = total_score / RANGE\n",
    "  return avg_score\n",
    "\n",
    "result = {}\n",
    "print('Net_5, Raw Model')\n",
    "raw_net_5_score = test_model(net_5, output_score_raw_model)\n",
    "result['raw_net_5_score'] = raw_net_5_score\n",
    "\n",
    "print('Net_10, Raw Model')\n",
    "raw_net_10_score = test_model(net_10, output_score_raw_model)\n",
    "result['raw_net_10_score'] = raw_net_10_score\n",
    "\n",
    "print('Net_30, Raw Model')\n",
    "raw_net_30_score = test_model(net_30, output_score_raw_model)\n",
    "result['raw_net_30_score'] = raw_net_30_score\n",
    "\n",
    "print('Net_60, Raw Model')\n",
    "raw_net_60_score = test_model(net_60, output_score_raw_model)\n",
    "result['raw_net_60_score'] = raw_net_60_score\n",
    "\n",
    "print('Net_5, Baymin')\n",
    "baymin_net_5_score = test_model(net_5, output_score_baymin)\n",
    "result['baymin_net_5_score'] = baymin_net_5_score\n",
    "\n",
    "print()\n",
    "print('Net_10, Baymin')\n",
    "baymin_net_10_score = test_model(net_10, output_score_baymin)\n",
    "result['baymin_net_10_score'] = baymin_net_10_score\n",
    "\n",
    "print()\n",
    "print('Net_30, Baymin')\n",
    "baymin_net_30_score = test_model(net_30, output_score_baymin)\n",
    "result['baymin_net_30_score'] = baymin_net_30_score\n",
    "\n",
    "print()\n",
    "print('Net_60, Baymin')\n",
    "baymin_net_60_score = test_model(net_60, output_score_baymin)\n",
    "result['baymin_net_60_score'] = baymin_net_60_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e4864a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'raw_net_5_score': 0.5, 'baymin_net_5_score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57915b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_comparison(result):\n",
    "    sizes = [5, 10, 30, 60]\n",
    "    raw_scores = [\n",
    "        result['raw_net_5_score'],\n",
    "        result['raw_net_10_score'],\n",
    "        result['raw_net_30_score'],\n",
    "        result['raw_net_60_score']\n",
    "    ]\n",
    "    baymin_scores = [\n",
    "        result['baymin_net_5_score'],\n",
    "        result['baymin_net_10_score'],\n",
    "        result['baymin_net_30_score'],\n",
    "        result['baymin_net_60_score']\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(sizes, raw_scores, marker='o', label=\"Raw Model\")\n",
    "    plt.plot(sizes, baymin_scores, marker='s', label=\"Baymin Model\")\n",
    "\n",
    "    plt.title(\"Model Comparison by Network Size\")\n",
    "    plt.xlabel(\"Network Size\")\n",
    "    plt.ylabel(\"Average Score\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4312b721",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (4,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplot_model_comparison\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mplot_model_comparison\u001b[39m\u001b[34m(result)\u001b[39m\n\u001b[32m     11\u001b[39m baymin_scores = [\n\u001b[32m     12\u001b[39m     result[\u001b[33m'\u001b[39m\u001b[33mbaymin_net_5_score\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# result['baymin_net_10_score'],\u001b[39;00m\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# result['baymin_net_30_score'],\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# result['baymin_net_60_score']\u001b[39;00m\n\u001b[32m     16\u001b[39m ]\n\u001b[32m     18\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43msizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mo\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRaw Model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m plt.plot(sizes, baymin_scores, marker=\u001b[33m'\u001b[39m\u001b[33ms\u001b[39m\u001b[33m'\u001b[39m, label=\u001b[33m\"\u001b[39m\u001b[33mBaymin Model\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mModel Comparison by Network Size\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages/matplotlib/pyplot.py:3838\u001b[39m, in \u001b[36mplot\u001b[39m\u001b[34m(scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   3830\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.plot)\n\u001b[32m   3831\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot\u001b[39m(\n\u001b[32m   3832\u001b[39m     *args: \u001b[38;5;28mfloat\u001b[39m | ArrayLike | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3836\u001b[39m     **kwargs,\n\u001b[32m   3837\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[32m-> \u001b[39m\u001b[32m3838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3839\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3841\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3842\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3843\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3844\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages/matplotlib/axes/_axes.py:1777\u001b[39m, in \u001b[36mAxes.plot\u001b[39m\u001b[34m(self, scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1534\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1535\u001b[39m \u001b[33;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[32m   1536\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1774\u001b[39m \u001b[33;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1776\u001b[39m kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n\u001b[32m-> \u001b[39m\u001b[32m1777\u001b[39m lines = [*\u001b[38;5;28mself\u001b[39m._get_lines(\u001b[38;5;28mself\u001b[39m, *args, data=data, **kwargs)]\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[32m   1779\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_line(line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages/matplotlib/axes/_base.py:297\u001b[39m, in \u001b[36m_process_plot_var_args.__call__\u001b[39m\u001b[34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m     this += args[\u001b[32m0\u001b[39m],\n\u001b[32m    296\u001b[39m     args = args[\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages/matplotlib/axes/_base.py:494\u001b[39m, in \u001b[36m_process_plot_var_args._plot_args\u001b[39m\u001b[34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[39m\n\u001b[32m    491\u001b[39m     axes.yaxis.update_units(y)\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.shape[\u001b[32m0\u001b[39m] != y.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y must have same first dimension, but \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    495\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.ndim > \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y.ndim > \u001b[32m2\u001b[39m:\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y can be no greater than 2D, but have \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    498\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: x and y must have same first dimension, but have shapes (4,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_comparison(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40cee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Example result dict (from your code above after running test_model)\n",
    "result = {\n",
    "    'raw_net_5_score': 0.82,\n",
    "    'raw_net_10_score': 0.79,\n",
    "    'raw_net_30_score': 0.76,\n",
    "    'raw_net_60_score': 0.75,\n",
    "    'baymin_net_5_score': 0.88,\n",
    "    'baymin_net_10_score': 0.86,\n",
    "    'baymin_net_30_score': 0.84,\n",
    "    'baymin_net_60_score': 0.83,\n",
    "}\n",
    "\n",
    "# Write into CSV\n",
    "with open(\"results.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"model\", \"net_size\", \"score\"])  # header\n",
    "    \n",
    "    for key, score in result.items():\n",
    "        # key format: \"{model}_net_{size}_score\"\n",
    "        parts = key.split(\"_\")\n",
    "        model = parts[0]      # \"raw\" or \"baymin\"\n",
    "        net_size = parts[2]   # \"5\", \"10\", etc.\n",
    "        \n",
    "        writer.writerow([model, net_size, score])\n",
    "\n",
    "print(\"Results written to results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086fd62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-bn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
