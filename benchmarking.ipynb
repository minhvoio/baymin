{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9532af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Netica\n",
      "Loading nets from: /fs04/scratch2/lb64/projects/llm-bn/benchmarking/data\n",
      "Loaded 4 nets from /fs04/scratch2/lb64/projects/llm-bn/benchmarking/data/nets_dataset.parquet\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to Python path so we can import modules from the project root\n",
    "# In Jupyter notebooks, __file__ is not defined, so we use getcwd() and navigate up\n",
    "current_dir = os.getcwd()\n",
    "# If we're in the testing directory, go up one level to get to project root\n",
    "if current_dir.endswith('/testing'):\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "else:\n",
    "    # If we're already in project root, use current directory\n",
    "    project_root = current_dir\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from bn_helpers.get_structures_print_tools import get_nets, printNet\n",
    "from bn_helpers.constants import MODEL, MODEL_QUIZ\n",
    "from benchmarking.question_types import (DEPENDENCY_QUESTIONS, COMMON_CAUSE_QUESTIONS, COMMON_EFFECT_QUESTIONS, BLOCKED_EVIDENCES_QUESTIONS, \n",
    "EVIDENCE_CHANGE_RELATIONSHIP_QUESTIONS, PROBABILITY_QUESTIONS, HIGHEST_IMPACT_EVIDENCE_QUESTIONS)\n",
    "from benchmarking.model_evaluator import (dependency_test, common_cause_test, common_effect_test, blocked_evidence_test, \n",
    "evidence_change_relationship_test, probability_test, highest_impact_evidence_test)\n",
    "from benchmarking.data_utils import load_nets_from_parquet\n",
    "import asyncio\n",
    "\n",
    "data_output = os.path.join(project_root, \"benchmarking\", \"data\")\n",
    "print(f\"Loading nets from: {data_output}\")\n",
    "net_5, net_10, net_30, net_60 = load_nets_from_parquet(os.path.join(data_output, \"nets_dataset.parquet\"))\n",
    "\n",
    "list_of_nets = [net_5, net_10, net_30, net_60]\n",
    "NUM_QUESTIONS = 30\n",
    "MAX_TOKENS = 3000\n",
    "IS_TESTING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f87bf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running dependency test for Net_5 with 5 questions\n",
      "Running question 1\n",
      "[Test] Logged: elementary_test - dependency - Q1\n",
      "Running question 2\n",
      "[Test] Logged: elementary_test - dependency - Q2\n",
      "Running question 3\n",
      "[Test] Logged: elementary_test - dependency - Q3\n",
      "Running question 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m net \u001b[38;5;129;01min\u001b[39;00m list_of_nets:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mdependency_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_questions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_QUESTIONS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMAX_TOKENS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43misTesting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIS_TESTING\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     common_cause_test(net, num_questions=NUM_QUESTIONS, max_tokens=MAX_TOKENS, isTesting=IS_TESTING)\n\u001b[32m      4\u001b[39m     common_effect_test(net, num_questions=NUM_QUESTIONS, max_tokens=MAX_TOKENS, isTesting=IS_TESTING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/fs04/scratch2/lb64/projects/llm-bn/benchmarking/model_evaluator.py:204\u001b[39m, in \u001b[36mdependency_test\u001b[39m\u001b[34m(net, model, model_quiz, max_tokens, num_questions, isTesting)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdependency_test\u001b[39m(net, model=MODEL, model_quiz=MODEL_QUIZ, max_tokens=\u001b[32m1000\u001b[39m, num_questions=\u001b[32m30\u001b[39m, isTesting=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43melementary_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEPENDENCY_QUESTIONS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_dependency_quiz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_quiz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_quiz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_questions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_questions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43misTesting\u001b[49m\u001b[43m=\u001b[49m\u001b[43misTesting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/fs04/scratch2/lb64/projects/llm-bn/benchmarking/model_evaluator.py:165\u001b[39m, in \u001b[36melementary_test\u001b[39m\u001b[34m(net, question_set, create_quiz_function, model, model_quiz, hasEvidence, max_tokens, num_questions, isTesting)\u001b[39m\n\u001b[32m    162\u001b[39m     quiz, y = create_quiz_function(question_output, net, node1, node2)\n\u001b[32m    163\u001b[39m     evidence = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m raw_model_score = \u001b[43mraw_model_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_quiz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_quiz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m baymin_score = baymin_test(net, quiz, y, question_output, model=model, max_tokens=max_tokens, model_quiz=model_quiz, isTesting=isTesting)\n\u001b[32m    167\u001b[39m raw_model_total_score += raw_model_score\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/fs04/scratch2/lb64/projects/llm-bn/benchmarking/model_evaluator.py:108\u001b[39m, in \u001b[36mraw_model_test\u001b[39m\u001b[34m(prompt, quiz, y, model, max_tokens, model_quiz)\u001b[39m\n\u001b[32m    106\u001b[39m loop = asyncio.get_event_loop()\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop.is_running():\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     ans = \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_answer_from_ollama\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    110\u001b[39m     ans = loop.run_until_complete(get_answer_from_ollama(prompt, model=model, max_tokens=max_tokens))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages/nest_asyncio.py:92\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     90\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages/nest_asyncio.py:115\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m     heappop(scheduled)\n\u001b[32m    110\u001b[39m timeout = (\n\u001b[32m    111\u001b[39m     \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[32m    113\u001b[39m         scheduled[\u001b[32m0\u001b[39m]._when - \u001b[38;5;28mself\u001b[39m.time(), \u001b[32m0\u001b[39m), \u001b[32m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._process_events(event_list)\n\u001b[32m    118\u001b[39m end_time = \u001b[38;5;28mself\u001b[39m.time() + \u001b[38;5;28mself\u001b[39m._clock_resolution\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/selectors.py:452\u001b[39m, in \u001b[36mEpollSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    450\u001b[39m ready = []\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for net in list_of_nets:\n",
    "    dependency_test(net, num_questions=NUM_QUESTIONS, max_tokens=MAX_TOKENS, isTesting=IS_TESTING)\n",
    "    common_cause_test(net, num_questions=NUM_QUESTIONS, max_tokens=MAX_TOKENS, isTesting=IS_TESTING)\n",
    "    common_effect_test(net, num_questions=NUM_QUESTIONS, max_tokens=MAX_TOKENS, isTesting=IS_TESTING)\n",
    "    blocked_evidence_test(net, num_questions=NUM_QUESTIONS, max_tokens=MAX_TOKENS, isTesting=IS_TESTING)\n",
    "    evidence_change_relationship_test(net, num_questions=NUM_QUESTIONS, max_tokens=MAX_TOKENS, isTesting=IS_TESTING)\n",
    "    probability_test(net, num_questions=NUM_QUESTIONS, max_tokens=MAX_TOKENS, isTesting=IS_TESTING)\n",
    "    highest_impact_evidence_test(net, num_questions=NUM_QUESTIONS, max_tokens=MAX_TOKENS, isTesting=IS_TESTING)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-bn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
