{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4cc2397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Raw</th>\n",
       "      <th colspan=\"3\" halign=\"left\">BayMin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>gpt-oss:20b</th>\n",
       "      <th>llama3.1:70b</th>\n",
       "      <th>qwen3:8b</th>\n",
       "      <th>gpt-oss:20b</th>\n",
       "      <th>llama3.1:70b</th>\n",
       "      <th>qwen3:8b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuestionType</th>\n",
       "      <th>NetworkSize</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Blocked Evidence</th>\n",
       "      <th>5</th>\n",
       "      <td>23.3 ± 15.1</td>\n",
       "      <td>26.7 ± 15.8</td>\n",
       "      <td>26.7 ± 15.8</td>\n",
       "      <td>76.7 ± 15.1</td>\n",
       "      <td>86.7 ± 12.2</td>\n",
       "      <td>53.3 ± 17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26.7 ± 15.8</td>\n",
       "      <td>20.0 ± 14.3</td>\n",
       "      <td>16.7 ± 13.3</td>\n",
       "      <td>86.7 ± 12.2</td>\n",
       "      <td>86.7 ± 12.2</td>\n",
       "      <td>50.0 ± 17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6.7 ± 8.9</td>\n",
       "      <td>3.3 ± 6.4</td>\n",
       "      <td>13.3 ± 12.2</td>\n",
       "      <td>86.7 ± 12.2</td>\n",
       "      <td>96.7 ± 6.4</td>\n",
       "      <td>56.7 ± 17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>26.7 ± 15.8</td>\n",
       "      <td>10.0 ± 10.7</td>\n",
       "      <td>20.0 ± 14.3</td>\n",
       "      <td>93.3 ± 8.9</td>\n",
       "      <td>93.3 ± 8.9</td>\n",
       "      <td>80.0 ± 14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Common Cause</th>\n",
       "      <th>5</th>\n",
       "      <td>80.0 ± 14.3</td>\n",
       "      <td>46.7 ± 17.9</td>\n",
       "      <td>66.7 ± 16.9</td>\n",
       "      <td>90.0 ± 10.7</td>\n",
       "      <td>86.7 ± 12.2</td>\n",
       "      <td>93.3 ± 8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63.3 ± 17.2</td>\n",
       "      <td>40.0 ± 17.5</td>\n",
       "      <td>46.7 ± 17.9</td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "      <td>93.3 ± 8.9</td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30.0 ± 16.4</td>\n",
       "      <td>20.0 ± 14.3</td>\n",
       "      <td>36.7 ± 17.2</td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "      <td>93.3 ± 8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>26.7 ± 15.8</td>\n",
       "      <td>16.7 ± 13.3</td>\n",
       "      <td>33.3 ± 16.9</td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "      <td>86.7 ± 12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Common Effect</th>\n",
       "      <th>5</th>\n",
       "      <td>66.7 ± 16.9</td>\n",
       "      <td>40.0 ± 17.5</td>\n",
       "      <td>66.7 ± 16.9</td>\n",
       "      <td>93.3 ± 8.9</td>\n",
       "      <td>70.0 ± 16.4</td>\n",
       "      <td>93.3 ± 8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63.3 ± 17.2</td>\n",
       "      <td>33.3 ± 16.9</td>\n",
       "      <td>36.7 ± 17.2</td>\n",
       "      <td>90.0 ± 10.7</td>\n",
       "      <td>80.0 ± 14.3</td>\n",
       "      <td>90.0 ± 10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>50.0 ± 17.9</td>\n",
       "      <td>10.0 ± 10.7</td>\n",
       "      <td>43.3 ± 17.7</td>\n",
       "      <td>86.7 ± 12.2</td>\n",
       "      <td>60.0 ± 17.5</td>\n",
       "      <td>90.0 ± 10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>50.0 ± 17.9</td>\n",
       "      <td>20.0 ± 14.3</td>\n",
       "      <td>23.3 ± 15.1</td>\n",
       "      <td>90.0 ± 10.7</td>\n",
       "      <td>70.0 ± 16.4</td>\n",
       "      <td>96.7 ± 6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Dependency</th>\n",
       "      <th>5</th>\n",
       "      <td>73.3 ± 15.8</td>\n",
       "      <td>46.7 ± 17.9</td>\n",
       "      <td>76.7 ± 15.1</td>\n",
       "      <td>96.7 ± 6.4</td>\n",
       "      <td>90.0 ± 10.7</td>\n",
       "      <td>93.3 ± 8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>70.0 ± 16.4</td>\n",
       "      <td>60.0 ± 17.5</td>\n",
       "      <td>60.0 ± 17.5</td>\n",
       "      <td>90.0 ± 10.7</td>\n",
       "      <td>93.3 ± 8.9</td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>36.7 ± 17.2</td>\n",
       "      <td>20.0 ± 14.3</td>\n",
       "      <td>26.7 ± 15.8</td>\n",
       "      <td>93.3 ± 8.9</td>\n",
       "      <td>90.0 ± 10.7</td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>33.3 ± 16.9</td>\n",
       "      <td>40.0 ± 17.5</td>\n",
       "      <td>36.7 ± 17.2</td>\n",
       "      <td>90.0 ± 10.7</td>\n",
       "      <td>86.7 ± 12.2</td>\n",
       "      <td>100.0 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Evidence Change Relationship</th>\n",
       "      <th>5</th>\n",
       "      <td>73.3 ± 15.8</td>\n",
       "      <td>53.3 ± 17.9</td>\n",
       "      <td>63.3 ± 17.2</td>\n",
       "      <td>86.7 ± 12.2</td>\n",
       "      <td>90.0 ± 10.7</td>\n",
       "      <td>80.0 ± 14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>66.7 ± 16.9</td>\n",
       "      <td>43.3 ± 17.7</td>\n",
       "      <td>46.7 ± 17.9</td>\n",
       "      <td>80.0 ± 14.3</td>\n",
       "      <td>96.7 ± 6.4</td>\n",
       "      <td>83.3 ± 13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>50.0 ± 17.9</td>\n",
       "      <td>30.0 ± 16.4</td>\n",
       "      <td>40.0 ± 17.5</td>\n",
       "      <td>80.0 ± 14.3</td>\n",
       "      <td>73.3 ± 15.8</td>\n",
       "      <td>90.0 ± 10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>36.7 ± 17.2</td>\n",
       "      <td>56.7 ± 17.7</td>\n",
       "      <td>26.7 ± 15.8</td>\n",
       "      <td>83.3 ± 13.3</td>\n",
       "      <td>46.7 ± 17.9</td>\n",
       "      <td>93.3 ± 8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Probability</th>\n",
       "      <th>5</th>\n",
       "      <td>40.0 ± 17.5</td>\n",
       "      <td>3.3 ± 6.4</td>\n",
       "      <td>3.3 ± 6.4</td>\n",
       "      <td>93.3 ± 8.9</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>60.0 ± 17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.3 ± 6.4</td>\n",
       "      <td>3.3 ± 6.4</td>\n",
       "      <td>3.3 ± 6.4</td>\n",
       "      <td>96.7 ± 6.4</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>26.7 ± 15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.3 ± 6.4</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>90.0 ± 10.7</td>\n",
       "      <td>3.3 ± 6.4</td>\n",
       "      <td>43.3 ± 17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3.3 ± 6.4</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>90.0 ± 10.7</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>33.3 ± 16.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Raw               \\\n",
       "                                          gpt-oss:20b llama3.1:70b   \n",
       "QuestionType                 NetworkSize                             \n",
       "Blocked Evidence             5            23.3 ± 15.1  26.7 ± 15.8   \n",
       "                             10           26.7 ± 15.8  20.0 ± 14.3   \n",
       "                             30             6.7 ± 8.9    3.3 ± 6.4   \n",
       "                             60           26.7 ± 15.8  10.0 ± 10.7   \n",
       "Common Cause                 5            80.0 ± 14.3  46.7 ± 17.9   \n",
       "                             10           63.3 ± 17.2  40.0 ± 17.5   \n",
       "                             30           30.0 ± 16.4  20.0 ± 14.3   \n",
       "                             60           26.7 ± 15.8  16.7 ± 13.3   \n",
       "Common Effect                5            66.7 ± 16.9  40.0 ± 17.5   \n",
       "                             10           63.3 ± 17.2  33.3 ± 16.9   \n",
       "                             30           50.0 ± 17.9  10.0 ± 10.7   \n",
       "                             60           50.0 ± 17.9  20.0 ± 14.3   \n",
       "Dependency                   5            73.3 ± 15.8  46.7 ± 17.9   \n",
       "                             10           70.0 ± 16.4  60.0 ± 17.5   \n",
       "                             30           36.7 ± 17.2  20.0 ± 14.3   \n",
       "                             60           33.3 ± 16.9  40.0 ± 17.5   \n",
       "Evidence Change Relationship 5            73.3 ± 15.8  53.3 ± 17.9   \n",
       "                             10           66.7 ± 16.9  43.3 ± 17.7   \n",
       "                             30           50.0 ± 17.9  30.0 ± 16.4   \n",
       "                             60           36.7 ± 17.2  56.7 ± 17.7   \n",
       "Probability                  5            40.0 ± 17.5    3.3 ± 6.4   \n",
       "                             10             3.3 ± 6.4    3.3 ± 6.4   \n",
       "                             30             3.3 ± 6.4    0.0 ± 0.0   \n",
       "                             60             3.3 ± 6.4    0.0 ± 0.0   \n",
       "\n",
       "                                                            BayMin  \\\n",
       "                                             qwen3:8b  gpt-oss:20b   \n",
       "QuestionType                 NetworkSize                             \n",
       "Blocked Evidence             5            26.7 ± 15.8  76.7 ± 15.1   \n",
       "                             10           16.7 ± 13.3  86.7 ± 12.2   \n",
       "                             30           13.3 ± 12.2  86.7 ± 12.2   \n",
       "                             60           20.0 ± 14.3   93.3 ± 8.9   \n",
       "Common Cause                 5            66.7 ± 16.9  90.0 ± 10.7   \n",
       "                             10           46.7 ± 17.9  100.0 ± 0.0   \n",
       "                             30           36.7 ± 17.2  100.0 ± 0.0   \n",
       "                             60           33.3 ± 16.9  100.0 ± 0.0   \n",
       "Common Effect                5            66.7 ± 16.9   93.3 ± 8.9   \n",
       "                             10           36.7 ± 17.2  90.0 ± 10.7   \n",
       "                             30           43.3 ± 17.7  86.7 ± 12.2   \n",
       "                             60           23.3 ± 15.1  90.0 ± 10.7   \n",
       "Dependency                   5            76.7 ± 15.1   96.7 ± 6.4   \n",
       "                             10           60.0 ± 17.5  90.0 ± 10.7   \n",
       "                             30           26.7 ± 15.8   93.3 ± 8.9   \n",
       "                             60           36.7 ± 17.2  90.0 ± 10.7   \n",
       "Evidence Change Relationship 5            63.3 ± 17.2  86.7 ± 12.2   \n",
       "                             10           46.7 ± 17.9  80.0 ± 14.3   \n",
       "                             30           40.0 ± 17.5  80.0 ± 14.3   \n",
       "                             60           26.7 ± 15.8  83.3 ± 13.3   \n",
       "Probability                  5              3.3 ± 6.4   93.3 ± 8.9   \n",
       "                             10             3.3 ± 6.4   96.7 ± 6.4   \n",
       "                             30             0.0 ± 0.0  90.0 ± 10.7   \n",
       "                             60             0.0 ± 0.0  90.0 ± 10.7   \n",
       "\n",
       "                                                                    \n",
       "                                         llama3.1:70b     qwen3:8b  \n",
       "QuestionType                 NetworkSize                            \n",
       "Blocked Evidence             5            86.7 ± 12.2  53.3 ± 17.9  \n",
       "                             10           86.7 ± 12.2  50.0 ± 17.9  \n",
       "                             30            96.7 ± 6.4  56.7 ± 17.7  \n",
       "                             60            93.3 ± 8.9  80.0 ± 14.3  \n",
       "Common Cause                 5            86.7 ± 12.2   93.3 ± 8.9  \n",
       "                             10            93.3 ± 8.9  100.0 ± 0.0  \n",
       "                             30           100.0 ± 0.0   93.3 ± 8.9  \n",
       "                             60           100.0 ± 0.0  86.7 ± 12.2  \n",
       "Common Effect                5            70.0 ± 16.4   93.3 ± 8.9  \n",
       "                             10           80.0 ± 14.3  90.0 ± 10.7  \n",
       "                             30           60.0 ± 17.5  90.0 ± 10.7  \n",
       "                             60           70.0 ± 16.4   96.7 ± 6.4  \n",
       "Dependency                   5            90.0 ± 10.7   93.3 ± 8.9  \n",
       "                             10            93.3 ± 8.9  100.0 ± 0.0  \n",
       "                             30           90.0 ± 10.7  100.0 ± 0.0  \n",
       "                             60           86.7 ± 12.2  100.0 ± 0.0  \n",
       "Evidence Change Relationship 5            90.0 ± 10.7  80.0 ± 14.3  \n",
       "                             10            96.7 ± 6.4  83.3 ± 13.3  \n",
       "                             30           73.3 ± 15.8  90.0 ± 10.7  \n",
       "                             60           46.7 ± 17.9   93.3 ± 8.9  \n",
       "Probability                  5              0.0 ± 0.0  60.0 ± 17.5  \n",
       "                             10             0.0 ± 0.0  26.7 ± 15.8  \n",
       "                             30             3.3 ± 6.4  43.3 ± 17.7  \n",
       "                             60             0.0 ± 0.0  33.3 ± 16.9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "MODEL_ORDER = ['gpt-oss:latest', 'llama3.1:70b', 'qwen3:8b']\n",
    "MODEL_LABEL = {\n",
    "\t'gpt-oss:latest': 'gpt-oss:20b',\n",
    "\t'llama3.1:70b': 'llama3.1:70b',\n",
    "\t'qwen3:8b': 'qwen3:8b',\n",
    "}\n",
    "\n",
    "def _pct(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if x.size == 0 or np.isnan(x).all():\n",
    "        return None\n",
    "    return round(float(np.nanmean(x) * 100.0), 1)\n",
    "\n",
    "def build_performance_table(csv_file_path: str, baymin_csv_file_path: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a DataFrame indexed by (QuestionType, NetworkSize) with grouped column\n",
    "    headers: top-level framework (Raw, BayMin) and second-level model labels\n",
    "    (gpt-oss:20b, llama3.1:70b, qwen3:8b). Values are mean percentage scores.\n",
    "    Includes all network sizes present for each question type.\n",
    "    Raw means are computed ONLY from csv_file_path.\n",
    "    BayMin means are computed ONLY from baymin_csv_file_path (or csv_file_path if None).\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1) Load sources separately (prevents leakage) ---\n",
    "    df_raw = pd.read_csv(csv_file_path)\n",
    "    df_bay = pd.read_csv(baymin_csv_file_path) if baymin_csv_file_path else df_raw.copy()\n",
    "\n",
    "    # --- 2) Aggregate separately ---\n",
    "    agg_raw = (\n",
    "        df_raw.groupby(['question_set_name', 'network_size', 'model'])['raw_model_score']\n",
    "            .agg(n='size',\n",
    "                mean='mean',\n",
    "                std=lambda s: s.std(ddof=0))\n",
    "            .rename(columns={'mean': 'raw_mean', 'std': 'raw_std', 'n': 'raw_n'})\n",
    "            .assign(raw_se=lambda d: d['raw_std'] / np.sqrt(d['raw_n']),\n",
    "                    raw_ci_hw=lambda d: 1.96 * np.sqrt(d['raw_mean'] * (1 - d['raw_mean']) / d['raw_n']))\n",
    "            .reset_index()\n",
    "    )\n",
    "\n",
    "    agg_bay = (\n",
    "        df_bay.groupby(['question_set_name', 'network_size', 'model'])['baymin_score']\n",
    "            .agg(n='size',\n",
    "                mean='mean',\n",
    "                std=lambda s: s.std(ddof=0))\n",
    "            .rename(columns={'mean': 'baymin_mean', 'std': 'baymin_std', 'n': 'baymin_n'})\n",
    "            .assign(baymin_se=lambda d: d['baymin_std'] / np.sqrt(d['baymin_n']),\n",
    "                    baymin_ci_hw=lambda d: 1.96 * np.sqrt(d['baymin_mean'] * (1 - d['baymin_mean']) / d['baymin_n']))\n",
    "            .reset_index()\n",
    "    )\n",
    "\n",
    "    # --- 3) Outer-merge the two aggregates on keys ---\n",
    "    agg = pd.merge(\n",
    "        agg_raw, agg_bay,\n",
    "        on=['question_set_name', 'network_size', 'model'],\n",
    "        how='outer'\n",
    "    )\n",
    "\n",
    "    # --- 4) Build MultiIndex columns: (Framework, ModelLabel) ---\n",
    "    top, bottom = [], []\n",
    "    for fw in ['Raw', 'BayMin']:\n",
    "        for m in MODEL_ORDER:\n",
    "            top.append(fw)\n",
    "            bottom.append(MODEL_LABEL[m])\n",
    "    cols = pd.MultiIndex.from_arrays([top, bottom])\n",
    "\n",
    "    # --- 5) Assemble rows (include all sizes seen per question type across both sources) ---\n",
    "    rows, row_index = [], []\n",
    "    for q in sorted(agg['question_set_name'].dropna().unique().tolist()):\n",
    "        sub = agg[agg['question_set_name'] == q]\n",
    "        # union of sizes that appear in either raw or baymin for this question type\n",
    "        available_sizes = sorted(sub['network_size'].dropna().unique().tolist())\n",
    "        for ns in available_sizes:\n",
    "            row_vals = []\n",
    "            # Raw block\n",
    "            for m in MODEL_ORDER:\n",
    "                val = sub[(sub['network_size'] == ns) & (sub['model'] == m)]\n",
    "                if len(val):\n",
    "                    mean = _pct(val['raw_mean'].values)\n",
    "                    hw   = _pct(val['raw_ci_hw'].values)   # or use 'raw_se' for SE\n",
    "                    cell = f\"{mean} ± {hw}\" if (mean is not None and hw is not None) else (f\"{mean}\" if mean is not None else None)\n",
    "                    if mean is not None:\n",
    "                        row_vals.append(cell)\n",
    "                    else:\n",
    "                        row_vals.append(None)\n",
    "                else:\n",
    "                    row_vals.append(None)\n",
    "\n",
    "            # BayMin block\n",
    "            for m in MODEL_ORDER:\n",
    "                val = sub[(sub['network_size'] == ns) & (sub['model'] == m)]\n",
    "                if len(val):\n",
    "                    mean = _pct(val['baymin_mean'].values)\n",
    "                    hw   = _pct(val['baymin_ci_hw'].values)  \n",
    "                    cell = f\"{mean} ± {hw}\" if (mean is not None and hw is not None) else (f\"{mean}\" if mean is not None else None)\n",
    "                    if mean is not None:\n",
    "                        row_vals.append(cell)\n",
    "                    else:\n",
    "                        row_vals.append(None)\n",
    "                else:\n",
    "                    row_vals.append(None)\n",
    "\n",
    "            rows.append(row_vals)\n",
    "            row_index.append((q.replace('_', ' ').title(), ns))\n",
    "\n",
    "    idx = pd.MultiIndex.from_tuples(row_index, names=['QuestionType', 'NetworkSize'])\n",
    "    table = pd.DataFrame(rows, index=idx, columns=cols)\n",
    "\n",
    "\t\t# Replace NaN values and 0 values with \"-\" for better readability\n",
    "    table = table.fillna(\"-\")\n",
    "    # excluded = table.columns[table.columns.get_level_values(0) == 'BayMin']\n",
    "    # cols_to_change = table.columns.difference(excluded)\n",
    "    # table.loc[:, cols_to_change] = table.loc[:, cols_to_change].replace(0, \"-\")\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "def show_performance_table(csv_file_path: str, baymin_csv_file_path: str = None) -> pd.DataFrame:\n",
    "\t\"\"\"Build and display the grouped performance table in the notebook.\"\"\"\n",
    "\ttable = build_performance_table(csv_file_path, baymin_csv_file_path)\n",
    "\tdisplay(table)\n",
    "\treturn table\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "_ = show_performance_table('test_log.csv', 'baymin_test_log.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280860f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Required packages:\n",
      "% \\usepackage{booktabs}\n",
      "% \\usepackage{multirow}\n",
      "% \\usepackage{makecell}\n",
      "% \\usepackage{xcolor}\n",
      "\n",
      "\\begin{table*}[t]\n",
      "\\label{tab:performance}\n",
      "  \\centering\n",
      "  \\caption{Accuracy Comparison across Models and Network Sizes.}\n",
      "  \\small\n",
      "  \\begin{tabular}{llccc|ccc}\n",
      "  \\toprule\n",
      "   &  & \\multicolumn{3}{c}{\\textbf{Raw}} & \\multicolumn{3}{c}{\\textbf{BayMin}} \\\\\n",
      "  \\cmidrule(lr){3-5}\n",
      "  \\cmidrule(lr){6-8}\n",
      "  \\textbf{Question Type} & \\textbf{Net} & \\textbf{gpt-oss:20b} & \\textbf{llama3.1:70b} & \\textbf{qwen3:8b} & \\textbf{gpt-oss:20b} & \\textbf{llama3.1:70b} & \\textbf{qwen3:8b} \\\\\n",
      "  \\midrule\n",
      "  \\multirow{4}{*}{Blocked Evidence} & 5 & 23.3 ± 15.1 & 26.7 ± 15.8 & 26.7 ± 15.8 & 76.7 ± 15.1 & 86.7 ± 12.2 & 53.3 ± 17.9 \\\\\n",
      "   & 10 & 26.7 ± 15.8 & 20.0 ± 14.3 & 16.7 ± 13.3 & 86.7 ± 12.2 & 86.7 ± 12.2 & 50.0 ± 17.9 \\\\\n",
      "   & 30 & 6.7 ± 8.9 & 3.3 ± 6.4 & 13.3 ± 12.2 & 86.7 ± 12.2 & 96.7 ± 6.4 & 56.7 ± 17.7 \\\\\n",
      "   & 60 & 26.7 ± 15.8 & 10.0 ± 10.7 & 20.0 ± 14.3 & 93.3 ± 8.9 & 93.3 ± 8.9 & 80.0 ± 14.3 \\\\\n",
      "  \\midrule\n",
      "  \\multirow{4}{*}{Common Cause} & 5 & 80.0 ± 14.3 & 46.7 ± 17.9 & 66.7 ± 16.9 & 90.0 ± 10.7 & 86.7 ± 12.2 & 93.3 ± 8.9 \\\\\n",
      "   & 10 & 63.3 ± 17.2 & 40.0 ± 17.5 & 46.7 ± 17.9 & \\textbf{\\textcolor[HTML]{10ac84}{100.0 ± 0.0}} & 93.3 ± 8.9 & \\textbf{\\textcolor[HTML]{10ac84}{100.0 ± 0.0}} \\\\\n",
      "   & 30 & 30.0 ± 16.4 & 20.0 ± 14.3 & 36.7 ± 17.2 & \\textbf{\\textcolor[HTML]{10ac84}{100.0 ± 0.0}} & \\textbf{\\textcolor[HTML]{10ac84}{100.0 ± 0.0}} & 93.3 ± 8.9 \\\\\n",
      "   & 60 & 26.7 ± 15.8 & 16.7 ± 13.3 & 33.3 ± 16.9 & \\textbf{\\textcolor[HTML]{10ac84}{100.0 ± 0.0}} & \\textbf{\\textcolor[HTML]{10ac84}{100.0 ± 0.0}} & 86.7 ± 12.2 \\\\\n",
      "  \\midrule\n",
      "  \\multirow{4}{*}{Common Effect} & 5 & 66.7 ± 16.9 & 40.0 ± 17.5 & 66.7 ± 16.9 & 93.3 ± 8.9 & 70.0 ± 16.4 & 93.3 ± 8.9 \\\\\n",
      "   & 10 & 63.3 ± 17.2 & 33.3 ± 16.9 & 36.7 ± 17.2 & 90.0 ± 10.7 & 80.0 ± 14.3 & 90.0 ± 10.7 \\\\\n",
      "   & 30 & 50.0 ± 17.9 & 10.0 ± 10.7 & 43.3 ± 17.7 & 86.7 ± 12.2 & 60.0 ± 17.5 & 90.0 ± 10.7 \\\\\n",
      "   & 60 & 50.0 ± 17.9 & 20.0 ± 14.3 & 23.3 ± 15.1 & 90.0 ± 10.7 & 70.0 ± 16.4 & 96.7 ± 6.4 \\\\\n",
      "  \\midrule\n",
      "  \\multirow{4}{*}{Dependency} & 5 & 73.3 ± 15.8 & 46.7 ± 17.9 & 76.7 ± 15.1 & 96.7 ± 6.4 & 90.0 ± 10.7 & 93.3 ± 8.9 \\\\\n",
      "   & 10 & 70.0 ± 16.4 & 60.0 ± 17.5 & 60.0 ± 17.5 & 90.0 ± 10.7 & 93.3 ± 8.9 & \\textbf{\\textcolor[HTML]{10ac84}{100.0 ± 0.0}} \\\\\n",
      "   & 30 & 36.7 ± 17.2 & 20.0 ± 14.3 & 26.7 ± 15.8 & 93.3 ± 8.9 & 90.0 ± 10.7 & \\textbf{\\textcolor[HTML]{10ac84}{100.0 ± 0.0}} \\\\\n",
      "   & 60 & 33.3 ± 16.9 & 40.0 ± 17.5 & 36.7 ± 17.2 & 90.0 ± 10.7 & 86.7 ± 12.2 & \\textbf{\\textcolor[HTML]{10ac84}{100.0 ± 0.0}} \\\\\n",
      "  \\midrule\n",
      "  \\multirow{4}{*}{Evidence Chg. Rel.} & 5 & 73.3 ± 15.8 & 53.3 ± 17.9 & 63.3 ± 17.2 & 86.7 ± 12.2 & 90.0 ± 10.7 & 80.0 ± 14.3 \\\\\n",
      "   & 10 & 66.7 ± 16.9 & 43.3 ± 17.7 & 46.7 ± 17.9 & 80.0 ± 14.3 & 96.7 ± 6.4 & 83.3 ± 13.3 \\\\\n",
      "   & 30 & 50.0 ± 17.9 & 30.0 ± 16.4 & 40.0 ± 17.5 & 80.0 ± 14.3 & 73.3 ± 15.8 & 90.0 ± 10.7 \\\\\n",
      "   & 60 & 36.7 ± 17.2 & 56.7 ± 17.7 & 26.7 ± 15.8 & 83.3 ± 13.3 & 46.7 ± 17.9 & 93.3 ± 8.9 \\\\\n",
      "  \\midrule\n",
      "  \\multirow{4}{*}{Probability} & 5 & 40.0 ± 17.5 & 3.3 ± 6.4 & 3.3 ± 6.4 & 93.3 ± 8.9 & \\textbf{\\textcolor[HTML]{FF5757}{0.0 ± 0.0}} & 60.0 ± 17.5 \\\\\n",
      "   & 10 & 3.3 ± 6.4 & 3.3 ± 6.4 & 3.3 ± 6.4 & 96.7 ± 6.4 & \\textbf{\\textcolor[HTML]{FF5757}{0.0 ± 0.0}} & 26.7 ± 15.8 \\\\\n",
      "   & 30 & 3.3 ± 6.4 & \\textbf{\\textcolor[HTML]{FF5757}{0.0 ± 0.0}} & \\textbf{\\textcolor[HTML]{FF5757}{0.0 ± 0.0}} & 90.0 ± 10.7 & 3.3 ± 6.4 & 43.3 ± 17.7 \\\\\n",
      "   & 60 & 3.3 ± 6.4 & \\textbf{\\textcolor[HTML]{FF5757}{0.0 ± 0.0}} & \\textbf{\\textcolor[HTML]{FF5757}{0.0 ± 0.0}} & 90.0 ± 10.7 & \\textbf{\\textcolor[HTML]{FF5757}{0.0 ± 0.0}} & 33.3 ± 16.9 \\\\\n",
      "  \\bottomrule\n",
      "  \\end{tabular}\n",
      "  \\normalsize\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "def table_to_latex(\n",
    "    table,\n",
    "    caption=\"Accuracy Comparison across Models and Network Sizes.\",\n",
    "    label=\"tab:performance\",\n",
    "    filename=None,\n",
    "    escape=True,\n",
    "    frameworks_order=(\"Raw\", \"BayMin\"),\n",
    "    starred=True,                 # use \\begin{table*} ... \\end{table*}\n",
    "    placement=\"[t]\",              # top placement\n",
    "    size_cmd=\"\\\\small\",\n",
    "    end_size_cmd=\"\\\\normalsize\",\n",
    "    add_vertical_bar=True,\n",
    "    display_require_packages=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Render a MultiIndex performance DataFrame to LaTeX in the requested style,\n",
    "    highlighting 100.0 ± 0.0 (green) and 0.0 ± 0.0 (red).\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    # --- Helpers ---\n",
    "    def tex_escape(s: str) -> str:\n",
    "        if not escape or s is None:\n",
    "            return s\n",
    "        return str(s).replace(\"_\", \"\\\\_\")\n",
    "\n",
    "    # Ensure frameworks exist in columns level 0\n",
    "    col_level0 = table.columns.get_level_values(0)\n",
    "    frameworks_present = [fw for fw in frameworks_order if fw in set(col_level0)]\n",
    "    frameworks_present += [fw for fw in col_level0.unique() if fw not in frameworks_present]\n",
    "    fw_cols = {fw: table.columns[col_level0 == fw] for fw in frameworks_present}\n",
    "\n",
    "    # Column spec\n",
    "    col_spec_parts = [\"l\", \"l\"]\n",
    "    for fw in frameworks_present:\n",
    "        if add_vertical_bar and fw == \"BayMin\":\n",
    "            col_spec_parts.append(\"|\")\n",
    "        col_spec_parts.extend([\"c\"] * len(fw_cols[fw]))\n",
    "    col_spec = \"\".join(col_spec_parts)\n",
    "\n",
    "    # --- Build LaTeX ---\n",
    "    lines = []\n",
    "    if display_require_packages:\n",
    "        lines.append(\"% Required packages:\")\n",
    "        lines.append(\"% \\\\usepackage{booktabs}\")\n",
    "        lines.append(\"% \\\\usepackage{multirow}\")\n",
    "        lines.append(\"% \\\\usepackage{makecell}\")\n",
    "        lines.append(\"% \\\\usepackage{xcolor}\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "    env = \"table*\" if starred else \"table\"\n",
    "    lines.append(f\"\\\\begin{{{env}}}{placement}\")\n",
    "    lines.append(\"  \\\\centering\")\n",
    "    lines.append(f\"  \\\\caption{{{caption}}}\")\n",
    "    lines.append(f\"  \\\\label{{{label}}}\")\n",
    "    if size_cmd:\n",
    "        lines.append(f\"  {size_cmd}\")\n",
    "    lines.append(f\"  \\\\begin{{tabular}}{{{col_spec}}}\")\n",
    "    lines.append(\"  \\\\toprule\")\n",
    "\n",
    "    # Header row 1\n",
    "    first_hdr_cells = [\"\", \"\"]\n",
    "    for fw in frameworks_present:\n",
    "        n = len(fw_cols[fw])\n",
    "        if n > 0:\n",
    "            if n == 1:\n",
    "                first_hdr_cells.append(f\"\\\\textbf{{{tex_escape(fw)}}}\")\n",
    "            else:\n",
    "                first_hdr_cells.append(f\"\\\\multicolumn{{{n}}}{{c}}{{\\\\textbf{{{tex_escape(fw)}}}}}\")\n",
    "    lines.append(\"  \" + \" & \".join(first_hdr_cells) + \" \\\\\\\\\")\n",
    "\n",
    "    # cmidrules\n",
    "    start_col = 3\n",
    "    for fw in frameworks_present:\n",
    "        n = len(fw_cols[fw])\n",
    "        if n > 0:\n",
    "            end_col = start_col + n - 1\n",
    "            lines.append(f\"  \\\\cmidrule(lr){{{start_col}-{end_col}}}\")\n",
    "            start_col = end_col + 1\n",
    "\n",
    "    # Header row 2\n",
    "    second_hdr = [\"\\\\textbf{Question Type}\", \"\\\\textbf{Net}\"]\n",
    "    for fw in frameworks_present:\n",
    "        for _, model_name in fw_cols[fw]:\n",
    "            second_hdr.append(f\"\\\\textbf{{{tex_escape(model_name)}}}\")\n",
    "    lines.append(\"  \" + \" & \".join(second_hdr) + \" \\\\\\\\\")\n",
    "    lines.append(\"  \\\\midrule\")\n",
    "\n",
    "    # --- Body ---\n",
    "    if not isinstance(table.index, pd.MultiIndex) or table.index.nlevels != 2:\n",
    "        raise ValueError(\"table.index must be a MultiIndex with (QuestionType, NetworkSize).\")\n",
    "\n",
    "    for qtype, subdf in table.groupby(level=0, sort=False):\n",
    "        # Rename question type if matches\n",
    "        qtype_tex = tex_escape(qtype)\n",
    "        if \"Evidence Change Relationship\" in qtype_tex:\n",
    "            qtype_tex = qtype_tex.replace(\"Evidence Change Relationship\", \"Evidence Chg. Rel.\")\n",
    "\n",
    "        n_rows = len(subdf)\n",
    "        first_row = True\n",
    "\n",
    "        for (qt, net), row in subdf.iterrows():\n",
    "            net_tex = tex_escape(net)\n",
    "\n",
    "            if first_row:\n",
    "                left_stub = f\"\\\\multirow{{{n_rows}}}{{*}}{{{qtype_tex}}} & {net_tex}\"\n",
    "                first_row = False\n",
    "            else:\n",
    "                left_stub = f\" & {net_tex}\"\n",
    "\n",
    "            data_cells = []\n",
    "            for fw in frameworks_present:\n",
    "                for col in fw_cols[fw]:\n",
    "                    val = row[col]\n",
    "                    if pd.isna(val) or val in (\"-\", \"---\"):\n",
    "                        data_cells.append(\"---\")\n",
    "                        continue\n",
    "\n",
    "                    val_str = str(val).strip()\n",
    "                    # Highlight special values\n",
    "                    if val_str.startswith(\"100\") and \"±\" in val_str and \"0.0\" in val_str:\n",
    "                        data_cells.append(\"\\\\textbf{\\\\textcolor[HTML]{10ac84}{\" + tex_escape(val_str) + \"}}\")\n",
    "                    elif val_str.startswith(\"0\") and \"±\" in val_str and \"0.0\" in val_str:\n",
    "                        data_cells.append(\"\\\\textbf{\\\\textcolor[HTML]{FF5757}{\" + tex_escape(val_str) + \"}}\")\n",
    "                    else:\n",
    "                        data_cells.append(tex_escape(val_str))\n",
    "\n",
    "            lines.append(\"  \" + \" & \".join([left_stub] + data_cells) + \" \\\\\\\\\")\n",
    "        lines.append(\"  \\\\midrule\")\n",
    "\n",
    "    # bottomrule\n",
    "    if lines[-1].strip() == \"\\\\midrule\" or lines[-1].strip() == \"  \\\\midrule\":\n",
    "        lines[-1] = \"  \\\\bottomrule\"\n",
    "    else:\n",
    "        lines.append(\"  \\\\bottomrule\")\n",
    "\n",
    "    lines.append(\"  \\\\end{tabular}\")\n",
    "    if end_size_cmd:\n",
    "        lines.append(f\"  {end_size_cmd}\")\n",
    "    lines.append(f\"\\\\end{{{env}}}\")\n",
    "\n",
    "    latex_code = \"\\n\".join(lines)\n",
    "\n",
    "    if filename:\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(latex_code)\n",
    "\n",
    "    return latex_code\n",
    "\n",
    "\n",
    "def generate_latex_table(csv_file_path: str, baymin_csv_file_path: str = None, \n",
    "                        filename: str = None, display_require_packages: bool = True):\n",
    "    \"\"\"\n",
    "    Generate LaTeX table from CSV data and optionally save to file.\n",
    "    \n",
    "    Args:\n",
    "        csv_file_path (str): Path to main CSV file\n",
    "        baymin_csv_file_path (str, optional): Path to BayMin CSV file\n",
    "        filename (str, optional): Output filename for LaTeX code\n",
    "    \n",
    "    Returns:\n",
    "        str: LaTeX table code\n",
    "    \"\"\"\n",
    "    # Build the performance table\n",
    "    table = build_performance_table(csv_file_path, baymin_csv_file_path)\n",
    "    \n",
    "    # Convert to LaTeX\n",
    "    latex_code = table_to_latex(table, filename=filename, display_require_packages=display_require_packages)\n",
    "    \n",
    "    return latex_code\n",
    "\n",
    "# Generate LaTeX table and save to file\n",
    "latex_code = generate_latex_table('test_log.csv', \n",
    "                                 'baymin_test_log.csv', \n",
    "                                 'performance_table.tex',\n",
    "                                 display_require_packages=True)\n",
    "\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc035b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-bn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
