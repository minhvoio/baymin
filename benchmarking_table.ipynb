{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cdc10e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BAYESIAN NETWORK MODEL PERFORMANCE ANALYSIS\n",
      "================================================================================\n",
      "Total tests: 540\n",
      "Models tested: gpt-oss:latest, llama3.1:70b, qwen3:8b\n",
      "Test types: elementary_test, numerical_test\n",
      "Question categories: dependency, common_cause, common_effect, blocked_evidence, probability, evidence_change_relationship\n",
      "Network size: 5 nodes\n",
      "================================================================================\n",
      "\n",
      "OVERALL PERFORMANCE SUMMARY\n",
      "--------------------------------------------------------------------------------\n",
      "+----+----------------+-------------+-------------+-----------+---------------+---------------+\n",
      "|    |     Model      |  Framework  |   Avg Score |   Std Dev |   Total Tests |   Improvement |\n",
      "+====+================+=============+=============+===========+===============+===============+\n",
      "|  0 | gpt-oss:latest |  Raw Model  |       0.594 |     0.491 |           180 |         0.333 |\n",
      "+----+----------------+-------------+-------------+-----------+---------------+---------------+\n",
      "|  1 | gpt-oss:latest |   BayMin    |       0.928 |     0.259 |           180 |         0.333 |\n",
      "+----+----------------+-------------+-------------+-----------+---------------+---------------+\n",
      "|  2 |  llama3.1:70b  |  Raw Model  |       0.361 |     0.48  |           180 |         0.311 |\n",
      "+----+----------------+-------------+-------------+-----------+---------------+---------------+\n",
      "|  3 |  llama3.1:70b  |   BayMin    |       0.672 |     0.469 |           180 |         0.311 |\n",
      "+----+----------------+-------------+-------------+-----------+---------------+---------------+\n",
      "|  4 |    qwen3:8b    |  Raw Model  |       0.506 |     0.5   |           180 |         0.306 |\n",
      "+----+----------------+-------------+-------------+-----------+---------------+---------------+\n",
      "|  5 |    qwen3:8b    |   BayMin    |       0.811 |     0.391 |           180 |         0.306 |\n",
      "+----+----------------+-------------+-------------+-----------+---------------+---------------+\n",
      "\n",
      "\n",
      "DETAILED BREAKDOWN BY QUESTION TYPE\n",
      "================================================================================\n",
      "\n",
      "DEPENDENCY QUESTIONS\n",
      "--------------------------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.733 |        1     |         0.267 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.467 |        0.633 |         0.167 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.767 |        1     |         0.233 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "COMMON CAUSE QUESTIONS\n",
      "--------------------------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.8   |        0.967 |         0.167 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.467 |        0.933 |         0.467 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.667 |        0.967 |         0.3   |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "COMMON EFFECT QUESTIONS\n",
      "--------------------------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.667 |        0.933 |         0.267 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.4   |        0.7   |         0.3   |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.667 |        1     |         0.333 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "BLOCKED EVIDENCE QUESTIONS\n",
      "--------------------------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.233 |        0.9   |         0.667 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.267 |        0.833 |         0.567 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.267 |        0.433 |         0.167 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "PROBABILITY QUESTIONS\n",
      "--------------------------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.4   |        0.967 |         0.567 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.033 |        0.033 |         0     |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.033 |        0.5   |         0.467 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "EVIDENCE CHANGE RELATIONSHIP QUESTIONS\n",
      "--------------------------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.733 |        0.8   |         0.067 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.533 |        0.9   |         0.367 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.633 |        0.967 |         0.333 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "\n",
      "PERFORMANCE BY TEST TYPE\n",
      "================================================================================\n",
      "\n",
      "ELEMENTARY TEST\n",
      "------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.633 |        0.92  |         0.287 |     150 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.427 |        0.8   |         0.373 |     150 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.6   |        0.873 |         0.273 |     150 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "NUMERICAL TEST\n",
      "------------------------------\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|    |     Model      |   Raw Avg |   BayMin Avg |   Improvement |   Tests |\n",
      "+====+================+===========+==============+===============+=========+\n",
      "|  0 | gpt-oss:latest |     0.4   |        0.967 |         0.567 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  1 |  llama3.1:70b  |     0.033 |        0.033 |         0     |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "|  2 |    qwen3:8b    |     0.033 |        0.5   |         0.467 |      30 |\n",
      "+----+----------------+-----------+--------------+---------------+---------+\n",
      "\n",
      "\n",
      "RUNTIME ANALYSIS\n",
      "================================================================================\n",
      "+----+----------------+-----------------------+--------------------------+--------------------+\n",
      "|    |     Model      |   Raw Avg Runtime (s) |   BayMin Avg Runtime (s) |  Runtime Overhead  |\n",
      "+====+================+=======================+==========================+====================+\n",
      "|  0 | gpt-oss:latest |                 68.25 |                    42.31 |      -25.94s       |\n",
      "+----+----------------+-----------------------+--------------------------+--------------------+\n",
      "|  1 |  llama3.1:70b  |                 37.06 |                    54.63 |      +17.56s       |\n",
      "+----+----------------+-----------------------+--------------------------+--------------------+\n",
      "|  2 |    qwen3:8b    |                 74.75 |                    50.73 |      -24.02s       |\n",
      "+----+----------------+-----------------------+--------------------------+--------------------+\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "def parse_and_print_results(csv_file_path):\n",
    "    \"\"\"\n",
    "    Parse the test log CSV and print a comprehensive performance table.\n",
    "    \n",
    "    Args:\n",
    "        csv_file_path (str): Path to the CSV file containing test results\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"BAYESIAN NETWORK MODEL PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total tests: {len(df)}\")\n",
    "    print(f\"Models tested: {', '.join(df['model'].unique())}\")\n",
    "    print(f\"Test types: {', '.join(df['test_type'].unique())}\")\n",
    "    print(f\"Question categories: {', '.join(df['question_set_name'].unique())}\")\n",
    "    print(f\"Network size: {df['network_size'].iloc[0]} nodes\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Create summary statistics\n",
    "    summary_data = []\n",
    "    \n",
    "    # Group by model and question type\n",
    "    for model in df['model'].unique():\n",
    "        model_data = df[df['model'] == model]\n",
    "        \n",
    "        # Raw model performance\n",
    "        raw_scores = model_data['raw_model_score'].values\n",
    "        raw_avg = np.mean(raw_scores)\n",
    "        raw_std = np.std(raw_scores)\n",
    "        \n",
    "        # BayMin framework performance  \n",
    "        baymin_scores = model_data['baymin_score'].values\n",
    "        baymin_avg = np.mean(baymin_scores)\n",
    "        baymin_std = np.std(baymin_scores)\n",
    "        \n",
    "        # Performance improvement\n",
    "        improvement = baymin_avg - raw_avg\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Model': model,\n",
    "            'Framework': 'Raw Model',\n",
    "            'Avg Score': f\"{raw_avg:.3f}\",\n",
    "            'Std Dev': f\"{raw_std:.3f}\",\n",
    "            'Total Tests': len(raw_scores),\n",
    "            'Improvement': f\"{improvement:+.3f}\"\n",
    "        })\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Model': model,\n",
    "            'Framework': 'BayMin',\n",
    "            'Avg Score': f\"{baymin_avg:.3f}\",\n",
    "            'Std Dev': f\"{baymin_std:.3f}\",\n",
    "            'Total Tests': len(baymin_scores),\n",
    "            'Improvement': f\"{improvement:+.3f}\"\n",
    "        })\n",
    "    \n",
    "    # Print overall summary table\n",
    "    print(\"\\nOVERALL PERFORMANCE SUMMARY\")\n",
    "    print(\"-\" * 80)\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(tabulate(summary_df, headers='keys', tablefmt='grid', stralign='center'))\n",
    "    \n",
    "    # Detailed breakdown by question type\n",
    "    print(\"\\n\\nDETAILED BREAKDOWN BY QUESTION TYPE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for question_type in df['question_set_name'].unique():\n",
    "        print(f\"\\n{question_type.upper().replace('_', ' ')} QUESTIONS\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        type_data = df[df['question_set_name'] == question_type]\n",
    "        type_summary = []\n",
    "        \n",
    "        for model in type_data['model'].unique():\n",
    "            model_type_data = type_data[type_data['model'] == model]\n",
    "            \n",
    "            raw_avg = np.mean(model_type_data['raw_model_score'].values)\n",
    "            baymin_avg = np.mean(model_type_data['baymin_score'].values)\n",
    "            improvement = baymin_avg - raw_avg\n",
    "            \n",
    "            type_summary.append({\n",
    "                'Model': model,\n",
    "                'Raw Avg': f\"{raw_avg:.3f}\",\n",
    "                'BayMin Avg': f\"{baymin_avg:.3f}\",\n",
    "                'Improvement': f\"{improvement:+.3f}\",\n",
    "                'Tests': len(model_type_data)\n",
    "            })\n",
    "        \n",
    "        type_df = pd.DataFrame(type_summary)\n",
    "        print(tabulate(type_df, headers='keys', tablefmt='grid', stralign='center'))\n",
    "    \n",
    "    # Performance by test type (elementary vs numerical)\n",
    "    print(\"\\n\\nPERFORMANCE BY TEST TYPE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for test_type in df['test_type'].unique():\n",
    "        print(f\"\\n{test_type.upper().replace('_', ' ')}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        test_data = df[df['test_type'] == test_type]\n",
    "        test_summary = []\n",
    "        \n",
    "        for model in test_data['model'].unique():\n",
    "            model_test_data = test_data[test_data['model'] == model]\n",
    "            \n",
    "            raw_avg = np.mean(model_test_data['raw_model_score'].values)\n",
    "            baymin_avg = np.mean(model_test_data['baymin_score'].values)\n",
    "            improvement = baymin_avg - raw_avg\n",
    "            \n",
    "            test_summary.append({\n",
    "                'Model': model,\n",
    "                'Raw Avg': f\"{raw_avg:.3f}\",\n",
    "                'BayMin Avg': f\"{baymin_avg:.3f}\",\n",
    "                'Improvement': f\"{improvement:+.3f}\",\n",
    "                'Tests': len(model_test_data)\n",
    "            })\n",
    "        \n",
    "        test_df = pd.DataFrame(test_summary)\n",
    "        print(tabulate(test_df, headers='keys', tablefmt='grid', stralign='center'))\n",
    "    \n",
    "    # Runtime analysis\n",
    "    print(\"\\n\\nRUNTIME ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    runtime_summary = []\n",
    "    for model in df['model'].unique():\n",
    "        model_data = df[df['model'] == model]\n",
    "        \n",
    "        raw_runtime = model_data['raw_model_runtime'].values\n",
    "        baymin_runtime = model_data['baymin_runtime'].values\n",
    "        \n",
    "        runtime_summary.append({\n",
    "            'Model': model,\n",
    "            'Raw Avg Runtime (s)': f\"{np.mean(raw_runtime):.2f}\",\n",
    "            'BayMin Avg Runtime (s)': f\"{np.mean(baymin_runtime):.2f}\",\n",
    "            'Runtime Overhead': f\"{np.mean(baymin_runtime) - np.mean(raw_runtime):+.2f}s\"\n",
    "        })\n",
    "    \n",
    "    runtime_df = pd.DataFrame(runtime_summary)\n",
    "    print(tabulate(runtime_df, headers='keys', tablefmt='grid', stralign='center'))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Test the function\n",
    "csv_path = \"benchmarking/results/latest/test_log.csv\"\n",
    "parse_and_print_results(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ab6423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuestionType NetworkSize [Raw] gpt-oss:20b llama3.1:70b qwen3:8b [BayMin] gpt-oss:20b llama3.1:70b qwen3:8b\n",
      "Blocked Evidence 5 23 26 26 90 83 43\n",
      "Common Cause 5 80 46 66 96 93 96\n",
      "Common Effect 5 66 40 66 93 70 100\n",
      "Dependency 5 73 46 76 100 63 100\n",
      "Evidence Change Relationship 5 73 53 63 80 90 96\n",
      "Probability 5 40 3 3 96 3 50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "MODEL_ORDER = ['gpt-oss:latest', 'llama3.1:70b', 'qwen3:8b']\n",
    "MODEL_LABEL = {\n",
    "\t'gpt-oss:latest': 'gpt-oss:20b',\n",
    "\t'llama3.1:70b': 'llama3.1:70b',\n",
    "\t'qwen3:8b': 'qwen3:8b',\n",
    "}\n",
    "\n",
    "\n",
    "def _pct(x):\n",
    "\tif len(x) == 0 or np.isnan(x).all():\n",
    "\t\treturn None\n",
    "\treturn round(float(np.nanmean(x) * 100.0), 1)\n",
    "\n",
    "\n",
    "def print_compact_performance_table(csv_file_path: str) -> pd.DataFrame:\n",
    "\t\"\"\"\n",
    "\tPrint a compact table per requirement:\n",
    "\tQuestionType NetworkSize Raw[gpt-oss:20b llama3.1:70b qwen3:8b] BayMin[gpt-oss:20b llama3.1:70b qwen3:8b]\n",
    "\tExample row: \"Dependency 5 60 30 50 90 70 80\"\n",
    "\tReturns the DataFrame used to print, for reuse/saving if needed.\n",
    "\t\"\"\"\n",
    "\t# Load\n",
    "\tdf = pd.read_csv(csv_file_path)\n",
    "\n",
    "\t# Aggregate means per (question_set_name, network_size, model)\n",
    "\tagg = (\n",
    "\t\tdf.groupby(['question_set_name', 'network_size', 'model'])\n",
    "\t\t.agg(raw_mean=('raw_model_score', 'mean'), baymin_mean=('baymin_score', 'mean'))\n",
    "\t\t.reset_index()\n",
    "\t)\n",
    "\n",
    "\t# Ensure all models appear even if missing for a question type\n",
    "\tqns = sorted(df['question_set_name'].unique().tolist())\n",
    "\tnsizes = sorted(df['network_size'].unique().tolist())\n",
    "\trows = []\n",
    "\tfor q in qns:\n",
    "\t\tfor ns in nsizes:\n",
    "\t\t\trow = {\n",
    "\t\t\t\t'QuestionType': q.replace('_', ' ').title(),\n",
    "\t\t\t\t'NetworkSize': ns,\n",
    "\t\t\t}\n",
    "\t\t\t# Raw block\n",
    "\t\t\tfor m in MODEL_ORDER:\n",
    "\t\t\t\tval = agg[(agg['question_set_name'] == q) & (agg['network_size'] == ns) & (agg['model'] == m)]['raw_mean']\n",
    "\t\t\t\tscore = _pct(val.values) if len(val) else None\n",
    "\t\t\t\trow[f'Raw {MODEL_LABEL[m]}'] = score\n",
    "\t\t\t# BayMin block\n",
    "\t\t\tfor m in MODEL_ORDER:\n",
    "\t\t\t\tval = agg[(agg['question_set_name'] == q) & (agg['network_size'] == ns) & (agg['model'] == m)]['baymin_mean']\n",
    "\t\t\t\tscore = _pct(val.values) if len(val) else None\n",
    "\t\t\t\trow[f'BayMin {MODEL_LABEL[m]}'] = score\n",
    "\t\t\trows.append(row)\n",
    "\n",
    "\twide_df = pd.DataFrame(rows)\n",
    "\n",
    "\t# Desired column ordering\n",
    "\tcols = (\n",
    "\t\t['QuestionType', 'NetworkSize'] +\n",
    "\t\t[*(f'Raw {MODEL_LABEL[m]}' for m in MODEL_ORDER)] +\n",
    "\t\t[*(f'BayMin {MODEL_LABEL[m]}' for m in MODEL_ORDER)]\n",
    "\t)\n",
    "\twide_df = wide_df[cols]\n",
    "\n",
    "\t# Print header with groups\n",
    "\traw_labels = [MODEL_LABEL[m] for m in MODEL_ORDER]\n",
    "\tbay_labels = [MODEL_LABEL[m] for m in MODEL_ORDER]\n",
    "\theader = (\n",
    "\t\t\"QuestionType NetworkSize \"\n",
    "\t\t\"[Raw] \" + \" \".join(raw_labels) + \" \"\n",
    "\t\t\"[BayMin] \" + \" \".join(bay_labels)\n",
    "\t)\n",
    "\tprint(header)\n",
    "\tfor _, r in wide_df.iterrows():\n",
    "\t\tvals = [\n",
    "\t\t\tstr(r['QuestionType']),\n",
    "\t\t\tstr(r['NetworkSize']),\n",
    "\t\t\t*[(\"\" if pd.isna(r[c]) else str(int(r[c]))) for c in [f'Raw {lab}' for lab in raw_labels]],\n",
    "\t\t\t*[(\"\" if pd.isna(r[c]) else str(int(r[c]))) for c in [f'BayMin {lab}' for lab in bay_labels]],\n",
    "\t\t]\n",
    "\t\tprint(\" \".join(vals))\n",
    "\n",
    "\treturn wide_df\n",
    "\n",
    "# Example usage (uncomment to run in the notebook):\n",
    "_ = print_compact_performance_table('benchmarking/results/latest/test_log.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4cc2397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1076932/3351906290.py:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[11.7 '-' '-' '-' 40.0 '-' '-' '-' 33.3 '-' '-' '-' 36.7 '-' '-' '-' 36.7\n",
      " '-' '-' '-' 20.0 '-' '-' '-']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  table.loc[:, cols_to_change] = table.loc[:, cols_to_change].replace(0, \"-\")\n",
      "/tmp/ipykernel_1076932/3351906290.py:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[13.3 '-' '-' '-' 23.3 '-' '-' '-' 20.0 '-' '-' '-' 23.3 '-' '-' '-' 26.7\n",
      " '-' '-' '-' 1.7 '-' '-' '-']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  table.loc[:, cols_to_change] = table.loc[:, cols_to_change].replace(0, \"-\")\n",
      "/tmp/ipykernel_1076932/3351906290.py:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[13.3 '-' '-' '-' 33.3 '-' '-' '-' 33.3 '-' '-' '-' 38.3 '-' '-' '-' 31.7\n",
      " '-' '-' '-' 1.7 '-' '-' '-']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  table.loc[:, cols_to_change] = table.loc[:, cols_to_change].replace(0, \"-\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Raw</th>\n",
       "      <th colspan=\"3\" halign=\"left\">BayMin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>gpt-oss:20b</th>\n",
       "      <th>llama3.1:70b</th>\n",
       "      <th>qwen3:8b</th>\n",
       "      <th>gpt-oss:20b</th>\n",
       "      <th>llama3.1:70b</th>\n",
       "      <th>qwen3:8b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuestionType</th>\n",
       "      <th>NetworkSize</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Blocked Evidence</th>\n",
       "      <th>5</th>\n",
       "      <td>11.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>83.3</td>\n",
       "      <td>85.0</td>\n",
       "      <td>48.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>86.7</td>\n",
       "      <td>86.7</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>86.7</td>\n",
       "      <td>96.7</td>\n",
       "      <td>56.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>93.3</td>\n",
       "      <td>93.3</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Common Cause</th>\n",
       "      <th>5</th>\n",
       "      <td>40.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>33.3</td>\n",
       "      <td>93.3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Common Effect</th>\n",
       "      <th>5</th>\n",
       "      <td>33.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>93.3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>96.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>86.7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>96.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Dependency</th>\n",
       "      <th>5</th>\n",
       "      <td>36.7</td>\n",
       "      <td>23.3</td>\n",
       "      <td>38.3</td>\n",
       "      <td>98.3</td>\n",
       "      <td>76.7</td>\n",
       "      <td>96.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>90.0</td>\n",
       "      <td>93.3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>93.3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>90.0</td>\n",
       "      <td>86.7</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Evidence Change Relationship</th>\n",
       "      <th>5</th>\n",
       "      <td>36.7</td>\n",
       "      <td>26.7</td>\n",
       "      <td>31.7</td>\n",
       "      <td>83.3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>80.0</td>\n",
       "      <td>96.7</td>\n",
       "      <td>83.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.3</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>83.3</td>\n",
       "      <td>46.7</td>\n",
       "      <td>93.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Probability</th>\n",
       "      <th>5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>96.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>43.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Raw                        \\\n",
       "                                         gpt-oss:20b llama3.1:70b qwen3:8b   \n",
       "QuestionType                 NetworkSize                                     \n",
       "Blocked Evidence             5                  11.7         13.3     13.3   \n",
       "                             10                    -            -        -   \n",
       "                             30                    -            -        -   \n",
       "                             60                    -            -        -   \n",
       "Common Cause                 5                  40.0         23.3     33.3   \n",
       "                             10                    -            -        -   \n",
       "                             30                    -            -        -   \n",
       "                             60                    -            -        -   \n",
       "Common Effect                5                  33.3         20.0     33.3   \n",
       "                             10                    -            -        -   \n",
       "                             30                    -            -        -   \n",
       "                             60                    -            -        -   \n",
       "Dependency                   5                  36.7         23.3     38.3   \n",
       "                             10                    -            -        -   \n",
       "                             30                    -            -        -   \n",
       "                             60                    -            -        -   \n",
       "Evidence Change Relationship 5                  36.7         26.7     31.7   \n",
       "                             10                    -            -        -   \n",
       "                             30                    -            -        -   \n",
       "                             60                    -            -        -   \n",
       "Probability                  5                  20.0          1.7      1.7   \n",
       "                             10                    -            -        -   \n",
       "                             30                    -            -        -   \n",
       "                             60                    -            -        -   \n",
       "\n",
       "                                              BayMin                        \n",
       "                                         gpt-oss:20b llama3.1:70b qwen3:8b  \n",
       "QuestionType                 NetworkSize                                    \n",
       "Blocked Evidence             5                  83.3         85.0     48.3  \n",
       "                             10                 86.7         86.7     50.0  \n",
       "                             30                 86.7         96.7     56.7  \n",
       "                             60                 93.3         93.3     80.0  \n",
       "Common Cause                 5                  93.3         90.0     95.0  \n",
       "                             10                100.0         93.3    100.0  \n",
       "                             30                100.0        100.0     93.3  \n",
       "                             60                100.0        100.0     86.7  \n",
       "Common Effect                5                  93.3         70.0     96.7  \n",
       "                             10                 90.0         80.0     90.0  \n",
       "                             30                 86.7         60.0     90.0  \n",
       "                             60                 90.0         70.0     96.7  \n",
       "Dependency                   5                  98.3         76.7     96.7  \n",
       "                             10                 90.0         93.3    100.0  \n",
       "                             30                 93.3         90.0    100.0  \n",
       "                             60                 90.0         86.7    100.0  \n",
       "Evidence Change Relationship 5                  83.3         90.0     88.3  \n",
       "                             10                 80.0         96.7     83.3  \n",
       "                             30                 80.0         73.3     90.0  \n",
       "                             60                 83.3         46.7     93.3  \n",
       "Probability                  5                  95.0          1.7     55.0  \n",
       "                             10                 96.7          0.0     26.7  \n",
       "                             30                 90.0          3.3     43.3  \n",
       "                             60                 90.0          0.0     33.3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def build_performance_table(csv_file_path: str, baymin_csv_file_path: str = None) -> pd.DataFrame:\n",
    "\t\"\"\"\n",
    "\tReturn a DataFrame indexed by (QuestionType, NetworkSize) with grouped column\n",
    "\theaders: top-level framework (Raw, BayMin) and second-level model labels\n",
    "\t(gpt-oss:20b, llama3.1:70b, qwen3:8b). Values are mean percentage scores.\n",
    "\tIncludes all network sizes present for each question type.\n",
    "\tConcatenates main CSV with baymin CSV if provided.\n",
    "\t\"\"\"\n",
    "\n",
    "\t# Load main CSV\n",
    "\tdf = pd.read_csv(csv_file_path)\n",
    "\t\n",
    "\t# Load and concatenate baymin CSV if provided\n",
    "\tif baymin_csv_file_path:\n",
    "\t\tdf_baymin = pd.read_csv(baymin_csv_file_path)\n",
    "\t\tdf = pd.concat([df, df_baymin], ignore_index=True)\n",
    "\n",
    "\t# Aggregate means once\n",
    "\tagg = (\n",
    "\t\tdf.groupby(['question_set_name', 'network_size', 'model'])\n",
    "\t\t.agg(raw_mean=('raw_model_score', 'mean'), baymin_mean=('baymin_score', 'mean'))\n",
    "\t\t.reset_index()\n",
    "\t)\n",
    "\n",
    "\t# Build MultiIndex columns: (Framework, ModelLabel)\n",
    "\ttop = []\n",
    "\tbottom = []\n",
    "\tfor fw in ['Raw', 'BayMin']:\n",
    "\t\tfor m in MODEL_ORDER:\n",
    "\t\t\ttop.append(fw)\n",
    "\t\t\tbottom.append(MODEL_LABEL[m])\n",
    "\tcols = pd.MultiIndex.from_arrays([top, bottom])\n",
    "\n",
    "\trows = []\n",
    "\trow_index = []\n",
    "\tfor q in sorted(agg['question_set_name'].unique().tolist()):\n",
    "\t\tsub = agg[agg['question_set_name'] == q]\n",
    "\t\t# Include all network sizes that exist in the data for this question type\n",
    "\t\tavailable_sizes = sorted(sub['network_size'].unique().tolist())\n",
    "\t\tfor ns in available_sizes:\n",
    "\t\t\trow_vals = []\n",
    "\t\t\t# Raw values (in model order)\n",
    "\t\t\tfor m in MODEL_ORDER:\n",
    "\t\t\t\tval = sub[(sub['network_size'] == ns) & (sub['model'] == m)]['raw_mean']\n",
    "\t\t\t\trow_vals.append(_pct(val.values) if len(val) else None)\n",
    "\t\t\t# BayMin values (in model order)\n",
    "\t\t\tfor m in MODEL_ORDER:\n",
    "\t\t\t\tval = sub[(sub['network_size'] == ns) & (sub['model'] == m)]['baymin_mean']\n",
    "\t\t\t\trow_vals.append(_pct(val.values) if len(val) else None)\n",
    "\t\t\trows.append(row_vals)\n",
    "\t\t\trow_index.append((q.replace('_', ' ').title(), ns))\n",
    "\n",
    "\tidx = pd.MultiIndex.from_tuples(row_index, names=['QuestionType', 'NetworkSize'])\n",
    "\ttable = pd.DataFrame(rows, index=idx, columns=cols)\n",
    "\n",
    "\t# Replace NaN values and 0 values with \"-\" for better readability\n",
    "\ttable = table.fillna(\"-\")\n",
    "\texcluded = table.columns[table.columns.get_level_values(0) == 'BayMin']\n",
    "\tcols_to_change = table.columns.difference(excluded)\n",
    "\ttable.loc[:, cols_to_change] = table.loc[:, cols_to_change].replace(0, \"-\")\n",
    "\n",
    "\treturn table\n",
    "\n",
    "\n",
    "def show_performance_table(csv_file_path: str, baymin_csv_file_path: str = None) -> pd.DataFrame:\n",
    "\t\"\"\"Build and display the grouped performance table in the notebook.\"\"\"\n",
    "\ttable = build_performance_table(csv_file_path, baymin_csv_file_path)\n",
    "\tdisplay(table)\n",
    "\treturn table\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "_ = show_performance_table('benchmarking/results/latest/test_log.csv', 'baymin_test_log.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-bn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
