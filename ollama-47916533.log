time=2025-10-17T02:02:30.125+11:00 level=INFO source=routes.go:1304 msg="server config" env="map[CUDA_VISIBLE_DEVICES:0 GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/mvo1/lb64_scratch/ollama-models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-10-17T02:02:30.207+11:00 level=INFO source=images.go:477 msg="total blobs: 31"
time=2025-10-17T02:02:30.213+11:00 level=INFO source=images.go:484 msg="total unused blobs removed: 0"
time=2025-10-17T02:02:30.219+11:00 level=INFO source=routes.go:1357 msg="Listening on 127.0.0.1:11434 (version 0.11.4)"
time=2025-10-17T02:02:30.219+11:00 level=INFO source=gpu.go:217 msg="looking for compatible GPUs"
time=2025-10-17T02:02:30.918+11:00 level=INFO source=types.go:130 msg="inference compute" id=GPU-6b739bbf-5989-4594-105d-96f7e04b9db8 library=cuda variant=v12 compute=8.6 driver=12.2 name="NVIDIA A40" total="44.4 GiB" available="44.1 GiB"
[GIN] 2025/10/17 - 02:02:33 | 200 |  212.149698ms |       127.0.0.1 | GET      "/api/tags"
time=2025-10-17T02:05:17.856+11:00 level=INFO source=sched.go:786 msg="new model will fit in available VRAM in single GPU, loading" model=/home/mvo1/lb64_scratch/ollama-models/blobs/sha256-6c02683809a8dc4eb05c78d44bc63bcd707703b078998fa58829c858ab337bb0 gpu=GPU-6b739bbf-5989-4594-105d-96f7e04b9db8 parallel=1 available=47340191744 required="3.0 GiB"
time=2025-10-17T02:05:18.051+11:00 level=INFO source=server.go:135 msg="system memory" total="1006.8 GiB" free="984.4 GiB" free_swap="0 B"
time=2025-10-17T02:05:18.052+11:00 level=INFO source=server.go:175 msg=offload library=cuda layers.requested=-1 layers.model=41 layers.offload=41 layers.split="" memory.available="[44.1 GiB]" memory.gpu_overhead="0 B" memory.required.full="3.0 GiB" memory.required.partial="3.0 GiB" memory.required.kv="320.0 MiB" memory.required.allocations="[3.0 GiB]" memory.weights.total="2.0 GiB" memory.weights.repeating="1.8 GiB" memory.weights.nonrepeating="201.0 MiB" memory.graph.full="266.7 MiB" memory.graph.partial="266.7 MiB"
llama_model_loader: loaded meta data with 42 key-value pairs and 362 tensors from /home/mvo1/lb64_scratch/ollama-models/blobs/sha256-6c02683809a8dc4eb05c78d44bc63bcd707703b078998fa58829c858ab337bb0 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = granite
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Granite 4.0 Micro
llama_model_loader: - kv   3:                         general.size_label str              = 3.4B
llama_model_loader: - kv   4:                            general.license str              = apache-2.0
llama_model_loader: - kv   5:                               general.tags arr[str,2]       = ["language", "granite-4.0"]
llama_model_loader: - kv   6:                        granite.block_count u32              = 40
llama_model_loader: - kv   7:                     granite.context_length u32              = 131072
llama_model_loader: - kv   8:                   granite.embedding_length u32              = 2560
llama_model_loader: - kv   9:                granite.feed_forward_length u32              = 8192
llama_model_loader: - kv  10:               granite.attention.head_count u32              = 40
llama_model_loader: - kv  11:            granite.attention.head_count_kv arr[i32,40]      = [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...
llama_model_loader: - kv  12:                     granite.rope.freq_base f32              = 10000000.000000
llama_model_loader: - kv  13:   granite.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  14:                       granite.expert_count u32              = 0
llama_model_loader: - kv  15:                  granite.expert_used_count u32              = 0
llama_model_loader: - kv  16:                         granite.vocab_size u32              = 100352
llama_model_loader: - kv  17:               granite.rope.dimension_count u32              = 64
llama_model_loader: - kv  18:                    granite.attention.scale f32              = 0.015625
llama_model_loader: - kv  19:                    granite.embedding_scale f32              = 12.000000
llama_model_loader: - kv  20:                     granite.residual_scale f32              = 0.220000
llama_model_loader: - kv  21:                        granite.logit_scale f32              = 10.000000
llama_model_loader: - kv  22:  granite.expert_shared_feed_forward_length u32              = 8192
llama_model_loader: - kv  23:                    granite.ssm.conv_kernel u32              = 4
llama_model_loader: - kv  24:                     granite.ssm.state_size u32              = 256
llama_model_loader: - kv  25:                    granite.ssm.group_count u32              = 1
llama_model_loader: - kv  26:                     granite.ssm.inner_size u32              = 5120
llama_model_loader: - kv  27:                 granite.ssm.time_step_rank u32              = 128
llama_model_loader: - kv  28:             granite.rope.scaling.finetuned bool             = true
llama_model_loader: - kv  29:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  30:                         tokenizer.ggml.pre str              = dbrx
llama_model_loader: - kv  31:                      tokenizer.ggml.tokens arr[str,100352]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  32:                  tokenizer.ggml.token_type arr[i32,100352]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  33:                      tokenizer.ggml.merges arr[str,100000]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
llama_model_loader: - kv  34:                tokenizer.ggml.bos_token_id u32              = 100257
llama_model_loader: - kv  35:                tokenizer.ggml.eos_token_id u32              = 100257
llama_model_loader: - kv  36:            tokenizer.ggml.unknown_token_id u32              = 100269
llama_model_loader: - kv  37:            tokenizer.ggml.padding_token_id u32              = 100256
llama_model_loader: - kv  38:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  39:                    tokenizer.chat_template str              = {%- set tools_system_message_prefix =...
llama_model_loader: - kv  40:               general.quantization_version u32              = 2
llama_model_loader: - kv  41:                          general.file_type u32              = 15
llama_model_loader: - type  f32:   81 tensors
llama_model_loader: - type q4_K:  240 tensors
llama_model_loader: - type q6_K:   41 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 1.95 GiB (4.93 BPW) 
load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
load: special tokens cache size = 96
load: token to piece cache size = 0.6152 MB
print_info: arch             = granite
print_info: vocab_only       = 1
print_info: model type       = ?B
print_info: model params     = 3.40 B
print_info: general.name     = Granite 4.0 Micro
print_info: f_embedding_scale = 0.000000
print_info: f_residual_scale  = 0.000000
print_info: f_attention_scale = 0.000000
print_info: vocab type       = BPE
print_info: n_vocab          = 100352
print_info: n_merges         = 100000
print_info: BOS token        = 100257 '<|end_of_text|>'
print_info: EOS token        = 100257 '<|end_of_text|>'
print_info: UNK token        = 100269 '<|unk|>'
print_info: PAD token        = 100256 '<|pad|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM PRE token    = 100258 '<|fim_prefix|>'
print_info: FIM SUF token    = 100260 '<|fim_suffix|>'
print_info: FIM MID token    = 100259 '<|fim_middle|>'
print_info: FIM PAD token    = 100261 '<|fim_pad|>'
print_info: EOG token        = 100257 '<|end_of_text|>'
print_info: EOG token        = 100261 '<|fim_pad|>'
print_info: max token length = 256
llama_model_load: vocab only - skipping tensors
time=2025-10-17T02:05:18.224+11:00 level=INFO source=server.go:438 msg="starting llama server" cmd="/fs04/scratch2/lb64/ollama-bin/bin/ollama runner --model /home/mvo1/lb64_scratch/ollama-models/blobs/sha256-6c02683809a8dc4eb05c78d44bc63bcd707703b078998fa58829c858ab337bb0 --ctx-size 4096 --batch-size 512 --n-gpu-layers 41 --threads 52 --parallel 1 --port 44667"
time=2025-10-17T02:05:18.224+11:00 level=INFO source=sched.go:481 msg="loaded runners" count=1
time=2025-10-17T02:05:18.224+11:00 level=INFO source=server.go:598 msg="waiting for llama runner to start responding"
time=2025-10-17T02:05:18.225+11:00 level=INFO source=server.go:632 msg="waiting for server to become available" status="llm server not responding"
time=2025-10-17T02:05:18.240+11:00 level=INFO source=runner.go:815 msg="starting go runner"
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA A40, compute capability 8.6, VMM: yes
load_backend: loaded CUDA backend from /fs04/scratch2/lb64/ollama-bin/lib/ollama/libggml-cuda.so
load_backend: loaded CPU backend from /fs04/scratch2/lb64/ollama-bin/lib/ollama/libggml-cpu-icelake.so
time=2025-10-17T02:05:32.638+11:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=500,600,610,700,750,800,860,870,890,900,1200 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-10-17T02:05:32.671+11:00 level=INFO source=runner.go:874 msg="Server listening on 127.0.0.1:44667"
time=2025-10-17T02:05:32.751+11:00 level=INFO source=server.go:632 msg="waiting for server to become available" status="llm server loading model"
llama_model_load_from_file_impl: using device CUDA0 (NVIDIA A40) - 45147 MiB free
llama_model_loader: loaded meta data with 42 key-value pairs and 362 tensors from /home/mvo1/lb64_scratch/ollama-models/blobs/sha256-6c02683809a8dc4eb05c78d44bc63bcd707703b078998fa58829c858ab337bb0 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = granite
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Granite 4.0 Micro
llama_model_loader: - kv   3:                         general.size_label str              = 3.4B
llama_model_loader: - kv   4:                            general.license str              = apache-2.0
llama_model_loader: - kv   5:                               general.tags arr[str,2]       = ["language", "granite-4.0"]
llama_model_loader: - kv   6:                        granite.block_count u32              = 40
llama_model_loader: - kv   7:                     granite.context_length u32              = 131072
llama_model_loader: - kv   8:                   granite.embedding_length u32              = 2560
llama_model_loader: - kv   9:                granite.feed_forward_length u32              = 8192
llama_model_loader: - kv  10:               granite.attention.head_count u32              = 40
llama_model_loader: - kv  11:            granite.attention.head_count_kv arr[i32,40]      = [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...
llama_model_loader: - kv  12:                     granite.rope.freq_base f32              = 10000000.000000
llama_model_loader: - kv  13:   granite.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  14:                       granite.expert_count u32              = 0
llama_model_loader: - kv  15:                  granite.expert_used_count u32              = 0
llama_model_loader: - kv  16:                         granite.vocab_size u32              = 100352
llama_model_loader: - kv  17:               granite.rope.dimension_count u32              = 64
llama_model_loader: - kv  18:                    granite.attention.scale f32              = 0.015625
llama_model_loader: - kv  19:                    granite.embedding_scale f32              = 12.000000
llama_model_loader: - kv  20:                     granite.residual_scale f32              = 0.220000
llama_model_loader: - kv  21:                        granite.logit_scale f32              = 10.000000
llama_model_loader: - kv  22:  granite.expert_shared_feed_forward_length u32              = 8192
llama_model_loader: - kv  23:                    granite.ssm.conv_kernel u32              = 4
llama_model_loader: - kv  24:                     granite.ssm.state_size u32              = 256
llama_model_loader: - kv  25:                    granite.ssm.group_count u32              = 1
llama_model_loader: - kv  26:                     granite.ssm.inner_size u32              = 5120
llama_model_loader: - kv  27:                 granite.ssm.time_step_rank u32              = 128
llama_model_loader: - kv  28:             granite.rope.scaling.finetuned bool             = true
llama_model_loader: - kv  29:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  30:                         tokenizer.ggml.pre str              = dbrx
llama_model_loader: - kv  31:                      tokenizer.ggml.tokens arr[str,100352]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  32:                  tokenizer.ggml.token_type arr[i32,100352]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  33:                      tokenizer.ggml.merges arr[str,100000]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
llama_model_loader: - kv  34:                tokenizer.ggml.bos_token_id u32              = 100257
llama_model_loader: - kv  35:                tokenizer.ggml.eos_token_id u32              = 100257
llama_model_loader: - kv  36:            tokenizer.ggml.unknown_token_id u32              = 100269
llama_model_loader: - kv  37:            tokenizer.ggml.padding_token_id u32              = 100256
llama_model_loader: - kv  38:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  39:                    tokenizer.chat_template str              = {%- set tools_system_message_prefix =...
llama_model_loader: - kv  40:               general.quantization_version u32              = 2
llama_model_loader: - kv  41:                          general.file_type u32              = 15
llama_model_loader: - type  f32:   81 tensors
llama_model_loader: - type q4_K:  240 tensors
llama_model_loader: - type q6_K:   41 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 1.95 GiB (4.93 BPW) 
load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
load: special tokens cache size = 96
load: token to piece cache size = 0.6152 MB
print_info: arch             = granite
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_embd           = 2560
print_info: n_layer          = 40
print_info: n_head           = 40
print_info: n_head_kv        = 8
print_info: n_rot            = 64
print_info: n_swa            = 0
print_info: n_swa_pattern    = 1
print_info: n_embd_head_k    = 64
print_info: n_embd_head_v    = 64
print_info: n_gqa            = 5
print_info: n_embd_k_gqa     = 512
print_info: n_embd_v_gqa     = 512
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 1.0e+01
print_info: f_attn_scale     = 1.6e-02
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: freq_base_train  = 10000000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = yes
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 3B
print_info: model params     = 3.40 B
print_info: general.name     = Granite 4.0 Micro
print_info: f_embedding_scale = 12.000000
print_info: f_residual_scale  = 0.220000
print_info: f_attention_scale = 0.015625
print_info: vocab type       = BPE
print_info: n_vocab          = 100352
print_info: n_merges         = 100000
print_info: BOS token        = 100257 '<|end_of_text|>'
print_info: EOS token        = 100257 '<|end_of_text|>'
print_info: UNK token        = 100269 '<|unk|>'
print_info: PAD token        = 100256 '<|pad|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM PRE token    = 100258 '<|fim_prefix|>'
print_info: FIM SUF token    = 100260 '<|fim_suffix|>'
print_info: FIM MID token    = 100259 '<|fim_middle|>'
print_info: FIM PAD token    = 100261 '<|fim_pad|>'
print_info: EOG token        = 100257 '<|end_of_text|>'
print_info: EOG token        = 100261 '<|fim_pad|>'
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: offloading 40 repeating layers to GPU
load_tensors: offloading output layer to GPU
load_tensors: offloaded 41/41 layers to GPU
load_tensors:        CUDA0 model buffer size =  1998.84 MiB
load_tensors:   CPU_Mapped model buffer size =   200.98 MiB
llama_context: constructing llama_context
llama_context: n_seq_max     = 1
llama_context: n_ctx         = 4096
llama_context: n_ctx_per_seq = 4096
llama_context: n_batch       = 512
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = 0
llama_context: freq_base     = 10000000.0
llama_context: freq_scale    = 1
llama_context: n_ctx_per_seq (4096) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_context:  CUDA_Host  output buffer size =     0.39 MiB
llama_kv_cache_unified: kv_size = 4096, type_k = 'f16', type_v = 'f16', n_layer = 40, can_shift = 1, padding = 32
llama_kv_cache_unified:      CUDA0 KV buffer size =   320.00 MiB
llama_kv_cache_unified: KV self size  =  320.00 MiB, K (f16):  160.00 MiB, V (f16):  160.00 MiB
llama_context:      CUDA0 compute buffer size =   348.00 MiB
llama_context:  CUDA_Host compute buffer size =    13.01 MiB
llama_context: graph nodes  = 1448
llama_context: graph splits = 2
time=2025-10-17T02:05:34.756+11:00 level=INFO source=server.go:637 msg="llama runner started in 16.53 seconds"
[GIN] 2025/10/17 - 02:05:49 | 200 | 32.078713326s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-10-17T02:05:50.579+11:00 level=INFO source=sched.go:546 msg="updated VRAM based on existing loaded models" gpu=GPU-6b739bbf-5989-4594-105d-96f7e04b9db8 library=cuda total="44.4 GiB" available="41.1 GiB"
time=2025-10-17T02:05:50.579+11:00 level=INFO source=sched.go:786 msg="new model will fit in available VRAM in single GPU, loading" model=/home/mvo1/lb64_scratch/ollama-models/blobs/sha256-b112e727c6f18875636c56a779790a590d705aec9e1c0eb5a97d51fc2a778583 gpu=GPU-6b739bbf-5989-4594-105d-96f7e04b9db8 parallel=1 available=44085936128 required="14.9 GiB"
time=2025-10-17T02:05:50.779+11:00 level=INFO source=server.go:135 msg="system memory" total="1006.8 GiB" free="982.5 GiB" free_swap="0 B"
time=2025-10-17T02:05:50.779+11:00 level=INFO source=server.go:175 msg=offload library=cuda layers.requested=-1 layers.model=25 layers.offload=25 layers.split="" memory.available="[41.1 GiB]" memory.gpu_overhead="0 B" memory.required.full="14.9 GiB" memory.required.partial="14.9 GiB" memory.required.kv="300.0 MiB" memory.required.allocations="[14.9 GiB]" memory.weights.total="11.7 GiB" memory.weights.repeating="10.7 GiB" memory.weights.nonrepeating="1.1 GiB" memory.graph.full="2.0 GiB" memory.graph.partial="2.0 GiB"
time=2025-10-17T02:05:50.842+11:00 level=INFO source=server.go:438 msg="starting llama server" cmd="/fs04/scratch2/lb64/ollama-bin/bin/ollama runner --ollama-engine --model /home/mvo1/lb64_scratch/ollama-models/blobs/sha256-b112e727c6f18875636c56a779790a590d705aec9e1c0eb5a97d51fc2a778583 --ctx-size 8192 --batch-size 512 --n-gpu-layers 25 --threads 52 --parallel 1 --port 42747"
time=2025-10-17T02:05:50.842+11:00 level=INFO source=sched.go:481 msg="loaded runners" count=2
time=2025-10-17T02:05:50.842+11:00 level=INFO source=server.go:598 msg="waiting for llama runner to start responding"
time=2025-10-17T02:05:50.842+11:00 level=INFO source=server.go:632 msg="waiting for server to become available" status="llm server not responding"
time=2025-10-17T02:05:50.857+11:00 level=INFO source=runner.go:925 msg="starting ollama engine"
time=2025-10-17T02:05:50.857+11:00 level=INFO source=runner.go:983 msg="Server listening on 127.0.0.1:42747"
time=2025-10-17T02:05:50.918+11:00 level=INFO source=ggml.go:92 msg="" architecture=gptoss file_type=MXFP4 name="" description="" num_tensors=315 num_key_values=30
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA A40, compute capability 8.6, VMM: yes
load_backend: loaded CUDA backend from /fs04/scratch2/lb64/ollama-bin/lib/ollama/libggml-cuda.so
load_backend: loaded CPU backend from /fs04/scratch2/lb64/ollama-bin/lib/ollama/libggml-cpu-icelake.so
time=2025-10-17T02:05:51.007+11:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=500,600,610,700,750,800,860,870,890,900,1200 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-10-17T02:05:51.093+11:00 level=INFO source=server.go:632 msg="waiting for server to become available" status="llm server loading model"
time=2025-10-17T02:05:51.137+11:00 level=INFO source=ggml.go:365 msg="offloading 24 repeating layers to GPU"
time=2025-10-17T02:05:51.137+11:00 level=INFO source=ggml.go:371 msg="offloading output layer to GPU"
time=2025-10-17T02:05:51.137+11:00 level=INFO source=ggml.go:376 msg="offloaded 25/25 layers to GPU"
time=2025-10-17T02:05:51.137+11:00 level=INFO source=ggml.go:379 msg="model weights" buffer=CUDA0 size="11.7 GiB"
time=2025-10-17T02:05:51.137+11:00 level=INFO source=ggml.go:379 msg="model weights" buffer=CPU size="1.1 GiB"
time=2025-10-17T02:05:51.146+11:00 level=INFO source=ggml.go:668 msg="compute graph" backend=CUDA0 buffer_type=CUDA0 size="2.1 GiB"
time=2025-10-17T02:05:51.146+11:00 level=INFO source=ggml.go:668 msg="compute graph" backend=CPU buffer_type=CPU size="5.6 MiB"
time=2025-10-17T02:06:18.407+11:00 level=INFO source=server.go:637 msg="llama runner started in 27.56 seconds"
[GIN] 2025/10/17 - 02:06:31 | 200 | 41.450511718s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:06:32 | 200 |  944.736879ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:06:36 | 200 |  4.637758006s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:06:37 | 200 |   868.55023ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:06:41 | 200 |  3.881448131s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:06:42 | 200 |  934.125454ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:06:43 | 200 |  970.652659ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:06:44 | 200 |  615.656395ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:06:44 | 200 |  570.459379ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:06:45 | 200 |  673.323596ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:06:46 | 200 |   583.60013ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:06:49 | 200 |  955.409781ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:06:55 | 200 |  6.141653012s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:06:56 | 200 |  895.075711ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:07:06 | 200 |  9.524792666s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:07:12 | 200 |   6.46971078s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:07:13 | 200 |  923.808962ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:07:14 | 200 |  900.819386ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:07:15 | 200 |  660.942638ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:07:15 | 200 |  544.924986ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:07:16 | 200 |  544.443059ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:07:16 | 200 |  556.048137ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:07:21 | 200 |  675.588501ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:07:24 | 200 |  3.086275519s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:07:25 | 200 |  810.867957ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:07:29 | 200 |  3.587229785s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:07:30 | 200 |  827.768445ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:07:34 | 200 |  4.020015887s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:07:35 | 200 |  903.052601ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:07:35 | 200 |  566.321446ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:07:36 | 200 |  574.265412ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:07:36 | 200 |  668.346449ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:07:37 | 200 |  677.465107ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:07:46 | 200 |  866.177386ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:07:52 | 200 |  5.708526317s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:07:53 | 200 |  902.505611ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:07:57 | 200 |  4.075177343s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:08:03 | 200 |  5.619300282s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:08:03 | 200 |  889.321647ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:08:04 | 200 |  900.145627ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:08:05 | 200 |  567.265051ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:08:05 | 200 |  565.891664ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:08:06 | 200 |  674.719335ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:08:07 | 200 |  588.166833ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:08:24 | 200 |  608.926654ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:08:33 | 200 |  8.955979729s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:08:34 | 200 |  1.435452991s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:08:37 | 200 |  2.931417097s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:08:45 | 200 |  7.393898459s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:08:46 | 200 |  943.152049ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:08:48 | 200 |  2.774532227s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:08:49 | 200 |  906.652854ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:08:50 | 200 |  658.886633ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:08:51 | 200 |  598.546438ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:08:51 | 200 |  604.233003ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:08:52 | 200 |   613.23415ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:09:23 | 200 |  772.730534ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:09:30 | 200 |  7.335894802s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:09:31 | 200 |  953.362762ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:09:44 | 200 | 13.474836888s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:09:49 | 200 |  5.019510625s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:09:51 | 200 |  1.263570782s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:09:59 | 200 |  8.230110457s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:01 | 200 |  2.043753228s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:08 | 200 |  6.725100871s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:09 | 200 |   921.70933ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:09 | 200 |  907.687984ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:10 | 200 |  566.201138ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:11 | 200 |  570.323318ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:11 | 200 |  579.592297ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:12 | 200 |  584.580277ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:12 | 200 |  241.006715ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:15 | 200 |  3.412717111s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:16 | 200 |  806.005471ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:23 | 200 |  6.610936929s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:25 | 200 |  2.407253362s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:33 | 200 |  7.489957971s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:34 | 200 |  948.339353ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:36 | 200 |  2.060651352s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:37 | 200 |  787.667588ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:37 | 200 |  654.563828ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:38 | 200 |  417.631958ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:38 | 200 |  350.837593ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:38 | 200 |  431.309918ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:39 | 200 |  339.179362ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:42 | 200 |  713.069279ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:43 | 200 |  383.755432ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:46 | 200 |  2.762784343s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:48 | 200 |  2.531178812s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:51 | 200 |  3.030178714s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:52 | 200 |  819.250121ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:10:53 | 200 |   656.55199ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:53 | 200 |  418.771572ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:53 | 200 |  328.278242ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:54 | 200 |  332.504478ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:54 | 200 |  339.030174ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:10:59 | 200 |  244.339349ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:11:02 | 200 |  3.268651076s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:11:06 | 200 |  3.941998229s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:11:10 | 200 |  3.452873111s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:11:10 | 200 |  829.555937ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:11:14 | 200 |  3.873284814s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:11:17 | 200 |  2.708096553s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:11:18 | 200 |  794.208554ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:11:18 | 200 |  659.017628ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:11:19 | 200 |  418.642718ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:11:19 | 200 |  326.911704ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:11:19 | 200 |  330.367002ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:11:20 | 200 |  343.399457ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:11:29 | 200 |  323.441603ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:11:33 | 200 |  3.970762612s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:11:37 | 200 |  4.311884366s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:11:47 | 200 |  9.269299472s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:11:48 | 200 |  1.295155122s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:11:49 | 200 |  664.243624ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:11:49 | 200 |  412.575948ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:11:49 | 200 |  329.000625ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:11:50 | 200 |  332.957498ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:11:50 | 200 |  336.279613ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:12:07 | 200 |  652.235154ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:12:08 | 200 |  522.135227ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:12:11 | 200 |  3.078669433s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:12:14 | 200 |  3.128964089s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:12:17 | 200 |  3.001200877s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:12:18 | 200 |  660.824413ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:12:18 | 200 |  415.618683ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:12:19 | 200 |  421.267301ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:12:19 | 200 |  428.140866ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:12:19 | 200 |  337.058163ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:12:50 | 200 |  248.229924ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:12:53 | 200 |  2.984744533s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:12:56 | 200 |  3.429957752s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:12:57 | 200 |  823.094511ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:02 | 200 |  4.810477409s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:05 | 200 |  3.114434432s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:06 | 200 |  815.757145ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:13 | 200 |  7.287003457s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:14 | 200 |  666.246285ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:14 | 200 |  415.525697ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:14 | 200 |  339.465195ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:15 | 200 |  333.786081ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:15 | 200 |  367.816288ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:16 | 200 |  701.370811ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:21 | 200 |  4.655477758s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:26 | 200 |  5.051337454s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:29 | 200 |  3.604725198s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:30 | 200 |  821.255413ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:31 | 200 |  648.063445ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:31 | 200 |  408.424887ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:31 | 200 |  319.160484ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:32 | 200 |  324.454477ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:32 | 200 |  331.488039ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:35 | 200 |  482.183977ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:36 | 200 |  304.620859ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:40 | 200 |  4.604968899s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:41 | 200 |   850.97972ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:44 | 200 |  2.594883185s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:45 | 200 |  1.054925688s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:48 | 200 |  3.393338551s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:49 | 200 |  652.868568ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:49 | 200 |  313.188895ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:49 | 200 |   322.79424ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:50 | 200 |  324.879329ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:50 | 200 |   328.38387ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:13:55 | 200 |  366.223841ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:13:59 | 200 |  3.777736406s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:14:02 | 200 |  3.155339542s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:14:05 | 200 |  2.912117622s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:14:05 | 200 |  653.072049ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:14:06 | 200 |   406.42371ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:14:06 | 200 |   318.83338ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:14:07 | 200 |  327.888515ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:14:07 | 200 |  329.086114ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:14:16 | 200 |  607.439311ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:14:19 | 200 |  2.766495063s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:14:21 | 200 |  2.753529327s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:14:25 | 200 |  3.563524779s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:14:26 | 200 |  652.496539ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:14:26 | 200 |  416.460402ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:14:26 | 200 |  319.037332ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:14:27 | 200 |  320.426341ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:14:27 | 200 |  330.996675ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:14:44 | 200 |  1.118166375s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:14:49 | 200 |  4.580310723s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:14:55 | 200 |    6.1237779s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:14:56 | 200 |  901.416087ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:14:59 | 200 |  3.204693084s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:15:00 | 200 |  815.508771ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:15:00 | 200 |   646.66654ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:15:01 | 200 |  407.823103ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:15:01 | 200 |  325.989284ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:15:02 | 200 |  353.868717ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:15:02 | 200 |  341.957262ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:15:32 | 200 |  359.573275ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:15:38 | 200 |  5.622873493s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:15:39 | 200 |  1.135090079s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:15:44 | 200 |  4.570222979s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:15:44 | 200 |   842.45101ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:15:49 | 200 |   4.59354328s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:15:50 | 200 |  850.825185ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:15:51 | 200 |   644.67763ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:15:51 | 200 |    407.8558ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:15:51 | 200 |  326.463274ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:15:52 | 200 |  330.336171ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:15:52 | 200 |  332.369624ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:15:52 | 200 |   370.16143ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:15:56 | 200 |  3.778339021s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:15:57 | 200 |   839.71493ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:00 | 200 |  3.246926666s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:04 | 200 |   3.47736381s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:04 | 200 |   692.34814ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:16:05 | 200 |  446.824162ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:16:05 | 200 |  453.956122ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:16:06 | 200 |  451.818686ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:16:06 | 200 |  462.110265ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:16:09 | 200 |  261.617875ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:16 | 200 |  6.724539575s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:17 | 200 |  907.669764ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:23 | 200 |  5.734680878s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:24 | 200 |  877.371722ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:28 | 200 |  4.725401736s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:29 | 200 |    851.4871ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:30 | 200 |  686.318635ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:16:30 | 200 |  443.644983ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:16:31 | 200 |  445.425167ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:16:31 | 200 |  451.030272ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:16:32 | 200 |  369.958522ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:16:37 | 200 |  296.468216ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:40 | 200 |   3.39466843s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:44 | 200 |  4.080691792s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:47 | 200 |  2.314649581s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:49 | 200 |  2.466878957s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:50 | 200 |  811.998782ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:16:51 | 200 |  687.346739ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:16:51 | 200 |  444.556258ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:16:51 | 200 |  448.399629ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:16:52 | 200 |   453.78003ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:16:52 | 200 |  461.182775ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:17:02 | 200 |  942.335622ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:17:02 | 400 |     108.119µs |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:17:07 | 200 |  1.084276457s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/10/17 - 02:17:11 | 200 |  3.671889305s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:17:13 | 200 |  1.436376531s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:17:15 | 200 |  2.696916492s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:17:16 | 200 |  809.954879ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:17:18 | 200 |  2.016156057s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:17:19 | 200 |  695.672022ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:17:19 | 200 |  444.701107ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:17:20 | 200 |  453.727861ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:17:20 | 200 |  450.820456ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:17:21 | 200 |   368.40826ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:17:38 | 200 |  769.876428ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:17:42 | 200 |  3.834621506s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:17:43 | 200 |  1.351098981s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:17:47 | 200 |  4.122973522s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:17:48 | 200 |  850.845533ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:17:51 | 200 |  3.289856865s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:17:52 | 200 |  821.878146ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:17:53 | 200 |  685.064593ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:17:53 | 200 |  444.421795ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:17:54 | 200 |   447.53743ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:17:54 | 200 |  452.828814ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:17:54 | 200 |  368.360896ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:18:25 | 200 |  407.175608ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:18:28 | 200 |  3.576498821s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:18:29 | 200 |   822.12553ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:18:33 | 200 |   4.20959646s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:18:34 | 200 |  840.695667ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:18:40 | 200 |  5.707991798s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:18:41 | 200 |  689.260387ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:18:41 | 200 |  442.648052ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:18:42 | 200 |  449.672789ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:18:42 | 200 |  453.971655ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:18:43 | 200 |  472.254694ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:18:43 | 200 |  746.013799ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:18:47 | 200 |  3.511273993s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:18:48 | 200 |  838.445957ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:18:52 | 200 |  4.644564908s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:18:56 | 200 |  3.304058328s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:18:57 | 200 |  858.250964ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:18:57 | 200 |  561.360174ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:18:58 | 200 |  571.348587ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:18:58 | 200 |  576.083341ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:18:59 | 200 |  588.955016ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:19:02 | 200 |   674.78684ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:19:09 | 200 |  7.114447414s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:19:10 | 200 |  929.217801ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:19:17 | 200 |   7.12115011s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:19:18 | 200 |  931.019898ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:19:28 | 200 |  9.293973047s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:19:29 | 200 |  952.883289ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:19:29 | 200 |   620.25658ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:19:30 | 200 |  625.742743ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:19:30 | 200 |  632.190098ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:19:31 | 200 |  639.555657ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:19:37 | 200 |  732.282515ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:19:40 | 200 |  3.049615234s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:19:44 | 200 |  4.837850158s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:19:49 | 200 |  4.337828397s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:19:50 | 200 |  836.440886ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:19:50 | 200 |  854.512061ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:19:51 | 200 |  618.490208ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:19:52 | 200 |  565.848737ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:19:52 | 200 |  623.127737ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:19:53 | 200 |  581.815267ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:20:02 | 200 |  773.723299ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:20:05 | 200 |  2.792613329s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:20:09 | 200 |  4.134975992s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:20:17 | 200 |  8.632867976s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:20:18 | 200 |  906.640842ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:20:19 | 200 |  592.952491ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:20:19 | 200 |  601.151721ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:20:20 | 200 |  601.098606ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:20:21 | 200 |  611.870919ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:20:38 | 200 |  723.735405ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:20:42 | 200 |   3.20872661s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:20:42 | 200 |  829.836974ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:20:45 | 200 |  2.638949324s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:20:46 | 200 |   824.34242ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:20:53 | 200 |  6.907688647s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:20:54 | 200 |  932.431821ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:20:55 | 200 |  864.157671ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:20:55 | 200 |  621.815744ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:20:56 | 200 |  621.730533ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:20:56 | 200 |  632.696025ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:20:57 | 200 |  638.578656ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:21:28 | 200 |  879.140182ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:21:33 | 200 |  4.948372851s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:21:37 | 200 |  4.435596787s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:21:44 | 200 |  6.725622873s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:21:56 | 200 | 11.875647751s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:21:57 | 200 |  948.857114ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:21:58 | 200 |  621.651883ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:21:58 | 200 |   628.74034ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:21:59 | 200 |  634.283646ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:21:59 | 200 |   638.90961ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:22:00 | 200 |  522.015144ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:04 | 200 |  3.984674283s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:07 | 200 |  3.217337011s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:08 | 200 |  819.703693ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:17 | 200 |  9.468756385s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:18 | 200 |  558.872424ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:22:18 | 200 |  314.347058ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:22:19 | 200 |   315.54707ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:22:19 | 200 |  326.567925ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:22:19 | 200 |   328.73846ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:22:22 | 200 |  520.244727ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:25 | 200 |  2.921073242s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:26 | 200 |  812.295925ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:29 | 200 |  3.133940277s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:30 | 200 |  825.078193ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:33 | 200 |  3.162673095s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:34 | 200 |  807.563534ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:34 | 200 |  664.360982ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:22:35 | 200 |  426.975079ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:22:35 | 200 |  427.104359ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:22:36 | 200 |    438.3576ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:22:36 | 200 |   448.43038ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:22:41 | 200 |   518.44934ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:44 | 200 |  3.298937735s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:46 | 200 |   1.50301997s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:54 | 200 |  7.959436253s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:22:55 | 200 |  958.533147ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:23:01 | 200 |   5.99920045s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:23:01 | 200 |  671.846846ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:23:02 | 200 |  319.426373ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:23:02 | 200 |   317.05665ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:23:02 | 200 |  324.057743ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:23:03 | 200 |  326.767071ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:23:11 | 200 |  525.316177ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:23:15 | 200 |  3.489834149s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:23:16 | 200 |  830.371819ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:23:19 | 200 |  3.294049719s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:23:20 | 200 |    831.8832ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:23:23 | 200 |   2.70335725s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:23:23 | 200 |   667.38944ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:23:24 | 200 |  342.331449ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:23:24 | 200 |  430.319557ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:23:24 | 200 |  333.595231ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:23:25 | 200 |  327.246199ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:23:42 | 200 |  1.066561501s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:23:46 | 200 |  4.248938896s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:23:50 | 200 |  4.191664584s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:23:51 | 200 |  870.937513ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:23:55 | 200 |  4.179412931s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:23:56 | 200 |  860.018929ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:23:57 | 200 |  661.718533ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:23:57 | 200 |  512.340862ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:23:58 | 200 |  512.532643ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:23:58 | 200 |  519.595943ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:23:59 | 200 |  530.853829ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:24:30 | 200 |  1.525255647s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:24:37 | 200 |   6.77598012s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:24:43 | 200 |  5.613853775s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:24:49 | 200 |  5.866661533s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:24:50 | 200 |  897.175307ms |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/10/17 - 02:24:50 | 200 |  820.206731ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:24:51 | 200 |   584.36699ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:24:52 | 200 |  584.973072ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:24:52 | 200 |  584.704355ms |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/10/17 - 02:24:53 | 200 |  592.911398ms |       127.0.0.1 | POST     "/api/chat"
