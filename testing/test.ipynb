{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30f2cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /fs04/scratch2/lb64/projects/llm-bn/testing\n",
      "Added project root to Python path: /fs04/scratch2/lb64/projects/llm-bn\n",
      "Python path now includes: ['/fs04/scratch2/lb64/projects/llm-bn', '/home/mvo1/lb64_scratch/miniconda3/envs/llm-bn/lib/python313.zip', '/home/mvo1/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13', '/home/mvo1/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/lib-dynload', '/home/mvo1/lb64_scratch/miniconda3/envs/llm-bn/lib/python3.13/site-packages']\n",
      "Loading Netica\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to Python path so we can import modules from the project root\n",
    "# In Jupyter notebooks, __file__ is not defined, so we use getcwd() and navigate up\n",
    "current_dir = os.getcwd()\n",
    "# If we're in the testing directory, go up one level to get to project root\n",
    "if current_dir.endswith('/testing'):\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "else:\n",
    "    # If we're already in project root, use current directory\n",
    "    project_root = current_dir\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Current working directory: {current_dir}\")\n",
    "print(f\"Added project root to Python path: {project_root}\")\n",
    "print(f\"Python path now includes: {[p for p in sys.path if 'llm-bn' in p]}\")\n",
    "\n",
    "import requests, json\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "from ollama_helper.ollama_helper import answer_this_prompt\n",
    "from bn_helpers.get_structures_print_tools import get_nets, printNet, get_BN_structure, get_BN_node_states\n",
    "from bn_helpers.bn_helpers import BnToolBox\n",
    "from bn_helpers.utils import get_path, set_findings, temporarily_set_findings\n",
    "from benchmarking.data_utils import load_nets_from_parquet\n",
    "from ollama_helper.ollama_helper import answer_this_prompt\n",
    "from ollama_helper.prompts import TAKE_QUIZ_PROMPT\n",
    "from bn_helpers.bn_helpers import BnToolBox\n",
    "from bn_helpers.get_structures_print_tools import get_BN_structure\n",
    "from bn_helpers.tool_agent import get_answer_from_tool_agent, chat_with_tools\n",
    "from benchmarking.quiz_generator import (\n",
    "    create_dependency_quiz, create_common_cause_quiz, create_common_effect_quiz, create_blocked_evidence_quiz, \n",
    "    create_evidence_change_relationship_quiz, create_probability_quiz, create_highest_impact_evidence_quiz)\n",
    "from benchmarking.benchmarking_utils import pick_two_random_nodes, fake_random_nodes\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.providers.ollama import OllamaProvider\n",
    "from bn_helpers.constants import MODEL, MODEL_QUIZ, OLLAMA_URL\n",
    "from benchmarking.question_types import (DEPENDENCY_QUESTIONS, COMMON_CAUSE_QUESTIONS, COMMON_EFFECT_QUESTIONS, BLOCKED_EVIDENCES_QUESTIONS, \n",
    "EVIDENCE_CHANGE_RELATIONSHIP_QUESTIONS, PROBABILITY_QUESTIONS, HIGHEST_IMPACT_EVIDENCE_QUESTIONS)\n",
    "from pydantic import BaseModel\n",
    "from benchmarking.model_evaluator import (dependency_test, validate_quiz_answer, model_do_quiz, \n",
    "two_nodes_question, probability_question, QuizAnswer, \n",
    "debug_print_elementary_quiz, debug_print_numerical_quiz, export_quiz_samples_to_csv)\n",
    "import asyncio\n",
    "import time\n",
    "from ollama_helper.ollama_helper import get_answer_from_ollama, get_quiz_answer_from_thinking_model\n",
    "\n",
    "\n",
    "MODEL_QUIZ = \"qwen2.5:7b\"\n",
    "# MODEL_TOOLS = \"gpt-oss:latest\"\n",
    "# MODEL_TOOLS = \"qwen3:8b\"\n",
    "MODEL_TOOLS = \"llama3.1:70b\"\n",
    "# MODEL_TOOLS = MODEL_QUIZ\n",
    "# print(generate_chat(\"Print [A, C] with no additional text\", model=\"qwen2.5:3b\", num_predict=5))\n",
    "# print(answer_this_prompt(\"Print [A, C] with no additional text\", model=\"qwen2.5:7b\", format=AnswerStructure.model_json_schema()))\n",
    "# Use the project root we established earlier to create the correct path\n",
    "\n",
    "# model = MODEL_TOOLS\n",
    "# prompt = \"Answer a\"\n",
    "# max_tokens = 1000\n",
    "# STREAM = True\n",
    "\n",
    "# try:\n",
    "#     loop = asyncio.get_event_loop()\n",
    "#     if loop.is_running():\n",
    "#         start_time = time.time()\n",
    "#         ans = loop.run_until_complete(get_quiz_answer_from_thinking_model(prompt, model=model, max_tokens=max_tokens, format=QuizAnswer, stream=STREAM))\n",
    "#         raw_response_time = time.time() - start_time\n",
    "#     else:\n",
    "#         start_time = time.time()\n",
    "#         ans = loop.run_until_complete(get_quiz_answer_from_thinking_model(prompt, model=model, max_tokens=max_tokens, format=QuizAnswer, stream=STREAM))\n",
    "#         raw_response_time = time.time() - start_time\n",
    "# except RuntimeError:\n",
    "#     start_time = time.time()\n",
    "#     ans = asyncio.run(get_quiz_answer_from_thinking_model(prompt, model=model, max_tokens=max_tokens, format=QuizAnswer, stream=STREAM))\n",
    "#     raw_response_time = time.time() - start_time\n",
    "\n",
    "# print(ans)\n",
    "# print(raw_response_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "352e713a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading nets from: /fs04/scratch2/lb64/projects/llm-bn/benchmarking/data\n",
      "Loaded 4 nets from /fs04/scratch2/lb64/projects/llm-bn/benchmarking/data/nets_dataset.parquet\n",
      "Net 5:\n",
      "C -> ['E', 'D', 'A', 'B']\n",
      "E -> ['D', 'A', 'B']\n",
      "D -> ['A']\n",
      "A -> ['B']\n",
      "B -> []\n",
      "\n",
      "Net 10:\n",
      "H -> ['I', 'C', 'A', 'F', 'D', 'B', 'G', 'J']\n",
      "I -> ['C', 'A', 'F', 'D', 'B', 'G', 'J', 'E']\n",
      "C -> ['A', 'F', 'D', 'B', 'E']\n",
      "A -> ['F', 'B', 'J', 'E']\n",
      "F -> ['G', 'J', 'E']\n",
      "D -> ['B', 'G', 'E']\n",
      "B -> ['G', 'J']\n",
      "G -> ['J']\n",
      "J -> []\n",
      "E -> []\n",
      "\n",
      "Net 30:\n",
      "M -> ['P', 'A1', 'A', 'F', 'Y', 'Q', 'C', 'L', 'K']\n",
      "P -> ['T', 'C1', 'V', 'Y', 'R', 'E', 'I']\n",
      "U -> ['A1', 'X', 'H', 'T', 'Z', 'C1', 'F', 'V', 'S']\n",
      "A1 -> ['Z', 'Y', 'Q', 'C']\n",
      "D -> ['A', 'Z', 'E', 'I']\n",
      "X -> ['A', 'Z', 'C1', 'F', 'R', 'E', 'C', 'L', 'D1']\n",
      "A -> ['G', 'W', 'F', 'V', 'E', 'Q', 'C', 'L', 'B']\n",
      "N -> ['J', 'B1', 'F', 'I', 'C', 'L']\n",
      "H -> ['G', 'Z', 'O', 'L', 'D1']\n",
      "G -> ['J', 'Z', 'V']\n",
      "J -> ['W', 'T', 'C1', 'B1', 'V', 'S', 'I', 'B']\n",
      "W -> ['C1', 'E', 'I', 'K']\n",
      "T -> ['Z', 'O', 'C1', 'V', 'E']\n",
      "Z -> ['C1', 'B1', 'Y', 'I', 'C', 'K']\n",
      "O -> ['C1', 'V', 'Y', 'I', 'K']\n",
      "C1 -> ['B1', 'V', 'C', 'L', 'B']\n",
      "B1 -> ['F', 'Y', 'C', 'L']\n",
      "F -> ['Y', 'I']\n",
      "V -> ['Y']\n",
      "Y -> []\n",
      "E -> ['Q', 'K']\n",
      "Q -> ['D1']\n",
      "C -> []\n",
      "S -> ['R', 'B', 'D1']\n",
      "R -> ['L', 'D1']\n",
      "L -> []\n",
      "K -> []\n",
      "I -> ['B']\n",
      "B -> []\n",
      "D1 -> []\n",
      "\n",
      "Net 60:\n",
      "P -> ['E1', 'C1', 'I', 'G', 'C2', 'F2']\n",
      "E1 -> ['X', 'E2', 'C', 'G2', 'H2']\n",
      "C1 -> ['Z', 'H', 'E', 'X1', 'B2', 'V']\n",
      "U -> ['N', 'P1', 'H', 'W1', 'D2', 'C', 'B', 'E', 'X1', 'L', 'H1']\n",
      "N -> ['Z', 'Z1', 'O', 'P1', 'G', 'S', 'M1', 'H2']\n",
      "A -> ['K1', 'Z', 'C', 'S', 'Q']\n",
      "V1 -> ['W', 'Z', 'D', 'S', 'K', 'I1']\n",
      "O1 -> ['K1', 'Q1', 'E2', 'K', 'A1']\n",
      "K1 -> ['Z', 'L1', 'V', 'R1']\n",
      "Z -> ['Z1', 'J1', 'Y1', 'E', 'H2', 'U1', 'R1', 'H1']\n",
      "Z1 -> ['O', 'L', 'M']\n",
      "O -> ['I', 'D1', 'R']\n",
      "T -> ['D', 'G1', 'F1', 'B', 'F2', 'M']\n",
      "D -> ['I', 'D2', 'G2', 'R', 'B2']\n",
      "J1 -> ['I', 'B']\n",
      "I -> ['D1', 'A2', 'H2', 'B2']\n",
      "G -> ['Q1', 'D2', 'M', 'Y']\n",
      "T1 -> ['D2', 'A1']\n",
      "F -> ['D2', 'L', 'B2', 'Y']\n",
      "N1 -> ['G1', 'Y1', 'E2', 'U1']\n",
      "Y1 -> ['H', 'D2', 'X1', 'B1']\n",
      "D2 -> ['C2', 'L', 'Y']\n",
      "F1 -> ['C2', 'B1', 'B2', 'V', 'Y']\n",
      "G1 -> ['P1', 'H', 'S', 'J', 'L1']\n",
      "P1 -> ['E2', 'A1', 'R1']\n",
      "S1 -> ['W', 'D1', 'Q1', 'B', 'Q', 'X1', 'B1', 'I1', 'M']\n",
      "Q1 -> ['H', 'V']\n",
      "H -> ['E2', 'F2', 'R']\n",
      "E2 -> ['C2', 'C', 'K', 'B1', 'I1']\n",
      "W -> ['D1', 'C2', 'F2', 'B1']\n",
      "C2 -> ['C']\n",
      "A2 -> ['G2', 'H2']\n",
      "X1 -> ['H2']\n",
      "H2 -> ['L', 'J']\n",
      "L -> ['F2', 'H1']\n",
      "F2 -> ['I1']\n",
      "D1 -> ['X', 'K', 'E']\n",
      "X -> []\n",
      "W1 -> ['C', 'B1']\n",
      "C -> ['R']\n",
      "S -> ['K']\n",
      "K -> ['G2']\n",
      "B -> ['Q']\n",
      "Q -> ['E', 'I1', 'H1']\n",
      "E -> ['G2']\n",
      "M1 -> ['A1', 'R1']\n",
      "A1 -> ['G2']\n",
      "G2 -> []\n",
      "L1 -> ['B2', 'R1', 'Y']\n",
      "B2 -> ['V']\n",
      "V -> []\n",
      "M -> []\n",
      "U1 -> ['R1']\n",
      "R1 -> ['Y']\n",
      "Y -> []\n",
      "R -> ['I1']\n",
      "I1 -> []\n",
      "B1 -> []\n",
      "J -> []\n",
      "H1 -> []\n",
      "\n",
      "Wrote quiz samples to: quiz_samples_net5.csv\n",
      "=== DEBUG: Printing Elementary Quiz ===\n",
      "Quiz function: create_dependency_quiz\n",
      "Network size: 5\n",
      "Has evidence: False\n",
      "Number of questions: 2\n",
      "==================================================\n",
      "\n",
      "--- Question 1 ---\n",
      "Node1: B\n",
      "Node2: C\n",
      "Evidence: None\n",
      "\n",
      "Question Format: Is changing the evidence of {node1} going to change the probability of {node2}?\n",
      "Generated Question: Is changing the evidence of B going to change the probability of C?\n",
      "Correct Answer: A\n",
      "\n",
      "Quiz:\n",
      "Is changing the evidence of B going to change the probability of C?\n",
      "--------------------------------\n",
      "A. Yes, B is d-connected to C, which means that entering evidence for B would change the probability of C and vice versa. They d-connected through the following path: ['B', 'C']\n",
      "--------------------------------\n",
      "B. Yes, they are d-connected through the path D, E. Meaning that changing the evidence of B will change the probability of C.\n",
      "--------------------------------\n",
      "C. None of the above\n",
      "--------------------------------\n",
      "D. No, there is no path between B and C. Meaning that changing the evidence of B will not change the probability of C.\n",
      "\n",
      "Quiz Dict Structure:\n",
      "Header: Is changing the evidence of B going to change the probability of C?\n",
      "Options: 4 options\n",
      "  A. Yes, B is d-connected to C, which means that entering evidence for B would change the probability of C and vice versa. They d-connected through the following path: ['B', 'C'] (Correct: True)\n",
      "  B. Yes, they are d-connected through the path D, E. Meaning that changing the evidence of B will change the probability of C. (Correct: False)\n",
      "  C. None of the above (Correct: False)\n",
      "  D. No, there is no path between B and C. Meaning that changing the evidence of B will not change the probability of C. (Correct: False)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Question 2 ---\n",
      "Node1: D\n",
      "Node2: E\n",
      "Evidence: None\n",
      "\n",
      "Question Format: Is {node1} d-connected to {node2}?\n",
      "Generated Question: Is D d-connected to E?\n",
      "Correct Answer: A\n",
      "\n",
      "Quiz:\n",
      "Is D d-connected to E?\n",
      "--------------------------------\n",
      "A. Yes, D is d-connected to E, which means that entering evidence for D would change the probability of E and vice versa. They d-connected through the following path: ['D', 'E']\n",
      "--------------------------------\n",
      "B. Yes, they are d-connected through the path B, C. Meaning that changing the evidence of D will change the probability of E.\n",
      "--------------------------------\n",
      "C. None of the above\n",
      "--------------------------------\n",
      "D. No, there is no path between D and E. Meaning that changing the evidence of D will not change the probability of E.\n",
      "\n",
      "Quiz Dict Structure:\n",
      "Header: Is D d-connected to E?\n",
      "Options: 4 options\n",
      "  A. Yes, D is d-connected to E, which means that entering evidence for D would change the probability of E and vice versa. They d-connected through the following path: ['D', 'E'] (Correct: True)\n",
      "  B. Yes, they are d-connected through the path B, C. Meaning that changing the evidence of D will change the probability of E. (Correct: False)\n",
      "  C. None of the above (Correct: False)\n",
      "  D. No, there is no path between D and E. Meaning that changing the evidence of D will not change the probability of E. (Correct: False)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DEBUG: Printing Elementary Quiz ===\n",
      "Quiz function: create_common_cause_quiz\n",
      "Network size: 5\n",
      "Has evidence: False\n",
      "Number of questions: 2\n",
      "==================================================\n",
      "\n",
      "--- Question 1 ---\n",
      "Node1: D\n",
      "Node2: B\n",
      "Evidence: None\n",
      "\n",
      "Question Format: What is the common cause of {node1} and {node2}?\n",
      "Generated Question: What is the common cause of D and B?\n",
      "Correct Answer: A\n",
      "\n",
      "Quiz:\n",
      "What is the common cause of D and B?\n",
      "--------------------------------\n",
      "A. The common causes of D and B are: C, E.\n",
      "--------------------------------\n",
      "B. The common causes of D and B are: A, E.\n",
      "--------------------------------\n",
      "C. No, there is no common cause between D and B.\n",
      "--------------------------------\n",
      "D. None of the above\n",
      "\n",
      "Quiz Dict Structure:\n",
      "Header: What is the common cause of D and B?\n",
      "Options: 4 options\n",
      "  A. The common causes of D and B are: C, E. (Correct: True)\n",
      "  B. The common causes of D and B are: A, E. (Correct: False)\n",
      "  C. No, there is no common cause between D and B. (Correct: False)\n",
      "  D. None of the above (Correct: False)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Question 2 ---\n",
      "Node1: C\n",
      "Node2: D\n",
      "Evidence: None\n",
      "\n",
      "Question Format: Is there a common cause that influences both {node1} and {node2}?\n",
      "Generated Question: Is there a common cause that influences both C and D?\n",
      "Correct Answer: C\n",
      "\n",
      "Quiz:\n",
      "Is there a common cause that influences both C and D?\n",
      "--------------------------------\n",
      "A. The common cause of C and D is: B, E.\n",
      "--------------------------------\n",
      "B. The common cause of C and D is: E, B.\n",
      "--------------------------------\n",
      "C. No, there is no common cause between C and D.\n",
      "--------------------------------\n",
      "D. None of the above\n",
      "\n",
      "Quiz Dict Structure:\n",
      "Header: Is there a common cause that influences both C and D?\n",
      "Options: 4 options\n",
      "  A. The common cause of C and D is: B, E. (Correct: False)\n",
      "  B. The common cause of C and D is: E, B. (Correct: False)\n",
      "  C. No, there is no common cause between C and D. (Correct: True)\n",
      "  D. None of the above (Correct: False)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DEBUG: Printing Elementary Quiz ===\n",
      "Quiz function: create_common_effect_quiz\n",
      "Network size: 5\n",
      "Has evidence: False\n",
      "Number of questions: 2\n",
      "==================================================\n",
      "\n",
      "--- Question 1 ---\n",
      "Node1: D\n",
      "Node2: A\n",
      "Evidence: None\n",
      "\n",
      "Question Format: What is the common effect of {node1} and {node2}?\n",
      "Generated Question: What is the common effect of D and A?\n",
      "Correct Answer: A\n",
      "\n",
      "Quiz:\n",
      "What is the common effect of D and A?\n",
      "--------------------------------\n",
      "A. The common effect of D and A is: B.\n",
      "--------------------------------\n",
      "B. The common effect of D and A is: B, C.\n",
      "--------------------------------\n",
      "C. No, there is no common effect between D and A.\n",
      "--------------------------------\n",
      "D. None of the above\n",
      "\n",
      "Quiz Dict Structure:\n",
      "Header: What is the common effect of D and A?\n",
      "Options: 4 options\n",
      "  A. The common effect of D and A is: B. (Correct: True)\n",
      "  B. The common effect of D and A is: B, C. (Correct: False)\n",
      "  C. No, there is no common effect between D and A. (Correct: False)\n",
      "  D. None of the above (Correct: False)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Question 2 ---\n",
      "Node1: B\n",
      "Node2: D\n",
      "Evidence: None\n",
      "\n",
      "Question Format: Is there a common effect that influences both {node1} and {node2}?\n",
      "Generated Question: Is there a common effect that influences both B and D?\n",
      "Correct Answer: C\n",
      "\n",
      "Quiz:\n",
      "Is there a common effect that influences both B and D?\n",
      "--------------------------------\n",
      "A. The common effect of B and D is: A, C.\n",
      "--------------------------------\n",
      "B. The common effect of B and D is: E, C.\n",
      "--------------------------------\n",
      "C. No, there is no common effect between B and D.\n",
      "--------------------------------\n",
      "D. None of the above\n",
      "\n",
      "Quiz Dict Structure:\n",
      "Header: Is there a common effect that influences both B and D?\n",
      "Options: 4 options\n",
      "  A. The common effect of B and D is: A, C. (Correct: False)\n",
      "  B. The common effect of B and D is: E, C. (Correct: False)\n",
      "  C. No, there is no common effect between B and D. (Correct: True)\n",
      "  D. None of the above (Correct: False)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DEBUG: Printing Elementary Quiz ===\n",
      "Quiz function: create_blocked_evidence_quiz\n",
      "Network size: 5\n",
      "Has evidence: False\n",
      "Number of questions: 2\n",
      "==================================================\n",
      "\n",
      "--- Question 1 ---\n",
      "Node1: E\n",
      "Node2: C\n",
      "Evidence: None\n",
      "\n",
      "Question Format: What is the minimal set of nodes that would block the dependency between {node1} and {node2}?\n",
      "Generated Question: What is the minimal set of nodes that would block the dependency between E and C?\n",
      "Correct Answer: C\n",
      "\n",
      "Quiz:\n",
      "What is the minimal set of nodes that would block the dependency between E and C?\n",
      "--------------------------------\n",
      "A. The evidence that would block the dependency between E and C is: A, D.\n",
      "--------------------------------\n",
      "B. The evidence that would block the dependency between E and C is: B, A.\n",
      "--------------------------------\n",
      "C. No, there is no evidence that would block the dependency between E and C.\n",
      "--------------------------------\n",
      "D. None of the above\n",
      "\n",
      "Quiz Dict Structure:\n",
      "Header: What is the minimal set of nodes that would block the dependency between E and C?\n",
      "Options: 4 options\n",
      "  A. The evidence that would block the dependency between E and C is: A, D. (Correct: False)\n",
      "  B. The evidence that would block the dependency between E and C is: B, A. (Correct: False)\n",
      "  C. No, there is no evidence that would block the dependency between E and C. (Correct: True)\n",
      "  D. None of the above (Correct: False)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Question 2 ---\n",
      "Node1: C\n",
      "Node2: D\n",
      "Evidence: None\n",
      "\n",
      "Question Format: Which node acts as a blocker for the dependency between {node1} and {node2}?\n",
      "Generated Question: Which node acts as a blocker for the dependency between C and D?\n",
      "Correct Answer: C\n",
      "\n",
      "Quiz:\n",
      "Which node acts as a blocker for the dependency between C and D?\n",
      "--------------------------------\n",
      "A. The evidence that would block the dependency between C and D is: E, A.\n",
      "--------------------------------\n",
      "B. The evidence that would block the dependency between C and D is: A, E.\n",
      "--------------------------------\n",
      "C. No, there is no evidence that would block the dependency between C and D.\n",
      "--------------------------------\n",
      "D. None of the above\n",
      "\n",
      "Quiz Dict Structure:\n",
      "Header: Which node acts as a blocker for the dependency between C and D?\n",
      "Options: 4 options\n",
      "  A. The evidence that would block the dependency between C and D is: E, A. (Correct: False)\n",
      "  B. The evidence that would block the dependency between C and D is: A, E. (Correct: False)\n",
      "  C. No, there is no evidence that would block the dependency between C and D. (Correct: True)\n",
      "  D. None of the above (Correct: False)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DEBUG: Printing Elementary Quiz ===\n",
      "Quiz function: create_evidence_change_relationship_quiz\n",
      "Network size: 5\n",
      "Has evidence: False\n",
      "Number of questions: 2\n",
      "==================================================\n",
      "\n",
      "--- Question 1 ---\n",
      "Node1: A\n",
      "Node2: C\n",
      "Evidence: ['D']\n",
      "(Auto-enabled evidence for this question format)\n",
      "\n",
      "Question Format: Is the relationship between {node1} and {node2} affected by the evidence of {evidence}?\n",
      "Generated Question: Is the relationship between A and C affected by the evidence of D?\n",
      "Correct Answer: A\n",
      "\n",
      "Quiz:\n",
      "Is the relationship between A and C affected by the evidence of D?\n",
      "--------------------------------\n",
      "A. No - conditioning on D does not change the dependency between A and C. Before observing D, they were d-connected. After observing all evidence, they remain d-connected.\n",
      "--------------------------------\n",
      "B. No - conditioning on D does not change the dependency between A and C. Before observing D, they were d-connected. After observing all evidence, they remain d-connected.\n",
      "--------------------------------\n",
      "C. Yes - conditioning on D changes the dependency between A and C. Before observing D, they were d-connected. After observing all evidence, they are d-separated.\n",
      "--------------------------------\n",
      "D. None of the above\n",
      "\n",
      "Quiz Dict Structure:\n",
      "Header: Is the relationship between A and C affected by the evidence of D?\n",
      "Options: 4 options\n",
      "  A. No - conditioning on D does not change the dependency between A and C. Before observing D, they were d-connected. After observing all evidence, they remain d-connected. (Correct: True)\n",
      "  B. No - conditioning on D does not change the dependency between A and C. Before observing D, they were d-connected. After observing all evidence, they remain d-connected. (Correct: False)\n",
      "  C. Yes - conditioning on D changes the dependency between A and C. Before observing D, they were d-connected. After observing all evidence, they are d-separated. (Correct: False)\n",
      "  D. None of the above (Correct: False)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Question 2 ---\n",
      "Node1: D\n",
      "Node2: B\n",
      "Evidence: ['C']\n",
      "(Auto-enabled evidence for this question format)\n",
      "\n",
      "Question Format: Does observing {evidence} change the dependency between {node1} and {node2}?\n",
      "Generated Question: Does observing C change the dependency between D and B?\n",
      "Correct Answer: A\n",
      "\n",
      "Quiz:\n",
      "Does observing C change the dependency between D and B?\n",
      "--------------------------------\n",
      "A. No - conditioning on C does not change the dependency between D and B. Before observing C, they were d-connected. After observing all evidence, they remain d-connected.\n",
      "--------------------------------\n",
      "B. No - conditioning on C does not change the dependency between D and B. Before observing C, they were d-connected. After observing all evidence, they remain d-connected.\n",
      "--------------------------------\n",
      "C. Yes - conditioning on C changes the dependency between D and B. Before observing C, they were d-connected. After observing all evidence, they are d-separated.\n",
      "--------------------------------\n",
      "D. None of the above\n",
      "\n",
      "Quiz Dict Structure:\n",
      "Header: Does observing C change the dependency between D and B?\n",
      "Options: 4 options\n",
      "  A. No - conditioning on C does not change the dependency between D and B. Before observing C, they were d-connected. After observing all evidence, they remain d-connected. (Correct: True)\n",
      "  B. No - conditioning on C does not change the dependency between D and B. Before observing C, they were d-connected. After observing all evidence, they remain d-connected. (Correct: False)\n",
      "  C. Yes - conditioning on C changes the dependency between D and B. Before observing C, they were d-connected. After observing all evidence, they are d-separated. (Correct: False)\n",
      "  D. None of the above (Correct: False)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DEBUG: Printing Numerical Quiz ===\n",
      "Quiz function: create_probability_quiz\n",
      "Network size: 5\n",
      "Has evidence: True\n",
      "Number of questions: 2\n",
      "==================================================\n",
      "\n",
      "--- Question 1 ---\n",
      "Node: B\n",
      "Evidence: ['C']\n",
      "\n",
      "Question Format: What is the probability of {node} given {evidence}?\n",
      "Generated Question: What is the probability of B given C?\n",
      "Correct Answer: A\n",
      "\n",
      "Quiz:\n",
      "What is the probability of B given C?\n",
      "--------------------------------\n",
      "A. P(B | C=True):\n",
      "  P(B=False) = 0.4971\n",
      "  P(B=True) = 0.5029\n",
      "\n",
      "Original distribution:\n",
      "  P(B=False) = 0.5546\n",
      "  P(B=True) = 0.4454\n",
      "\n",
      "Conclusion:\n",
      "  Belief in 'False' decreased by 0.0576\n",
      "  Belief in 'True' increased by 0.0576\n",
      "  Largest overall per-state shift: 0.0576.\n",
      "Evidence impact (leave-one-out):\n",
      "  - C: L1=0.1151, max_abs=0.0576\n",
      "  => Most influential evidence: C (by L1 contribution).\n",
      "--------------------------------\n",
      "B. P(B | C=True):\n",
      "  P(B=False) = 0.4871\n",
      "  P(B=True) = 0.5129\n",
      "\n",
      "Original distribution:\n",
      "  P(B=False) = 0.5546\n",
      "  P(B=True) = 0.4454\n",
      "\n",
      "Conclusion:\n",
      "  Belief in 'False' decreased by 0.0676\n",
      "  Belief in 'True' increased by 0.0676\n",
      "  Largest overall per-state shift: 0.0676.\n",
      "Evidence impact (leave-one-out):\n",
      "  - C: L1=0.1151, max_abs=0.0576\n",
      "  => Most influential evidence: C (by L1 contribution).\n",
      "--------------------------------\n",
      "C. P(B | C=True):\n",
      "  P(B=False) = 0.4918\n",
      "  P(B=True) = 0.5082\n",
      "\n",
      "Original distribution:\n",
      "  P(B=False) = 0.5546\n",
      "  P(B=True) = 0.4454\n",
      "\n",
      "Conclusion:\n",
      "  Belief in 'False' decreased by 0.0628\n",
      "  Belief in 'True' increased by 0.0628\n",
      "  Largest overall per-state shift: 0.0628.\n",
      "Evidence impact (leave-one-out):\n",
      "  - C: L1=0.1151, max_abs=0.0576\n",
      "  => Most influential evidence: C (by L1 contribution).\n",
      "--------------------------------\n",
      "D. None of the above\n",
      "\n",
      "Quiz Dict Structure:\n",
      "Header: What is the probability of B given C?\n",
      "Options: 4 options\n",
      "  A. P(B | C=True):\n",
      "  P(B=False) = 0.4971\n",
      "  P(B=True) = 0.5029\n",
      "\n",
      "Original distribution:\n",
      "  P(B=False) = 0.5546\n",
      "  P(B=True) = 0.4454\n",
      "\n",
      "Conclusion:\n",
      "  Belief in 'False' decreased by 0.0576\n",
      "  Belief in 'True' increased by 0.0576\n",
      "  Largest overall per-state shift: 0.0576.\n",
      "Evidence impact (leave-one-out):\n",
      "  - C: L1=0.1151, max_abs=0.0576\n",
      "  => Most influential evidence: C (by L1 contribution). (Correct: True)\n",
      "  B. P(B | C=True):\n",
      "  P(B=False) = 0.4871\n",
      "  P(B=True) = 0.5129\n",
      "\n",
      "Original distribution:\n",
      "  P(B=False) = 0.5546\n",
      "  P(B=True) = 0.4454\n",
      "\n",
      "Conclusion:\n",
      "  Belief in 'False' decreased by 0.0676\n",
      "  Belief in 'True' increased by 0.0676\n",
      "  Largest overall per-state shift: 0.0676.\n",
      "Evidence impact (leave-one-out):\n",
      "  - C: L1=0.1151, max_abs=0.0576\n",
      "  => Most influential evidence: C (by L1 contribution). (Correct: False)\n",
      "  C. P(B | C=True):\n",
      "  P(B=False) = 0.4918\n",
      "  P(B=True) = 0.5082\n",
      "\n",
      "Original distribution:\n",
      "  P(B=False) = 0.5546\n",
      "  P(B=True) = 0.4454\n",
      "\n",
      "Conclusion:\n",
      "  Belief in 'False' decreased by 0.0628\n",
      "  Belief in 'True' increased by 0.0628\n",
      "  Largest overall per-state shift: 0.0628.\n",
      "Evidence impact (leave-one-out):\n",
      "  - C: L1=0.1151, max_abs=0.0576\n",
      "  => Most influential evidence: C (by L1 contribution). (Correct: False)\n",
      "  D. None of the above (Correct: False)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Question 2 ---\n",
      "Node: A\n",
      "Evidence: ['B', 'D', 'C']\n",
      "\n",
      "Question Format: Given {evidence}, what is the probability of {node}?\n",
      "Generated Question: Given B, D, C, what is the probability of A?\n",
      "Correct Answer: A\n",
      "\n",
      "Quiz:\n",
      "Given B, D, C, what is the probability of A?\n",
      "--------------------------------\n",
      "A. P(A | B=True, D=True, C=True):\n",
      "  P(A=False) = 0.5424\n",
      "  P(A=True) = 0.4576\n",
      "\n",
      "Original distribution:\n",
      "  P(A=False) = 0.3971\n",
      "  P(A=True) = 0.6029\n",
      "\n",
      "Conclusion:\n",
      "  Belief in 'False' increased by 0.1453\n",
      "  Belief in 'True' decreased by 0.1453\n",
      "  Largest overall per-state shift: 0.1453.\n",
      "Evidence impact (leave-one-out):\n",
      "  - D: L1=0.3850, max_abs=0.1925\n",
      "  - B: L1=0.0715, max_abs=0.0357\n",
      "  - C: L1=0.0658, max_abs=0.0329\n",
      "  => Most influential evidence: D (by L1 contribution).\n",
      "--------------------------------\n",
      "B. P(A | B=True, D=True, C=True):\n",
      "  P(A=False) = 0.5451\n",
      "  P(A=True) = 0.4549\n",
      "\n",
      "Original distribution:\n",
      "  P(A=False) = 0.3971\n",
      "  P(A=True) = 0.6029\n",
      "\n",
      "Conclusion:\n",
      "  Belief in 'False' increased by 0.1480\n",
      "  Belief in 'True' decreased by 0.1480\n",
      "  Largest overall per-state shift: 0.1480.\n",
      "Evidence impact (leave-one-out):\n",
      "  - D: L1=0.3850, max_abs=0.1925\n",
      "  - B: L1=0.0715, max_abs=0.0357\n",
      "  - C: L1=0.0658, max_abs=0.0329\n",
      "  => Most influential evidence: D (by L1 contribution).\n",
      "--------------------------------\n",
      "C. P(A | B=True, D=True, C=True):\n",
      "  P(A=False) = 0.5622\n",
      "  P(A=True) = 0.4378\n",
      "\n",
      "Original distribution:\n",
      "  P(A=False) = 0.3971\n",
      "  P(A=True) = 0.6029\n",
      "\n",
      "Conclusion:\n",
      "  Belief in 'False' increased by 0.1651\n",
      "  Belief in 'True' decreased by 0.1651\n",
      "  Largest overall per-state shift: 0.1651.\n",
      "Evidence impact (leave-one-out):\n",
      "  - D: L1=0.3850, max_abs=0.1925\n",
      "  - B: L1=0.0715, max_abs=0.0357\n",
      "  - C: L1=0.0658, max_abs=0.0329\n",
      "  => Most influential evidence: D (by L1 contribution).\n",
      "--------------------------------\n",
      "D. None of the above\n",
      "\n",
      "Quiz Dict Structure:\n",
      "Header: Given B, D, C, what is the probability of A?\n",
      "Options: 4 options\n",
      "  A. P(A | B=True, D=True, C=True):\n",
      "  P(A=False) = 0.5424\n",
      "  P(A=True) = 0.4576\n",
      "\n",
      "Original distribution:\n",
      "  P(A=False) = 0.3971\n",
      "  P(A=True) = 0.6029\n",
      "\n",
      "Conclusion:\n",
      "  Belief in 'False' increased by 0.1453\n",
      "  Belief in 'True' decreased by 0.1453\n",
      "  Largest overall per-state shift: 0.1453.\n",
      "Evidence impact (leave-one-out):\n",
      "  - D: L1=0.3850, max_abs=0.1925\n",
      "  - B: L1=0.0715, max_abs=0.0357\n",
      "  - C: L1=0.0658, max_abs=0.0329\n",
      "  => Most influential evidence: D (by L1 contribution). (Correct: True)\n",
      "  B. P(A | B=True, D=True, C=True):\n",
      "  P(A=False) = 0.5451\n",
      "  P(A=True) = 0.4549\n",
      "\n",
      "Original distribution:\n",
      "  P(A=False) = 0.3971\n",
      "  P(A=True) = 0.6029\n",
      "\n",
      "Conclusion:\n",
      "  Belief in 'False' increased by 0.1480\n",
      "  Belief in 'True' decreased by 0.1480\n",
      "  Largest overall per-state shift: 0.1480.\n",
      "Evidence impact (leave-one-out):\n",
      "  - D: L1=0.3850, max_abs=0.1925\n",
      "  - B: L1=0.0715, max_abs=0.0357\n",
      "  - C: L1=0.0658, max_abs=0.0329\n",
      "  => Most influential evidence: D (by L1 contribution). (Correct: False)\n",
      "  C. P(A | B=True, D=True, C=True):\n",
      "  P(A=False) = 0.5622\n",
      "  P(A=True) = 0.4378\n",
      "\n",
      "Original distribution:\n",
      "  P(A=False) = 0.3971\n",
      "  P(A=True) = 0.6029\n",
      "\n",
      "Conclusion:\n",
      "  Belief in 'False' increased by 0.1651\n",
      "  Belief in 'True' decreased by 0.1651\n",
      "  Largest overall per-state shift: 0.1651.\n",
      "Evidence impact (leave-one-out):\n",
      "  - D: L1=0.3850, max_abs=0.1925\n",
      "  - B: L1=0.0715, max_abs=0.0357\n",
      "  - C: L1=0.0658, max_abs=0.0329\n",
      "  => Most influential evidence: D (by L1 contribution). (Correct: False)\n",
      "  D. None of the above (Correct: False)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data_output = os.path.join(project_root, \"benchmarking\", \"data\")\n",
    "print(f\"Loading nets from: {data_output}\")\n",
    "net_5, net_10, net_30, net_60 = load_nets_from_parquet(os.path.join(data_output, \"nets_dataset.parquet\"))\n",
    "\n",
    "from benchmarking.model_evaluator import dependency_test, common_cause_test, common_effect_test, blocked_evidence_test, evidence_change_relationship_test, probability_test, highest_impact_evidence_test\n",
    "\n",
    "\n",
    "print(f\"Net 5:\")\n",
    "printNet(net_5)\n",
    "print()\n",
    "\n",
    "print('Net 10:')\n",
    "printNet(net_10)\n",
    "print()\n",
    "\n",
    "print('Net 30:')\n",
    "printNet(net_30)\n",
    "print()\n",
    "\n",
    "print('Net 60:')\n",
    "printNet(net_60)\n",
    "print()\n",
    "\n",
    "export_quiz_samples_to_csv(\n",
    "    net_5,\n",
    "    num_questions=5,\n",
    "    output_file_path=\"quiz_samples_net5.csv\",\n",
    "    include_sets=[\"dependency\", \"common_cause\", \"common_effect\", \"blocked_evidence\", \"evidence_change_relationship\", \"probability\"]\n",
    ")\n",
    "\n",
    "# For elementary tests\n",
    "debug_print_elementary_quiz(\n",
    "    net=net_5,\n",
    "    question_set=DEPENDENCY_QUESTIONS,\n",
    "    create_quiz_function=create_dependency_quiz,\n",
    "    has_evidence=False,\n",
    "    num_questions=2\n",
    ")\n",
    "print()\n",
    "\n",
    "debug_print_elementary_quiz(\n",
    "    net=net_5,\n",
    "    question_set=COMMON_CAUSE_QUESTIONS,\n",
    "    create_quiz_function=create_common_cause_quiz,\n",
    "    has_evidence=False,\n",
    "    num_questions=2\n",
    ")\n",
    "print()\n",
    "\n",
    "debug_print_elementary_quiz(\n",
    "    net=net_5,\n",
    "    question_set=COMMON_EFFECT_QUESTIONS,\n",
    "    create_quiz_function=create_common_effect_quiz,\n",
    "    has_evidence=False,\n",
    "    num_questions=2\n",
    ")\n",
    "print()\n",
    "\n",
    "debug_print_elementary_quiz(\n",
    "    net=net_5,\n",
    "    question_set=BLOCKED_EVIDENCES_QUESTIONS,\n",
    "    create_quiz_function=create_blocked_evidence_quiz,\n",
    "    has_evidence=False,\n",
    "    num_questions=2\n",
    ")\n",
    "print()\n",
    "\n",
    "debug_print_elementary_quiz(\n",
    "    net=net_5,\n",
    "    question_set=EVIDENCE_CHANGE_RELATIONSHIP_QUESTIONS,\n",
    "    create_quiz_function=create_evidence_change_relationship_quiz,\n",
    "    has_evidence=False,\n",
    "    num_questions=2\n",
    ")\n",
    "print()\n",
    "\n",
    "debug_print_numerical_quiz(\n",
    "    net=net_5,\n",
    "    question_set=PROBABILITY_QUESTIONS,\n",
    "    create_quiz_function=create_probability_quiz,\n",
    "    has_evidence=True,\n",
    "    num_questions=2\n",
    ")\n",
    "\n",
    "\n",
    "# print('Dependency Test:--------------------------------')\n",
    "# dependency_test(net_5, num_questions=1)\n",
    "\n",
    "# print('Common Cause Test:--------------------------------')\n",
    "# common_cause_test(net_5, num_questions=1)\n",
    "\n",
    "# print('Common Effect Test:--------------------------------')\n",
    "# common_effect_test(net_5, num_questions=1)\n",
    "\n",
    "# print('Blocked Evidence Test:--------------------------------')\n",
    "# blocked_evidence_test(net_5, num_questions=1)\n",
    "\n",
    "# print('Evidence Change Relationship Test:--------------------------------')\n",
    "# evidence_change_relationship_test(net_5, num_questions=1)\n",
    "\n",
    "# print('Probability Test:--------------------------------')\n",
    "# probability_test(net_5, num_questions=1)\n",
    "\n",
    "# print('Highest Impact Evidence Test:--------------------------------')\n",
    "# highest_impact_evidence_test(net_5, num_questions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "785af237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Network ===\n",
      "\n",
      "C -> ['E', 'D', 'A', 'B']\n",
      "E -> ['D', 'A', 'B']\n",
      "D -> ['A']\n",
      "A -> ['B']\n",
      "B -> []\n",
      "\n",
      "C ['False', 'True']\n",
      "E ['False', 'True']\n",
      "D ['False', 'True']\n",
      "A ['False', 'True']\n",
      "B ['False', 'True']\n",
      "\n",
      "\n",
      "=== USER QUERY ===\n",
      " Is the relationship between C and E affected by the evidence of B? \n",
      "\n",
      "\n",
      "=== BayMin Answer ===\n",
      "\n",
      "[BayMin] tool_call #1: check_evidences_change_relationship_between_two_nodes({'evidence': [{'B': 'True'}], 'node1': 'C', 'node2': 'E'})\n",
      "[BayMin] tool_result #1: {'result': 'No - conditioning on B=True does not change the dependency between C and E. Before observing B=True, they were d-connected. After observing all evidence, they remain d-connected. Sequence: +B => d-connected.'}\n",
      "[BayMin] tool_call #1: check_d_connected({'from_node': 'C', 'to_node': 'E'})\n",
      "[BayMin] tool_result #1: {'result': \"Yes, C is d-connected to E, which means that entering evidence for C would change the probability of E and vice versa. They d-connected through the following path: ['C', 'E']\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No - conditioning on B=True does not change the dependency between C and E. Before observing B=True, they were d-connected. After observing all evidence, they remain d-connected. Sequence: +B => d-connected.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n=== Network ===\\n\")\n",
    "# nets = get_nets()\n",
    "# myNet = nets[1]\n",
    "\n",
    "printNet(net_5)\n",
    "print()\n",
    "print(get_BN_node_states(net_5))\n",
    "\n",
    "\n",
    "question = (\n",
    "    # \"Is Visitinz Azia change the probability of Smokng?\"\n",
    "    # \"Which symtome has a higher impact on Lung Cancer knowing that person is visiting Asia?\"\n",
    "    # \"Is changing the evidence of A going to change the probability of B?\"\n",
    "    # \"What is the common effect of C and B?\"\n",
    "    # \"What is the probability of XRay given Lung Cancer, Smoking and Visit Asiaaa?\"\n",
    "    \"Is the relationship between C and E affected by the evidence of B?\"\n",
    "    # \"What is the probability of A given B is increased and C is present?\"\n",
    "    # \"Is the relationship between Vizit Azia and Lung Cancr get affected when we observe Tuberculosis or Cancer?\"\n",
    "    # \"What set of evidences would block the path between B and C?\"\n",
    "\n",
    ")\n",
    "MODEL = \"llama3.1:70b\"\n",
    "print(\"\\n=== USER QUERY ===\\n\", question, \"\\n\")\n",
    "print(\"\\n=== BayMin Answer ===\\n\")\n",
    "# chat_with_tools(net_5, question, max_tokens=1000, isDebug=True, model=MODEL, isTesting=False)\n",
    "get_answer_from_tool_agent(net_5, question, max_tokens=5000, isTesting=False, isDebug=True)\n",
    "# answer = get_answer_from_tool_agent(myNet, question, max_tokens=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad3e340-3732-4cbd-92c3-4a1c98cf1a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "{\"fnName\":\"add\"}\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to function successfully\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from pydantic import BaseModel\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "MODEL = \"gpt-oss-bn-json\"\n",
    "def answer_this_prompt(prompt, stream=False, model=MODEL, temperature=0, format=None):\n",
    "    payload = {\n",
    "        \"prompt\": prompt,\n",
    "        \"model\": model,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_new_tokens\": 50, # only when stream = False work\n",
    "        \"format\": format\n",
    "    }\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    endpoint = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "    # Send the POST request with streaming enabled\n",
    "    with requests.post(endpoint, headers=headers, json=payload, stream=True) as response:\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                # Process the response incrementally\n",
    "                full_response = \"\"\n",
    "                for line in response.iter_lines(decode_unicode=True):\n",
    "                    if line.strip():  # Skip empty lines\n",
    "                        response_json = json.loads(line)\n",
    "                        chunk = response_json.get(\"response\", \"\")\n",
    "                        full_response += chunk\n",
    "                        \n",
    "                        # Render the response as Markdown\n",
    "                        if stream:\n",
    "                            clear_output(wait=True)\n",
    "                            display(Markdown(full_response))\n",
    "                        \n",
    "                return full_response\n",
    "            except json.JSONDecodeError as e:\n",
    "                return \"Failed to parse JSON: \" + str(e)\n",
    "        else:\n",
    "            return \"Failed to retrieve response: \" + str(response.status_code)\n",
    "\n",
    "class BnToolBox(BaseModel):\n",
    "    fnName: str\n",
    "\n",
    "def add(a=5, b=6):\n",
    "    print('Go to function successfully')\n",
    "    return a + b\n",
    "\n",
    "output = answer_this_prompt('output this function name: add', stream=True, format=BnToolBox.model_json_schema())\n",
    "\n",
    "bn_tool_box = BnToolBox.model_validate_json(output)\n",
    "if bn_tool_box.fnName == 'add':\n",
    "    print(add())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2e5a36-7719-4e9d-a231-84c79e94b1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "{\"fnName\":\"isConnected\"}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bn_path = \"./nets/collection/\"\n",
    "from bni_netica.bni_netica import *\n",
    "from bni_netica.bni_netica import Net\n",
    "\n",
    "CancerNeapolitanNet = Net(bn_path+\"Cancer Neapolitan.neta\")\n",
    "ChestClinicNet = Net(bn_path+\"ChestClinic.neta\")\n",
    "ClassifierNet = Net(bn_path+\"Classifier.neta\")\n",
    "CoronaryRiskNet = Net(bn_path+\"Coronary Risk.neta\")\n",
    "FireNet = Net(bn_path+\"Fire.neta\")\n",
    "MendelGeneticsNet = Net(bn_path+\"Mendel Genetics.neta\")\n",
    "RatsNet = Net(bn_path+\"Rats.neta\")\n",
    "WetGrassNet = Net(bn_path+\"Wet Grass.neta\")\n",
    "RatsNoisyOr = Net(bn_path+\"Rats_NoisyOr.dne\")\n",
    "Derm = Net(bn_path+\"Derm 7.9 A.dne\")\n",
    "\n",
    "BN = \"\"\n",
    "for node in FireNet.nodes():\n",
    "    BN += f\"{node.name()} -> {[child.name() for child in node.children()]}\\n\"\n",
    "\n",
    "def isConnected(net, fromNode, toNode):\n",
    "  relatedNodes = net.node(fromNode).getRelated(\"d_connected\")\n",
    "  for node in relatedNodes:\n",
    "    if node.name() == toNode:\n",
    "      return True\n",
    "  return False\n",
    "\n",
    "\n",
    "BN = \"\"\n",
    "for node in FireNet.nodes():\n",
    "    BN += f\"{node.name()} -> {[child.name() for child in node.children()]}\\n\"\n",
    "\n",
    "PROMPT = \"Within {BN}, is {fromNode} an ancestor of {toNode}?\"\n",
    "fromNode = 'Alarm'\n",
    "toNode = 'Fire'\n",
    "\n",
    "PROMPT = PROMPT.format(BN=BN, fromNode=fromNode, toNode=toNode)\n",
    "inputPrompt = PROMPT + 'if user ask anything related to are these two nodes connected to each other, output this function name: isConnected'\n",
    "output2 = answer_this_prompt(inputPrompt, stream=True, format=BnToolBox.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae4982",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"\"\"In this Bayesian Networks: {BN}, is {fromNode} connected to {toNode}?\"\"\",\n",
    "    \"\"\"In this Bayesian Networks: {BN}, is {fromNode} connected to {toNode}? What are the two nodes mentioned?\"\"\",\n",
    "    \"Within the Bayesian Network {BN}, does a path exist from {fromNode} to {toNode}?\",\n",
    "    \"In the graph {BN}, can information flow from {fromNode} to {toNode}?\", # top perform \n",
    "    \"Are {fromNode} and {toNode} dependent in the Bayesian Network {BN}?\",\n",
    "    \"In {BN}, is there any direct or indirect connection between {fromNode} and {toNode}?\",\n",
    "    \"Can {fromNode} influence {toNode} in the Bayesian Network {BN}?\",\n",
    "    \"Is {toNode} reachable from {fromNode} in the structure of {BN}?\",\n",
    "    \"Does {BN} contain a path that links {fromNode} to {toNode}?\",\n",
    "    \"Are there any edges—direct or through other nodes—connecting {fromNode} and {toNode} in {BN}?\",\n",
    "    \"Is {toNode} conditionally dependent on {fromNode} in the Bayesian Network {BN}?\",\n",
    "    \"Within {BN}, is {fromNode} an ancestor of {toNode}?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfNets = [CancerNeapolitanNet, ChestClinicNet, ClassifierNet, CoronaryRiskNet, FireNet, MendelGeneticsNet, RatsNet, WetGrassNet, RatsNoisyOr, Derm]\n",
    "\n",
    "for question in questions:\n",
    "  total = 0\n",
    "  correct = 0\n",
    "  print(f\"Question: {question.format(BN=net.name(), fromNode=fromNode, toNode=toNode)}\")\n",
    "  for net in listOfNets:\n",
    "      for _ in range(5):\n",
    "        total += 1\n",
    "        fromNode, toNode = pick_two_random_nodes(net)\n",
    "        if fromNode and toNode:\n",
    "            \n",
    "            correctIdentified, queryFromNode, queryToNode = correctIdentification(question, net, fromNode, toNode)\n",
    "            if correctIdentified:\n",
    "              correct += 1\n",
    "            else:\n",
    "              print(f\"Incorrect identification for {net.name()}\")\n",
    "              printNet(net)\n",
    "              print()\n",
    "              print(\"Expected:\", fromNode, \"->\", toNode)\n",
    "              print(\"Reality:\", queryFromNode, \"->\", queryToNode)\n",
    "              print(\"----------------------------------------------------\")\n",
    "\n",
    "  print(f\"Total: {total}, Correct: {correct}, Accuracy: {correct/total:.2%}\")\n",
    "  print(\"<------------------------------------------------------------------------->\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dcb14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bni_netica.support_tools import get_nets, printNet, get_BN_structure, get_BN_node_states\n",
    "# from bni_netica.bn_helpers import BnHelper, QueryTwoNodes, ParamExtractor\n",
    "# from ollama_helper.ollama_helper import answer_this_prompt\n",
    "# from bni_netica.scripts import HELLO_SCRIPT, MENU_SCRIPT, GET_FN_SCRIPT\n",
    "\n",
    "# # PROMPT = \"\"\"Consider this question: '{question}'. \n",
    "# # What are the two nodes in this question? \n",
    "# # Make sure to correctly output the names of nodes exactly as mentioned in the network and in the order as the question mentioned. \n",
    "# # For example, if the question mentioned \"A and B\" then the two nodes are fromNode: A, toNode: B; or if the question mentioned \"Smoking and Cancer\" then the two nodes are fromNode: Smoking, toNode: Cancer. \n",
    "# # Answer in JSON format.\"\"\"\n",
    "\n",
    "# def query_menu(BN_string, net):\n",
    "#     \"\"\"Input: BN: string, net: object\"\"\"\n",
    "#     pre_query = f\"\"\"In this Bayesian Network: \n",
    "# {BN_string}\n",
    "# \"\"\"\n",
    "#     user_query = input(\"Enter your query here: \")\n",
    "#     get_fn_prompt = pre_query + \"\\n\" + user_query + GET_FN_SCRIPT\n",
    "\n",
    "#     get_fn = answer_this_prompt(get_fn_prompt, format=BnHelper.model_json_schema())\n",
    "#     print(\"\\nBayMin:\")\n",
    "#     print(get_fn)\n",
    "\n",
    "#     get_fn = BnHelper.model_validate_json(get_fn)\n",
    "#     fn = get_fn.function_name\n",
    "\n",
    "#     bn_helper = BnHelper(function_name=fn)\n",
    "#     param_extractor = ParamExtractor()\n",
    "    \n",
    "#     if fn == \"is_XY_dconnected\":\n",
    "        \n",
    "#         get_params = param_extractor.extract_two_nodes_from_query(pre_query, user_query)\n",
    "#         print(get_params)\n",
    "\n",
    "#         ans = bn_helper.is_XY_dconnected(net, get_params.from_node, get_params.to_node)\n",
    "\n",
    "#         if ans:\n",
    "#             template = f\"Yes, {get_params.from_node} is d-connected to {get_params.to_node}, which means that entering evidence for {get_params.from_node} would change the probability of {get_params.to_node} and vice versa.\"\n",
    "#         else:\n",
    "#             template = f\"No, {get_params.from_node} is not d-connected to {get_params.to_node}, which means that entering evidence for {get_params.from_node} would not change the probability of {get_params.to_node}.\"\n",
    "        \n",
    "#         explain_prompt = f\"\"\"User asked: In this '{BN_string}', '{user_query}'. We use {fn} function and the output is: '{ans}'. Follow this exact template to provide the answer: '{template}'.\"\"\"\n",
    "#         print(answer_this_prompt(explain_prompt))\n",
    "\n",
    "#     print()\n",
    "    \n",
    "#     print(MENU_SCRIPT)\n",
    "#     choice = int(input(\"Enter your choice: \"))\n",
    "#     print()\n",
    "\n",
    "#     if choice == 1:\n",
    "#         input(\"Enter your query here: \")\n",
    "#         print('This is a sample answer.\\n')\n",
    "#     elif choice == 2:\n",
    "#         input(\"Enter your query here: \")\n",
    "#         print('This is a sample answer.\\n')\n",
    "#     elif choice == 3:\n",
    "#         print(\"Not yet implemented\\n\")\n",
    "#         return \n",
    "#     elif choice == 4:\n",
    "#         print(\"Goodbye!\\n\")\n",
    "#         return    \n",
    "\n",
    "# def main():\n",
    "#     print(HELLO_SCRIPT)\n",
    "#     nets = get_nets()\n",
    "\n",
    "    \n",
    "#     for i, net in enumerate(nets):\n",
    "#         print(f\"{i}: {net.name()}\")\n",
    "\n",
    "#     print()\n",
    "#     choice = int(input(\"Enter the number of the network you want to use: \"))\n",
    "#     print()\n",
    "#     if choice < 0 or choice >= len(nets):\n",
    "#         print(\"Invalid choice. Exiting.\")\n",
    "#         return\n",
    "    \n",
    "#     net = nets[choice]\n",
    "#     print(f\"You chose: {net.name()}\")\n",
    "#     printNet(net)\n",
    "#     print('\\nBN states:\\n')\n",
    "#     print(get_BN_node_states(net))\n",
    "\n",
    "#     BN_string = get_BN_structure(net)\n",
    "#     query_menu(BN_string=BN_string, net=net)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-bn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
